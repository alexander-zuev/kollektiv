{
  "too_small": [
    {
      "id": "35c70e57-5e8c-4993-9f84-79990c745dd2",
      "size": 4,
      "headers": {
        "h1": "Textembed",
        "h2": "",
        "h3": ""
      },
      "text": "Back to top\n"
    },
    {
      "id": "5231e10f-b1b5-42a9-85f4-f56901509ade",
      "size": 65,
      "headers": {
        "h1": "Upstage",
        "h2": "UpstageEmbedding \\#",
        "h3": ""
      },
      "text": "Bases: <code>OpenAIEmbedding</code>\n\nClass for Upstage embeddings.\n\nSource code in <code>llama-index-integrations/embeddings/llama-index-embeddings-upstage/llama_index/embeddings/upstage/base.py</code>\n\n|     |     |\n| --- | --- |\n"
    },
    {
      "id": "ca9c2750-d6f5-4e07-aa1f-d391f8ef07bd",
      "size": 99,
      "headers": {
        "h1": "Simple",
        "h2": "SimpleChatEngine \\#",
        "h3": ""
      },
      "text": "[Skip to content](https://docs.llamaindex.ai/en/stable/api_reference/chat_engines/simple/#llama_index.core.chat_engine.SimpleChatEngine)\nBases: <code>BaseChatEngine</code>\n\nSimple Chat Engine.\n\nHave a conversation with the LLM.\nThis does not make use of a knowledge base.\n\nSource code in <code>llama-index-core/llama_index/core/chat_engine/simple.py</code>\n\n|     |     |\n| --- | --- |\n"
    },
    {
      "id": "dac05150-816a-4391-9e36-1a2432b95e23",
      "size": 61,
      "headers": {
        "h1": "Response",
        "h2": "ResponseEvaluator<code>module-attribute</code>\\#",
        "h3": ""
      },
      "text": "[Skip to content](https://docs.llamaindex.ai/en/stable/api_reference/evaluation/response/#llama_index.core.evaluation.ResponseEvaluator)\nEvaluation modules.\n```\nResponseEvaluator = FaithfulnessEvaluator\n\n```\n\nBack to top\n\nHi, how can I help you?\n\nðŸ¦™\n"
    },
    {
      "id": "016aaec6-6268-4bc5-a161-d17ee01ceaf1",
      "size": 98,
      "headers": {
        "h1": "Coa",
        "h2": "CoAAgentWorker \\#",
        "h3": ""
      },
      "text": "[Skip to content](https://docs.llamaindex.ai/en/stable/api_reference/agent/coa/#llama_index.agent.coa.CoAAgentWorker)\nBases: <code>BaseAgentWorker</code>\n\nChain-of-abstraction Agent Worker.\n\nSource code in <code>llama-index-integrations/agent/llama-index-agent-coa/llama_index/agent/coa/step.py</code>\n\n|     |     |\n| --- | --- |\n"
    },
    {
      "id": "27c7353f-6488-41df-a003-5621aa167af8",
      "size": 82,
      "headers": {
        "h1": "Context",
        "h2": "ContextChatEngine \\#",
        "h3": ""
      },
      "text": "Bases: <code>BaseChatEngine</code>\n\nContext Chat Engine.\n\nUses a retriever to retrieve a context, set the context in the system prompt,\nand then uses an LLM to generate a response, for a fluid chat experience.\n\nSource code in <code>llama-index-core/llama_index/core/chat_engine/context.py</code>\n\n|     |     |\n| --- | --- |\n"
    },
    {
      "id": "d34bc4e3-e617-4b51-bd2a-749bbdb8e92b",
      "size": 89,
      "headers": {
        "h1": "Index",
        "h2": "BaseEmbedding \\#",
        "h3": ""
      },
      "text": "[Skip to content](https://docs.llamaindex.ai/en/stable/api_reference/embeddings/#llama_index.core.embeddings.BaseEmbedding)\nBases: <code>TransformComponent</code>, <code>DispatcherSpanMixin</code>\n\nBase class for embeddings.\n\nSource code in <code>llama-index-core/llama_index/core/base/embeddings/base.py</code>\n\n|     |     |\n| --- | --- |\n"
    },
    {
      "id": "ade869ca-40ec-49b4-8687-de3ac0ce93db",
      "size": 63,
      "headers": {
        "h1": "Sagemaker endpoint",
        "h2": "SageMakerEmbedding \\#",
        "h3": ""
      },
      "text": "Bases: <code>BaseEmbedding</code>\n\nSource code in <code>llama-index-integrations/embeddings/llama-index-embeddings-sagemaker-endpoint/llama_index/embeddings/sagemaker_endpoint/base.py</code>\n\n|     |     |\n| --- | --- |\n"
    },
    {
      "id": "ac2f2590-3665-4b85-b300-ad2034f73315",
      "size": 96,
      "headers": {
        "h1": "Bedrock",
        "h2": "BedrockEmbedding \\#",
        "h3": ""
      },
      "text": "[Skip to content](https://docs.llamaindex.ai/en/stable/api_reference/embeddings/bedrock/#llama_index.embeddings.bedrock.BedrockEmbedding)\nBases: <code>BaseEmbedding</code>\n\nSource code in <code>llama-index-integrations/embeddings/llama-index-embeddings-bedrock/llama_index/embeddings/bedrock/base.py</code>\n\n|     |     |\n| --- | --- |\n"
    },
    {
      "id": "77b24cac-5cf5-4013-97c7-04f1dedb1001",
      "size": 68,
      "headers": {
        "h1": "API Reference \\#",
        "h2": "",
        "h3": ""
      },
      "text": "[Skip to content](https://docs.llamaindex.ai/en/stable/api_reference/#api-reference)\nLlamaIndex provides thorough documentation of modules and integrations used in the framework.\n\nUse the navigation or search to find the classes you are interested in!\n\nBack to top\n\nHi, how can I help you?\n\nðŸ¦™\n"
    }
  ],
  "too_large": []
}
