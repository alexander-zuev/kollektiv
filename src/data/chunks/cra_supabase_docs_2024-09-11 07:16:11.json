[
  {
    "chunk_id": "3feba070-2b6a-4bb2-b821-bd45be755483",
    "metadata": {
      "token_count": 132,
      "source_url": "https://supabase.com/docs/guides/ai/examples/nextjs-vector-search",
      "page_title": "Vector search with Next.js and OpenAI | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector search with Next.js and OpenAI",
        "h2": "Learn how to build a ChatGPT-style doc search powered by Next.js, OpenAI, and Supabase."
      },
      "text": "* * *\n\nWhile our [Headless Vector search](/docs/guides/ai/examples/headless-vector-search) provides a toolkit for generative Q&A, in this tutorial we'll go more in-depth, build a custom ChatGPT-like search experience from the ground-up using Next.js. You will:\n\n1. Convert your markdown into embeddings using OpenAI.\n2. Store you embeddings in Postgres using pgvector.\n3. Deploy a function for answering your users' questions.\n\nYou can read our [Supabase Clippy](https://supabase.com/blog/chatgpt-supabase-docs) blog post for a full example.\n"
    }
  },
  {
    "chunk_id": "b4c32009-9f24-4b02-b724-d671d492d63d",
    "metadata": {
      "token_count": 82,
      "source_url": "https://supabase.com/docs/guides/ai/examples/nextjs-vector-search",
      "page_title": "Vector search with Next.js and OpenAI | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector search with Next.js and OpenAI",
        "h2": "Learn how to build a ChatGPT-style doc search powered by Next.js, OpenAI, and Supabase."
      },
      "text": "\nWe assume that you have a Next.js project with a collection of `.mdx` files nested inside your `pages` directory. We will start developing locally with the Supabase CLI and then push our local database changes to our hosted Supabase project. You can find the [full Next.js example on GitHub](https://github.com/supabase-community/nextjs-openai-doc-search).\n",
      "overlap_text": {
        "previous_chunk_id": "3feba070-2b6a-4bb2-b821-bd45be755483",
        "text": "Content of the previous chunk for context: h1: Vector search with Next.js and OpenAI h2: Learn how to build a ChatGPT-style doc search powered by Next.js, OpenAI, and Supabase.\n\n using pgvector.\n3. Deploy a function for answering your users' questions.\n\nYou can read our [Supabase Clippy](https://supabase.com/blog/chatgpt-supabase-docs) blog post for a full example.\n"
      }
    }
  },
  {
    "chunk_id": "67064f8c-d14a-4bf7-9a7a-a85f4c9cd28b",
    "metadata": {
      "token_count": 40,
      "source_url": "https://supabase.com/docs/guides/ai/examples/nextjs-vector-search",
      "page_title": "Vector search with Next.js and OpenAI | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector search with Next.js and OpenAI",
        "h2": "Create a project [\\#](\\#create-a-project)"
      },
      "text": "1. [Create a new project](https://supabase.com/dashboard) in the Supabase Dashboard.\n2. Enter your project details.\n3. Wait for the new database to launch.\n",
      "overlap_text": {
        "previous_chunk_id": "b4c32009-9f24-4b02-b724-d671d492d63d",
        "text": "Content of the previous chunk for context: h1: Vector search with Next.js and OpenAI h2: Learn how to build a ChatGPT-style doc search powered by Next.js, OpenAI, and Supabase.\n\n with the Supabase CLI and then push our local database changes to our hosted Supabase project. You can find the [full Next.js example on GitHub](https://github.com/supabase-community/nextjs-openai-doc-search).\n"
      }
    }
  },
  {
    "chunk_id": "5e352dd7-b78c-489a-b992-ab19855dcaac",
    "metadata": {
      "token_count": 97,
      "source_url": "https://supabase.com/docs/guides/ai/examples/nextjs-vector-search",
      "page_title": "Vector search with Next.js and OpenAI | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector search with Next.js and OpenAI",
        "h2": "Prepare the database [\\#](\\#prepare-the-database)"
      },
      "text": "Let's prepare the database schema. We can use the \"OpenAI Vector Search\" quickstart in the [SQL Editor](https://supabase.com/dashboard/project/_/sql), or you can copy/paste the SQL below and run it yourself.\n\nDashboardSQL\n\n1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.\n2. Click **OpenAI Vector Search**.\n3. Click **Run**.\n",
      "overlap_text": {
        "previous_chunk_id": "67064f8c-d14a-4bf7-9a7a-a85f4c9cd28b",
        "text": "Content of the previous chunk for context: h1: Vector search with Next.js and OpenAI h2: Create a project [\\#](\\#create-a-project)\n\n1. [Create a new project](https://supabase.com/dashboard) in the Supabase Dashboard.\n2. Enter your project details.\n3. Wait for the new database to launch.\n"
      }
    }
  },
  {
    "chunk_id": "b9fcdcad-3264-4856-a94f-8f4aea17aead",
    "metadata": {
      "token_count": 121,
      "source_url": "https://supabase.com/docs/guides/ai/examples/nextjs-vector-search",
      "page_title": "Vector search with Next.js and OpenAI | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector search with Next.js and OpenAI",
        "h2": "Pre-process the knowledge base at build time [\\#](\\#pre-process-the-knowledge-base-at-build-time)"
      },
      "text": "With our database set up, we need to process and store all `.mdx` files in the `pages` directory. You can find the full script [here](https://github.com/supabase-community/nextjs-openai-doc-search/blob/main/lib/generate-embeddings.ts), or follow the steps below:\n\n1\n\n### Generate Embeddings\n\nCreate a new file `lib/generate-embeddings.ts` and copy the code over from [GitHub](https://github.com/supabase-community/nextjs-openai-doc-search/blob/main/lib/generate-embeddings.ts).\n",
      "overlap_text": {
        "previous_chunk_id": "5e352dd7-b78c-489a-b992-ab19855dcaac",
        "text": "Content of the previous chunk for context: h1: Vector search with Next.js and OpenAI h2: Prepare the database [\\#](\\#prepare-the-database)\n\n run it yourself.\n\nDashboardSQL\n\n1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.\n2. Click **OpenAI Vector Search**.\n3. Click **Run**.\n"
      }
    }
  },
  {
    "chunk_id": "0ea96c18-6d54-41c2-a21a-7449abebefab",
    "metadata": {
      "token_count": 105,
      "source_url": "https://supabase.com/docs/guides/ai/examples/nextjs-vector-search",
      "page_title": "Vector search with Next.js and OpenAI | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector search with Next.js and OpenAI",
        "h2": "Pre-process the knowledge base at build time [\\#](\\#pre-process-the-knowledge-base-at-build-time)"
      },
      "text": "\n`\n1\ncurl \\\n2\nhttps://raw.githubusercontent.com/supabase-community/nextjs-openai-doc-search/main/lib/generate-embeddings.ts \\\n3\n-o \"lib/generate-embeddings.ts\"\n`\n\n2\n\n### Set up environment variables\n\nWe need some environment variables to run the script. Add them to your `.env` file and make sure your `.env` file is not committed to source control!\nYou can get your local Supabase credentials by running `supabase status`.\n",
      "overlap_text": {
        "previous_chunk_id": "b9fcdcad-3264-4856-a94f-8f4aea17aead",
        "text": "Content of the previous chunk for context: h1: Vector search with Next.js and OpenAI h2: Pre-process the knowledge base at build time [\\#](\\#pre-process-the-knowledge-base-at-build-time)\n\ndings\n\nCreate a new file `lib/generate-embeddings.ts` and copy the code over from [GitHub](https://github.com/supabase-community/nextjs-openai-doc-search/blob/main/lib/generate-embeddings.ts).\n"
      }
    }
  },
  {
    "chunk_id": "1b7cd410-b87b-4c6b-b441-9bf22a9bd898",
    "metadata": {
      "token_count": 151,
      "source_url": "https://supabase.com/docs/guides/ai/examples/nextjs-vector-search",
      "page_title": "Vector search with Next.js and OpenAI | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector search with Next.js and OpenAI",
        "h2": "Pre-process the knowledge base at build time [\\#](\\#pre-process-the-knowledge-base-at-build-time)"
      },
      "text": "\n`\n1\nNEXT_PUBLIC_SUPABASE_URL=\n2\nNEXT_PUBLIC_SUPABASE_ANON_KEY=\n3\nSUPABASE_SERVICE_ROLE_KEY=\n4\n5\n# Get your key at https://platform.openai.com/account/api-keys\n6\nOPENAI_API_KEY=\n`\n\n3\n\n### Run script at build time\n\nInclude the script in your `package.json` script commands to enable Vercel to automaticall run it at build time.\n\n`\n1\n\"scripts\": {\n2\n\"dev\": \"next dev\",\n3\n\"build\": \"pnpm run embeddings && next build\",\n4\n\"start\": \"next start\",\n5\n\"embeddings\": \"tsx lib/generate-embeddings.ts\"\n6\n},\n`\n",
      "overlap_text": {
        "previous_chunk_id": "0ea96c18-6d54-41c2-a21a-7449abebefab",
        "text": "Content of the previous chunk for context: h1: Vector search with Next.js and OpenAI h2: Pre-process the knowledge base at build time [\\#](\\#pre-process-the-knowledge-base-at-build-time)\n\nWe need some environment variables to run the script. Add them to your `.env` file and make sure your `.env` file is not committed to source control!\nYou can get your local Supabase credentials by running `supabase status`.\n"
      }
    }
  },
  {
    "chunk_id": "103042d5-d652-479a-a0f8-cca32035fcec",
    "metadata": {
      "token_count": 111,
      "source_url": "https://supabase.com/docs/guides/ai/examples/nextjs-vector-search",
      "page_title": "Vector search with Next.js and OpenAI | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector search with Next.js and OpenAI",
        "h2": "Create text completion with OpenAI API [\\#](\\#create-text-completion-with-openai-api)"
      },
      "text": "Anytime a user asks a question, we need to create an embedding for their question, perform a similarity search, and then send a text completion request to the OpenAI API with the query and then context content merged together into a prompt.\n\nAll of this is glued together in a [Vercel Edge Function](https://vercel.com/docs/concepts/functions/edge-functions), the code for which can be found on [GitHub](https://github.com/supabase-community/nextjs-openai-doc-search/blob/main/pages/api/vector-search.ts).\n",
      "overlap_text": {
        "previous_chunk_id": "1b7cd410-b87b-4c6b-b441-9bf22a9bd898",
        "text": "Content of the previous chunk for context: h1: Vector search with Next.js and OpenAI h2: Pre-process the knowledge base at build time [\\#](\\#pre-process-the-knowledge-base-at-build-time)\n\n\"dev\": \"next dev\",\n3\n\"build\": \"pnpm run embeddings && next build\",\n4\n\"start\": \"next start\",\n5\n\"embeddings\": \"tsx lib/generate-embeddings.ts\"\n6\n},\n`\n"
      }
    }
  },
  {
    "chunk_id": "4e5f7c72-9ace-4155-805f-1d68dabc9b2c",
    "metadata": {
      "token_count": 185,
      "source_url": "https://supabase.com/docs/guides/ai/examples/nextjs-vector-search",
      "page_title": "Vector search with Next.js and OpenAI | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector search with Next.js and OpenAI",
        "h2": "Create text completion with OpenAI API [\\#](\\#create-text-completion-with-openai-api)"
      },
      "text": "\n1\n\n### Create Embedding for Question\n\nIn order to perform similarity search we need to turn the question into an embedding.\n\n``\n1\nconst embeddingResponse = await fetch('https://api.openai.com/v1/embeddings', {\n2\nmethod: 'POST',\n3\nheaders: {\n4\n    Authorization: `Bearer ${openAiKey}`,\n5\n    'Content-Type': 'application/json',\n6\n},\n7\nbody: JSON.stringify({\n8\n    model: 'text-embedding-ada-002',\n9\n    input: sanitizedQuery.replaceAll('\\n', ' '),\n10\n}),\n11\n})\n12\n13\nif (embeddingResponse.status !== 200) {\n14\nthrow new ApplicationError('Failed to create embedding for question', embeddingResponse)\n15\n}\n16\n17\nconst {\n18\ndata: [{ embedding }],\n19\n} = await embeddingResponse.json()\n``\n\n",
      "overlap_text": {
        "previous_chunk_id": "103042d5-d652-479a-a0f8-cca32035fcec",
        "text": "Content of the previous chunk for context: h1: Vector search with Next.js and OpenAI h2: Create text completion with OpenAI API [\\#](\\#create-text-completion-with-openai-api)\n\n Function](https://vercel.com/docs/concepts/functions/edge-functions), the code for which can be found on [GitHub](https://github.com/supabase-community/nextjs-openai-doc-search/blob/main/pages/api/vector-search.ts).\n"
      }
    }
  },
  {
    "chunk_id": "965ce8e9-d855-468c-9edc-6d5f03bc3fd9",
    "metadata": {
      "token_count": 111,
      "source_url": "https://supabase.com/docs/guides/ai/examples/nextjs-vector-search",
      "page_title": "Vector search with Next.js and OpenAI | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector search with Next.js and OpenAI",
        "h2": "Create text completion with OpenAI API [\\#](\\#create-text-completion-with-openai-api)"
      },
      "text": "2\n\n### Perform similarity search\n\nUsing the `embeddingResponse` we can now perform similarity search by performing an remote procedure call (RPC) to the database function we created earlier.\n\n`\n1\nconst { error: matchError, data: pageSections } = await supabaseClient.rpc(\n2\n'match_page_sections',\n3\n{\n4\n    embedding,\n5\n    match_threshold: 0.78,\n6\n    match_count: 10,\n7\n    min_content_length: 50,\n8\n}\n9\n)\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "4e5f7c72-9ace-4155-805f-1d68dabc9b2c",
        "text": "Content of the previous chunk for context: h1: Vector search with Next.js and OpenAI h2: Create text completion with OpenAI API [\\#](\\#create-text-completion-with-openai-api)\n\n.status !== 200) {\n14\nthrow new ApplicationError('Failed to create embedding for question', embeddingResponse)\n15\n}\n16\n17\nconst {\n18\ndata: [{ embedding }],\n19\n} = await embeddingResponse.json()\n``\n\n"
      }
    }
  },
  {
    "chunk_id": "9131968e-440f-40ac-bc37-da166e50d842",
    "metadata": {
      "token_count": 449,
      "source_url": "https://supabase.com/docs/guides/ai/examples/nextjs-vector-search",
      "page_title": "Vector search with Next.js and OpenAI | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector search with Next.js and OpenAI",
        "h2": "Create text completion with OpenAI API [\\#](\\#create-text-completion-with-openai-api)"
      },
      "text": "3\n\n### Perform text completion request\n\nWith the relevant content for the user's question identified, we can now build the prompt and make a text completion request via the OpenAI API.\n\nIf successful, the OpenAI API will respond with a `text/event-stream` response that we can simply forward to the client where we'll process the event stream to smoothly print the answer to the user.\n\n``\n1\nconst prompt = codeBlock`\n2\n${oneLine`\n3\n    You are a very enthusiastic Supabase representative who loves\n4\n    to help people! Given the following sections from the Supabase\n5\n    documentation, answer the question using only that information,\n6\n    outputted in markdown format. If you are unsure and the answer\n7\n    is not explicitly written in the documentation, say\n8\n    \"Sorry, I don't know how to help with that.\"\n9\n`}\n10\n11\nContext sections:\n12\n${contextText}\n13\n14\nQuestion: \"\"\"\n15\n${sanitizedQuery}\n16\n\"\"\"\n17\n18\nAnswer as markdown (including related code snippets if available):\n19\n`\n20\n21\nconst completionOptions: CreateCompletionRequest = {\n22\nmodel: 'gpt-3.5-turbo-instruct',\n23\nprompt,\n24\nmax_tokens: 512,\n25\ntemperature: 0,\n26\nstream: true,\n27\n}\n28\n29\nconst response = await fetch('https://api.openai.com/v1/completions', {\n30\nmethod: 'POST',\n31\nheaders: {\n32\n    Authorization: `Bearer ${openAiKey}`,\n33\n    'Content-Type': 'application/json',\n34\n},\n35\nbody: JSON.stringify(completionOptions),\n36\n})\n37\n38\nif (!response.ok) {\n39\nconst error = await response.json()\n40\nthrow new ApplicationError('Failed to generate completion', error)\n41\n}\n42\n43\n// Proxy the streamed SSE response from OpenAI\n44\nreturn new Response(response.body, {\n45\nheaders: {\n46\n    'Content-Type': 'text/event-stream',\n47\n},\n48\n})\n``\n",
      "overlap_text": {
        "previous_chunk_id": "965ce8e9-d855-468c-9edc-6d5f03bc3fd9",
        "text": "Content of the previous chunk for context: h1: Vector search with Next.js and OpenAI h2: Create text completion with OpenAI API [\\#](\\#create-text-completion-with-openai-api)\n\n'match_page_sections',\n3\n{\n4\n    embedding,\n5\n    match_threshold: 0.78,\n6\n    match_count: 10,\n7\n    min_content_length: 50,\n8\n}\n9\n)\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "1d9ce237-8e66-4424-9fb6-aade87d011ae",
    "metadata": {
      "token_count": 526,
      "source_url": "https://supabase.com/docs/guides/ai/examples/nextjs-vector-search",
      "page_title": "Vector search with Next.js and OpenAI | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector search with Next.js and OpenAI",
        "h2": "Display the answer on the frontend [\\#](\\#display-the-answer-on-the-frontend)"
      },
      "text": "In a last step, we need to process the event stream from the OpenAI API and print the answer to the user. The full code for this can be found on [GitHub](https://github.com/supabase-community/nextjs-openai-doc-search/blob/main/components/SearchDialog.tsx).\n\n``\n1\nconst handleConfirm = React.useCallback(\n2\nasync (query: string) => {\n3\n    setAnswer(undefined)\n4\n    setQuestion(query)\n5\n    setSearch('')\n6\n    dispatchPromptData({ index: promptIndex, answer: undefined, query })\n7\n    setHasError(false)\n8\n    setIsLoading(true)\n9\n10\n    const eventSource = new SSE(`api/vector-search`, {\n11\n      headers: {\n12\n        apikey: process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY ?? '',\n13\n        Authorization: `Bearer ${process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY}`,\n14\n        'Content-Type': 'application/json',\n15\n      },\n16\n      payload: JSON.stringify({ query }),\n17\n    })\n18\n19\n    function handleError<T>(err: T) {\n20\n      setIsLoading(false)\n21\n      setHasError(true)\n22\n      console.error(err)\n23\n    }\n24\n25\n    eventSource.addEventListener('error', handleError)\n26\n    eventSource.addEventListener('message', (e: any) => {\n27\n      try {\n28\n        setIsLoading(false)\n29\n30\n        if (e.data === '[DONE]') {\n31\n          setPromptIndex((x) => {\n32\n            return x + 1\n33\n          })\n34\n          return\n35\n        }\n36\n37\n        const completionResponse: CreateCompletionResponse = JSON.parse(e.data)\n38\n        const text = completionResponse.choices[0].text\n39\n40\n        setAnswer((answer) => {\n41\n          const currentAnswer = answer ?? ''\n42\n43\n          dispatchPromptData({\n44\n            index: promptIndex,\n45\n            answer: currentAnswer + text,\n46\n          })\n47\n48\n          return (answer ?? '') + text\n49\n        })\n50\n      } catch (err) {\n51\n        handleError(err)\n52\n      }\n53\n    })\n54\n55\n    eventSource.stream()\n56\n57\n    eventSourceRef.current = eventSource\n58\n59\n    setIsLoading(true)\n60\n},\n61\n[promptIndex, promptData]\n62\n)\n``\n",
      "overlap_text": {
        "previous_chunk_id": "9131968e-440f-40ac-bc37-da166e50d842",
        "text": "Content of the previous chunk for context: h1: Vector search with Next.js and OpenAI h2: Create text completion with OpenAI API [\\#](\\#create-text-completion-with-openai-api)\n\n41\n}\n42\n43\n// Proxy the streamed SSE response from OpenAI\n44\nreturn new Response(response.body, {\n45\nheaders: {\n46\n    'Content-Type': 'text/event-stream',\n47\n},\n48\n})\n``\n"
      }
    }
  },
  {
    "chunk_id": "b493669d-d8b1-4b68-9845-5dce182a3ea9",
    "metadata": {
      "token_count": 172,
      "source_url": "https://supabase.com/docs/guides/ai/examples/nextjs-vector-search",
      "page_title": "Vector search with Next.js and OpenAI | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector search with Next.js and OpenAI",
        "h2": "Learn more [\\#](\\#learn-more)"
      },
      "text": "Want to learn more about the awesome tech that is powering this?\n\n- Read about how we built [ChatGPT for the Supabase Docs](https://supabase.com/blog/chatgpt-supabase-docs).\n- Read the pgvector Docs for [Embeddings and vector similarity](https://supabase.com/docs/guides/database/extensions/pgvector)\n- Watch Greg's video for a full breakdown:\n\nWatch video guide\n\n![Video guide preview](https://supabase.com/docs/_next/image?url=http%3A%2F%2Fimg.youtube.com%2Fvi%2FxmfNUCjszh4%2F0.jpg&w=3840&q=75&dpl=dpl_8T75GeYs2RqN59z5hY7ru4dxhiVp)\n\n",
      "overlap_text": {
        "previous_chunk_id": "1d9ce237-8e66-4424-9fb6-aade87d011ae",
        "text": "Content of the previous chunk for context: h1: Vector search with Next.js and OpenAI h2: Display the answer on the frontend [\\#](\\#display-the-answer-on-the-frontend)\n\n\n    })\n54\n55\n    eventSource.stream()\n56\n57\n    eventSourceRef.current = eventSource\n58\n59\n    setIsLoading(true)\n60\n},\n61\n[promptIndex, promptData]\n62\n)\n``\n"
      }
    }
  },
  {
    "chunk_id": "7da75c2f-aa72-4d25-a3a6-8b7c996e1408",
    "metadata": {
      "token_count": 100,
      "source_url": "https://supabase.com/docs/guides/ai/examples/nextjs-vector-search",
      "page_title": "Vector search with Next.js and OpenAI | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector search with Next.js and OpenAI",
        "h2": "Learn more [\\#](\\#learn-more)"
      },
      "text": "### Is this helpful?\n\nYesNo\n\nThanks for your feedback!\n\nOn this page\n\n- [Create a project](#create-a-project)\n- [Prepare the database](#prepare-the-database)\n- [Pre-process the knowledge base at build time](#pre-process-the-knowledge-base-at-build-time)\n- [Create text completion with OpenAI API](#create-text-completion-with-openai-api)\n- [Display the answer on the frontend](#display-the-answer-on-the-frontend)\n",
      "overlap_text": {
        "previous_chunk_id": "b493669d-d8b1-4b68-9845-5dce182a3ea9",
        "text": "Content of the previous chunk for context: h1: Vector search with Next.js and OpenAI h2: Learn more [\\#](\\#learn-more)\n\n%2FxmfNUCjszh4%2F0.jpg&w=3840&q=75&dpl=dpl_8T75GeYs2RqN59z5hY7ru4dxhiVp)\n\n"
      }
    }
  },
  {
    "chunk_id": "fd8b0df0-dcaa-4554-be5a-10d65b1f50b4",
    "metadata": {
      "token_count": 54,
      "source_url": "https://supabase.com/docs/guides/ai/examples/nextjs-vector-search",
      "page_title": "Vector search with Next.js and OpenAI | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector search with Next.js and OpenAI",
        "h2": "Learn more [\\#](\\#learn-more)"
      },
      "text": "- [Learn more](#learn-more)\n\n1. We only collect analytics essential to ensuring smooth operation of our services. [Learn more](https://supabase.com/privacy)\n\n\n\n\n\n   AcceptOpt out[Learn more](https://supabase.com/privacy)\n",
      "overlap_text": {
        "previous_chunk_id": "7da75c2f-aa72-4d25-a3a6-8b7c996e1408",
        "text": "Content of the previous chunk for context: h1: Vector search with Next.js and OpenAI h2: Learn more [\\#](\\#learn-more)\n\n](#pre-process-the-knowledge-base-at-build-time)\n- [Create text completion with OpenAI API](#create-text-completion-with-openai-api)\n- [Display the answer on the frontend](#display-the-answer-on-the-frontend)\n"
      }
    }
  },
  {
    "chunk_id": "b0e0defb-6780-4f7b-bd1e-b2491c0e2f69",
    "metadata": {
      "token_count": 85,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API"
      },
      "text": "* * *\n\n# API\n\n`vecs` is a python client for managing and querying vector stores in PostgreSQL with the [pgvector extension](https://github.com/pgvector/pgvector). This guide will help you get started with using vecs.\n\nIf you don't have a Postgres database with the pgvector ready, see [hosting](https://supabase.github.io/vecs/hosting) for easy options.\n"
    }
  },
  {
    "chunk_id": "a421569f-97a7-4ccf-84bf-1fbb9e2886e9",
    "metadata": {
      "token_count": 27,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API",
        "h2": "Installation [\\#](\\#installation)"
      },
      "text": "Requires:\n\n- Python 3.7+\n\nYou can install vecs using pip:\n\n`\n_10\npip install vecs\n`\n",
      "overlap_text": {
        "previous_chunk_id": "b0e0defb-6780-4f7b-bd1e-b2491c0e2f69",
        "text": "Content of the previous chunk for context: h1: API\n\nvector). This guide will help you get started with using vecs.\n\nIf you don't have a Postgres database with the pgvector ready, see [hosting](https://supabase.github.io/vecs/hosting) for easy options.\n"
      }
    }
  },
  {
    "chunk_id": "e863ed28-7e4f-4880-ac4c-b376511bfe63",
    "metadata": {
      "token_count": 105,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API",
        "h2": "Connecting [\\#](\\#connecting)"
      },
      "text": "Before you can interact with vecs, create the client to communicate with Postgres. If you haven't started a Postgres instance yet, see [hosting](https://supabase.github.io/vecs/hosting).\n\n`\n_10\nimport vecs\n_10\n_10\nDB_CONNECTION = \"postgresql://<user>:<password>@<host>:<port>/<db_name>\"\n_10\n_10\n# create vector store client\n_10\nvx = vecs.create_client(DB_CONNECTION)\n`\n",
      "overlap_text": {
        "previous_chunk_id": "a421569f-97a7-4ccf-84bf-1fbb9e2886e9",
        "text": "Content of the previous chunk for context: h1: API h2: Installation [\\#](\\#installation)\n\nRequires:\n\n- Python 3.7+\n\nYou can install vecs using pip:\n\n`\n_10\npip install vecs\n`\n"
      }
    }
  },
  {
    "chunk_id": "5f07e0be-412a-4e23-a9da-64ffda4d46ef",
    "metadata": {
      "token_count": 52,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API",
        "h2": "Get or Create a Collection [\\#](\\#get-or-create-a-collection)"
      },
      "text": "You can get a collection (or create if it doesn't exist), specifying the collection's name and the number of dimensions for the vectors you intend to store.\n\n`\n_10\ndocs = vx.get_or_create_collection(name=\"docs\", dimension=3)\n`\n",
      "overlap_text": {
        "previous_chunk_id": "e863ed28-7e4f-4880-ac4c-b376511bfe63",
        "text": "Content of the previous chunk for context: h1: API h2: Connecting [\\#](\\#connecting)\n\n\n_10\nDB_CONNECTION = \"postgresql://<user>:<password>@<host>:<port>/<db_name>\"\n_10\n_10\n# create vector store client\n_10\nvx = vecs.create_client(DB_CONNECTION)\n`\n"
      }
    }
  },
  {
    "chunk_id": "8d328ddc-3255-46b3-8ae7-9722a916dfeb",
    "metadata": {
      "token_count": 211,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API",
        "h2": "Upserting vectors [\\#](\\#upserting-vectors)"
      },
      "text": "`vecs` combines the concepts of \"insert\" and \"update\" into \"upsert\". Upserting records adds them to the collection if the `id` is not present, or updates the existing record if the `id` does exist.\n\n`\n_15\n# add records to the collection\n_15\ndocs.upsert(\n_15\n    records=[\\\n_15\\\n        (\\\n_15\\\n         \"vec0\",           # the vector's identifier\\\n_15\\\n         [0.1, 0.2, 0.3],  # the vector. list or np.array\\\n_15\\\n         {\"year\": 1973}    # associated  metadata\\\n_15\\\n        ),\\\n_15\\\n        (\\\n_15\\\n         \"vec1\",\\\n_15\\\n         [0.7, 0.8, 0.9],\\\n_15\\\n         {\"year\": 2012}\\\n_15\\\n        )\\\n_15\\\n    ]\n_15\n)\n`\n",
      "overlap_text": {
        "previous_chunk_id": "5f07e0be-412a-4e23-a9da-64ffda4d46ef",
        "text": "Content of the previous chunk for context: h1: API h2: Get or Create a Collection [\\#](\\#get-or-create-a-collection)\n\n get a collection (or create if it doesn't exist), specifying the collection's name and the number of dimensions for the vectors you intend to store.\n\n`\n_10\ndocs = vx.get_or_create_collection(name=\"docs\", dimension=3)\n`\n"
      }
    }
  },
  {
    "chunk_id": "497350f0-8278-471a-864f-8a33c07a2d74",
    "metadata": {
      "token_count": 101,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API",
        "h2": "Deleting vectors [\\#](\\#deleting-vectors)"
      },
      "text": "Deleting records removes them from the collection. To delete records, specify a list of `ids` or metadata filters to the `delete` method. The ids of the sucessfully deleted records are returned from the method. Note that attempting to delete non-existent records does not raise an error.\n\n`\n_10\ndocs.delete(ids=[\"vec0\", \"vec1\"])\n_10\n# or delete by a metadata filter\n_10\ndocs.delete(filters={\"year\": {\"$eq\": 2012}})\n`\n",
      "overlap_text": {
        "previous_chunk_id": "8d328ddc-3255-46b3-8ae7-9722a916dfeb",
        "text": "Content of the previous chunk for context: h1: API h2: Upserting vectors [\\#](\\#upserting-vectors)\n\n\",\\\n_15\\\n         [0.7, 0.8, 0.9],\\\n_15\\\n         {\"year\": 2012}\\\n_15\\\n        )\\\n_15\\\n    ]\n_15\n)\n`\n"
      }
    }
  },
  {
    "chunk_id": "a6817863-1e3f-4695-828c-a0896c779408",
    "metadata": {
      "token_count": 100,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API",
        "h2": "Create an index [\\#](\\#create-an-index)"
      },
      "text": "Collections can be queried immediately after being created.\nHowever, for good throughput, the collection should be indexed after records have been upserted.\n\nOnly one index may exist per-collection. By default, creating an index will replace any existing index.\n\nTo create an index:\n\n`\n_10\ndocs.create_index()\n`\n\nYou may optionally provide a distance measure and index method.\n\nAvailable options for distance `measure` are:\n\n- `vecs.IndexMeasure.cosine_distance`\n- `vecs.IndexMeasure.l2_distance`\n",
      "overlap_text": {
        "previous_chunk_id": "497350f0-8278-471a-864f-8a33c07a2d74",
        "text": "Content of the previous chunk for context: h1: API h2: Deleting vectors [\\#](\\#deleting-vectors)\n\n does not raise an error.\n\n`\n_10\ndocs.delete(ids=[\"vec0\", \"vec1\"])\n_10\n# or delete by a metadata filter\n_10\ndocs.delete(filters={\"year\": {\"$eq\": 2012}})\n`\n"
      }
    }
  },
  {
    "chunk_id": "f67b4031-d2aa-4d7d-abb5-6b4986316229",
    "metadata": {
      "token_count": 147,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API",
        "h2": "Create an index [\\#](\\#create-an-index)"
      },
      "text": "- `vecs.IndexMeasure.max_inner_product`\n\nwhich correspond to different methods for comparing query vectors to the vectors in the database.\n\nIf you aren't sure which to use, the default of cosine\\_distance is the most widely compatible with off-the-shelf embedding methods.\n\nAvailable options for index `method` are:\n\n- `vecs.IndexMethod.auto`\n- `vecs.IndexMethod.hnsw`\n- `vecs.IndexMethod.ivfflat`\n\nWhere `auto` selects the best available index method, `hnsw` uses the [HNSW](https://github.com/pgvector/pgvector#hnsw) method and `ivfflat` uses [IVFFlat](https://github.com/pgvector/pgvector#ivfflat).\n",
      "overlap_text": {
        "previous_chunk_id": "a6817863-1e3f-4695-828c-a0896c779408",
        "text": "Content of the previous chunk for context: h1: API h2: Create an index [\\#](\\#create-an-index)\n\n an index:\n\n`\n_10\ndocs.create_index()\n`\n\nYou may optionally provide a distance measure and index method.\n\nAvailable options for distance `measure` are:\n\n- `vecs.IndexMeasure.cosine_distance`\n- `vecs.IndexMeasure.l2_distance`\n"
      }
    }
  },
  {
    "chunk_id": "6e096dae-49b4-4950-b1a3-017ef74f608c",
    "metadata": {
      "token_count": 101,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API",
        "h2": "Create an index [\\#](\\#create-an-index)"
      },
      "text": "\nHNSW and IVFFlat indexes both allow for parameterization to control the speed/accuracy tradeoff. vecs provides sane defaults for these parameters. For a greater level of control you can optionally pass an instance of `vecs.IndexArgsIVFFlat` or `vecs.IndexArgsHNSW` to `create_index`'s `index_arguments` argument. Descriptions of the impact for each parameter are available in the [pgvector docs](https://github.com/pgvector/pgvector).\n",
      "overlap_text": {
        "previous_chunk_id": "f67b4031-d2aa-4d7d-abb5-6b4986316229",
        "text": "Content of the previous chunk for context: h1: API h2: Create an index [\\#](\\#create-an-index)\n\n, `hnsw` uses the [HNSW](https://github.com/pgvector/pgvector#hnsw) method and `ivfflat` uses [IVFFlat](https://github.com/pgvector/pgvector#ivfflat).\n"
      }
    }
  },
  {
    "chunk_id": "771f6eb6-2b85-4b9d-a10f-7a91c2b80d3d",
    "metadata": {
      "token_count": 118,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API",
        "h2": "Create an index [\\#](\\#create-an-index)"
      },
      "text": "\nWhen using IVFFlat indexes, the index must be created **after** the collection has been populated with records. Building an IVFFlat index on an empty collection will result in significantly reduced recall. You can continue upserting new documents after the index has been created, but should rebuild the index if the size of the collection more than doubles since the last index operation.\n\nHNSW indexes can be created immediately after the collection without populating records.\n\nTo manually specify `method`, `measure`, and `index_arguments` add them as arguments to `create_index` for example:\n",
      "overlap_text": {
        "previous_chunk_id": "6e096dae-49b4-4950-b1a3-017ef74f608c",
        "text": "Content of the previous chunk for context: h1: API h2: Create an index [\\#](\\#create-an-index)\n\nlat` or `vecs.IndexArgsHNSW` to `create_index`'s `index_arguments` argument. Descriptions of the impact for each parameter are available in the [pgvector docs](https://github.com/pgvector/pgvector).\n"
      }
    }
  },
  {
    "chunk_id": "54480a3b-841d-423c-b3a8-5717709253df",
    "metadata": {
      "token_count": 98,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API",
        "h2": "Create an index [\\#](\\#create-an-index)"
      },
      "text": "\n`\n_10\ndocs.create_index(\n_10\n    method=IndexMethod.hnsw,\n_10\n    measure=IndexMeasure.cosine_distance,\n_10\n    index_arguments=IndexArgsHNSW(m=8),\n_10\n)\n`\n\nThe time required to create an index grows with the number of records and size of vectors.\nFor a few thousand records expect sub-minute a response in under a minute. It may take a few\nminutes for larger collections.\n",
      "overlap_text": {
        "previous_chunk_id": "771f6eb6-2b85-4b9d-a10f-7a91c2b80d3d",
        "text": "Content of the previous chunk for context: h1: API h2: Create an index [\\#](\\#create-an-index)\n\n than doubles since the last index operation.\n\nHNSW indexes can be created immediately after the collection without populating records.\n\nTo manually specify `method`, `measure`, and `index_arguments` add them as arguments to `create_index` for example:\n"
      }
    }
  },
  {
    "chunk_id": "34ee6ac6-8a91-4262-beec-06b37a0f7cb9",
    "metadata": {
      "token_count": 102,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API",
        "h2": "Query [\\#](\\#query)"
      },
      "text": "Given a collection `docs` with several records:\n\n### Basic [\\#](\\#basic)\n\nThe simplest form of search is to provide a query vector.\n\nIndexes are essential for good performance. See [creating an index](#create-an-index) for more info.\n\nIf you do not create an index, every query will return a warning\n\n`\n_10\nquery does not have a covering index for cosine_similarity. See Collection.create_index\n`\n\nthat incldues the `IndexMeasure` you should index.\n",
      "overlap_text": {
        "previous_chunk_id": "54480a3b-841d-423c-b3a8-5717709253df",
        "text": "Content of the previous chunk for context: h1: API h2: Create an index [\\#](\\#create-an-index)\n\n),\n_10\n)\n`\n\nThe time required to create an index grows with the number of records and size of vectors.\nFor a few thousand records expect sub-minute a response in under a minute. It may take a few\nminutes for larger collections.\n"
      }
    }
  },
  {
    "chunk_id": "b9d5a4f0-c514-4509-bc4c-9dff9d8a7e24",
    "metadata": {
      "token_count": 112,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API",
        "h2": "Query [\\#](\\#query)"
      },
      "text": "\n`\n_10\ndocs.query(\n_10\n    data=[0.4,0.5,0.6],          # required\n_10\n    limit=5,                     # number of records to return\n_10\n    filters={},                  # metadata filters\n_10\n    measure=\"cosine_distance\",   # distance measure to use\n_10\n    include_value=False,         # should distance measure values be returned?\n_10\n    include_metadata=False,      # should record metadata be returned?\n_10\n)\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "34ee6ac6-8a91-4262-beec-06b37a0f7cb9",
        "text": "Content of the previous chunk for context: h1: API h2: Query [\\#](\\#query)\n\n.\n\nIf you do not create an index, every query will return a warning\n\n`\n_10\nquery does not have a covering index for cosine_similarity. See Collection.create_index\n`\n\nthat incldues the `IndexMeasure` you should index.\n"
      }
    }
  },
  {
    "chunk_id": "299394b6-128c-4f6e-b16d-78e2de7801dd",
    "metadata": {
      "token_count": 123,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API",
        "h2": "Query [\\#](\\#query)"
      },
      "text": "Which returns a list of vector record `ids`.\n\n### Metadata Filtering [\\#](\\#metadata-filtering)\n\nThe metadata that is associated with each record can also be filtered during a query.\n\nAs an example, `{\"year\": {\"$eq\": 2005}}` filters a `year` metadata key to be equal to 2005\n\nIn context:\n\n`\n_10\ndocs.query(\n_10\n    data=[0.4,0.5,0.6],\n_10\n    filters={\"year\": {\"$eq\": 2012}}, # metadata filters\n_10\n)\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "b9d5a4f0-c514-4509-bc4c-9dff9d8a7e24",
        "text": "Content of the previous chunk for context: h1: API h2: Query [\\#](\\#query)\n\n=\"cosine_distance\",   # distance measure to use\n_10\n    include_value=False,         # should distance measure values be returned?\n_10\n    include_metadata=False,      # should record metadata be returned?\n_10\n)\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "49024cd4-bb80-4fd7-bafa-e0b641fd21c7",
    "metadata": {
      "token_count": 129,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API",
        "h2": "Query [\\#](\\#query)"
      },
      "text": "For a complete reference, see the [metadata guide](metadata).\n\n### Disconnect [\\#](\\#disconnect)\n\nWhen you're done with a collection, be sure to disconnect the client from the database.\n\n`\n_10\nvx.disconnect()\n`\n\nalternatively, use the client as a context manager and it will automatically close the connection on exit.\n\n`\n_10\nimport vecs\n_10\n_10\nDB_CONNECTION = \"postgresql://<user>:<password>@<host>:<port>/<db_name>\"\n_10\n_10\n# create vector store client\n_10\nwith vecs.create_client(DB_CONNECTION) as vx:\n",
      "overlap_text": {
        "previous_chunk_id": "299394b6-128c-4f6e-b16d-78e2de7801dd",
        "text": "Content of the previous chunk for context: h1: API h2: Query [\\#](\\#query)\n\n`\n_10\ndocs.query(\n_10\n    data=[0.4,0.5,0.6],\n_10\n    filters={\"year\": {\"$eq\": 2012}}, # metadata filters\n_10\n)\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "023151d1-4613-4308-8652-6c01b1ad3a04",
    "metadata": {
      "token_count": 29,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API",
        "h2": "Query [\\#](\\#query)"
      },
      "text": "_10\n    # do some work here\n_10\n    pass\n_10\n_10\n# connections are now closed\n`\n",
      "overlap_text": {
        "previous_chunk_id": "49024cd4-bb80-4fd7-bafa-e0b641fd21c7",
        "text": "Content of the previous chunk for context: h1: API h2: Query [\\#](\\#query)\n\n_10\nDB_CONNECTION = \"postgresql://<user>:<password>@<host>:<port>/<db_name>\"\n_10\n_10\n# create vector store client\n_10\nwith vecs.create_client(DB_CONNECTION) as vx:\n"
      }
    }
  },
  {
    "chunk_id": "d7db4aee-0787-4361-849a-3fdaed58638b",
    "metadata": {
      "token_count": 121,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API",
        "h2": "Adapters [\\#](\\#adapters)"
      },
      "text": "Adapters are an optional feature to transform data before adding to or querying from a collection. Adapters make it possible to interact with a collection using only your project's native data type (eg. just raw text), rather than manually handling vectors.\n\nFor a complete list of available adapters, see [built-in adapters](https://supabase.github.io/vecs/concepts_adapters#built-in-adapters).\n\nAs an example, we'll create a collection with an adapter that chunks text into paragraphs and converts each chunk into an embedding vector using the `all-MiniLM-L6-v2` model.\n",
      "overlap_text": {
        "previous_chunk_id": "023151d1-4613-4308-8652-6c01b1ad3a04",
        "text": "Content of the previous chunk for context: h1: API h2: Query [\\#](\\#query)\n\n_10\n    # do some work here\n_10\n    pass\n_10\n_10\n# connections are now closed\n`\n"
      }
    }
  },
  {
    "chunk_id": "4167ea81-fc32-4257-9b0f-ddeaa212c639",
    "metadata": {
      "token_count": 220,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API",
        "h2": "Adapters [\\#](\\#adapters)"
      },
      "text": "\nFirst, install `vecs` with optional dependencies for text embeddings:\n\n`\n_10\npip install \"vecs[text_embedding]\"\n`\n\nThen create a collection with an adapter to chunk text into paragraphs and embed each paragraph using the `all-MiniLM-L6-v2` 384 dimensional text embedding model.\n\n`\n_16\nimport vecs\n_16\nfrom vecs.adapter import Adapter, ParagraphChunker, TextEmbedding\n_16\n_16\n# create vector store client\n_16\nvx = vecs.Client(\"postgresql://<user>:<password>@<host>:<port>/<db_name>\")\n_16\n_16\n# create a collection with an adapter\n_16\ndocs = vx.get_or_create_collection(\n_16\n    name=\"docs\",\n_16\n    adapter=Adapter(\n_16\n        [\\\n_16\\\n            ParagraphChunker(skip_during_query=True),\\\n_16\\\n            TextEmbedding(model='all-MiniLM-L6-v2'),\\\n_16\\\n        ]\n_16\n    )\n_16\n)\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "d7db4aee-0787-4361-849a-3fdaed58638b",
        "text": "Content of the previous chunk for context: h1: API h2: Adapters [\\#](\\#adapters)\n\nvecs/concepts_adapters#built-in-adapters).\n\nAs an example, we'll create a collection with an adapter that chunks text into paragraphs and converts each chunk into an embedding vector using the `all-MiniLM-L6-v2` model.\n"
      }
    }
  },
  {
    "chunk_id": "26db3e3c-3f4a-4248-b0a5-70d5825c73dc",
    "metadata": {
      "token_count": 161,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API",
        "h2": "Adapters [\\#](\\#adapters)"
      },
      "text": "With the adapter registered against the collection, we can upsert records into the collection passing in text rather than vectors.\n\n`\n_15\n# add records to the collection using text as the media type\n_15\ndocs.upsert(\n_15\n    records=[\\\n_15\\\n        (\\\n_15\\\n         \"vec0\",\\\n_15\\\n         \"four score and ....\", # <- note that we can now pass text here\\\n_15\\\n         {\"year\": 1973}\\\n_15\\\n        ),\\\n_15\\\n        (\\\n_15\\\n         \"vec1\",\\\n_15\\\n         \"hello, world!\",\\\n_15\\\n         {\"year\": \"2012\"}\\\n_15\\\n        )\\\n_15\\\n    ]\n_15\n)\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "4167ea81-fc32-4257-9b0f-ddeaa212c639",
        "text": "Content of the previous chunk for context: h1: API h2: Adapters [\\#](\\#adapters)\n\n [\\\n_16\\\n            ParagraphChunker(skip_during_query=True),\\\n_16\\\n            TextEmbedding(model='all-MiniLM-L6-v2'),\\\n_16\\\n        ]\n_16\n    )\n_16\n)\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "eb19d26f-f790-455b-a36f-d6cf5cf1e78d",
    "metadata": {
      "token_count": 36,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API",
        "h2": "Adapters [\\#](\\#adapters)"
      },
      "text": "Similarly, we can query the collection using text.\n\n`\n_10\n_10\n# search by text\n_10\ndocs.query(data=\"foo bar\")\n`\n\n* * *\n",
      "overlap_text": {
        "previous_chunk_id": "26db3e3c-3f4a-4248-b0a5-70d5825c73dc",
        "text": "Content of the previous chunk for context: h1: API h2: Adapters [\\#](\\#adapters)\n\n        (\\\n_15\\\n         \"vec1\",\\\n_15\\\n         \"hello, world!\",\\\n_15\\\n         {\"year\": \"2012\"}\\\n_15\\\n        )\\\n_15\\\n    ]\n_15\n)\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "a84e2943-87f5-482c-897a-5a66e22d9421",
    "metadata": {
      "token_count": 107,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API",
        "h2": "Deprecated [\\#](\\#deprecated)"
      },
      "text": "### Create collection [\\#](\\#create-collection)\n\nDeprecated: use [get\\_or\\_create\\_collection](#get-or-create-a-collection)\n\nYou can create a collection to store vectors specifying the collections name and the number of dimensions in the vectors you intend to store.\n\n`\n_10\ndocs = vx.create_collection(name=\"docs\", dimension=3)\n`\n\n### Get an existing collection [\\#](\\#get-an-existing-collection)\n\nDeprecated: use [get\\_or\\_create\\_collection](#get-or-create-a-collection)\n\n",
      "overlap_text": {
        "previous_chunk_id": "eb19d26f-f790-455b-a36f-d6cf5cf1e78d",
        "text": "Content of the previous chunk for context: h1: API h2: Adapters [\\#](\\#adapters)\n\nSimilarly, we can query the collection using text.\n\n`\n_10\n_10\n# search by text\n_10\ndocs.query(data=\"foo bar\")\n`\n\n* * *\n"
      }
    }
  },
  {
    "chunk_id": "0bc6091c-0191-4a35-9837-a9f228d4ce16",
    "metadata": {
      "token_count": 32,
      "source_url": "https://supabase.com/docs/guides/ai/python/api",
      "page_title": "API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "API",
        "h2": "Deprecated [\\#](\\#deprecated)"
      },
      "text": "To access a previously created collection, use `get_collection` to retrieve it by name\n\n`\n_10\ndocs = vx.get_collection(name=\"docs\")\n`\n",
      "overlap_text": {
        "previous_chunk_id": "a84e2943-87f5-482c-897a-5a66e22d9421",
        "text": "Content of the previous chunk for context: h1: API h2: Deprecated [\\#](\\#deprecated)\n\n10\ndocs = vx.create_collection(name=\"docs\", dimension=3)\n`\n\n### Get an existing collection [\\#](\\#get-an-existing-collection)\n\nDeprecated: use [get\\_or\\_create\\_collection](#get-or-create-a-collection)\n\n"
      }
    }
  },
  {
    "chunk_id": "beec9fbe-d609-4d6b-8819-e766dc95826a",
    "metadata": {
      "token_count": 70,
      "source_url": "https://supabase.com/docs/guides/ai/langchain",
      "page_title": "LangChain | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "LangChain"
      },
      "text": "* * *\n\n[LangChain](https://langchain.com/) is a popular framework for working with AI, Vectors, and embeddings. LangChain supports using Supabase as a [vector store](https://js.langchain.com/docs/modules/indexes/vector_stores/integrations/supabase), using the `pgvector` extension.\n"
    }
  },
  {
    "chunk_id": "51c6a67a-345e-43b5-bbf9-d52d58fd245f",
    "metadata": {
      "token_count": 57,
      "source_url": "https://supabase.com/docs/guides/ai/langchain",
      "page_title": "LangChain | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "LangChain",
        "h2": "Initializing your database [\\#](\\#initializing-your-database)"
      },
      "text": "Prepare you database with the relevant tables:\n\nDashboardSQL\n\n1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.\n2. Click **LangChain** in the Quick start section.\n3. Click **Run**.\n",
      "overlap_text": {
        "previous_chunk_id": "beec9fbe-d609-4d6b-8819-e766dc95826a",
        "text": "Content of the previous chunk for context: h1: LangChain\n\n AI, Vectors, and embeddings. LangChain supports using Supabase as a [vector store](https://js.langchain.com/docs/modules/indexes/vector_stores/integrations/supabase), using the `pgvector` extension.\n"
      }
    }
  },
  {
    "chunk_id": "5916c1d9-2eba-4154-9d3a-2598b6101c54",
    "metadata": {
      "token_count": 345,
      "source_url": "https://supabase.com/docs/guides/ai/langchain",
      "page_title": "LangChain | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "LangChain",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "You can now search your documents using any Node.js application. This is intended to be run on a secure server route.\n\n``\n_28\nimport { SupabaseVectorStore } from 'langchain/vectorstores/supabase'\n_28\nimport { OpenAIEmbeddings } from 'langchain/embeddings/openai'\n_28\nimport { createClient } from '@supabase/supabase-js'\n_28\n_28\nconst supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY\n_28\nif (!supabaseKey) throw new Error(`Expected SUPABASE_SERVICE_ROLE_KEY`)\n_28\n_28\nconst url = process.env.SUPABASE_URL\n_28\nif (!url) throw new Error(`Expected env var SUPABASE_URL`)\n_28\n_28\nexport const run = async () => {\n_28\nconst client = createClient(url, supabaseKey)\n_28\n_28\nconst vectorStore = await SupabaseVectorStore.fromTexts(\n_28\n    ['Hello world', 'Bye bye', \"What's this?\"],\n_28\n    [{ id: 2 }, { id: 1 }, { id: 3 }],\n_28\n    new OpenAIEmbeddings(),\n_28\n    {\n_28\n      client,\n_28\n      tableName: 'documents',\n_28\n      queryName: 'match_documents',\n_28\n    }\n_28\n)\n_28\n_28\nconst resultOne = await vectorStore.similaritySearch('Hello world', 1)\n_28\n_28\nconsole.log(resultOne)\n_28\n}\n``\n\n",
      "overlap_text": {
        "previous_chunk_id": "51c6a67a-345e-43b5-bbf9-d52d58fd245f",
        "text": "Content of the previous chunk for context: h1: LangChain h2: Initializing your database [\\#](\\#initializing-your-database)\n\n:\n\nDashboardSQL\n\n1. Go to the [SQL Editor](https://supabase.com/dashboard/project/_/sql) page in the Dashboard.\n2. Click **LangChain** in the Quick start section.\n3. Click **Run**.\n"
      }
    }
  },
  {
    "chunk_id": "9990a444-9337-4eed-a1d7-850e62fdfbf5",
    "metadata": {
      "token_count": 118,
      "source_url": "https://supabase.com/docs/guides/ai/langchain",
      "page_title": "LangChain | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "LangChain",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "### Simple metadata filtering [\\#](\\#simple-metadata-filtering)\n\nGiven the above `match_documents` Postgres function, you can also pass a filter parameter to only return documents with a specific metadata field value. This filter parameter is a JSON object, and the `match_documents` function will use the Postgres JSONB Containment operator `@>` to filter documents by the metadata field values you specify. See details on the [Postgres JSONB Containment operator](https://www.postgresql.org/docs/current/datatype-json.html#JSON-CONTAINMENT) for more information.\n",
      "overlap_text": {
        "previous_chunk_id": "5916c1d9-2eba-4154-9d3a-2598b6101c54",
        "text": "Content of the previous chunk for context: h1: LangChain h2: Usage [\\#](\\#usage)\n\n',\n_28\n    }\n_28\n)\n_28\n_28\nconst resultOne = await vectorStore.similaritySearch('Hello world', 1)\n_28\n_28\nconsole.log(resultOne)\n_28\n}\n``\n\n"
      }
    }
  },
  {
    "chunk_id": "7dd7f2bd-853a-4523-b19e-d19a4d302261",
    "metadata": {
      "token_count": 344,
      "source_url": "https://supabase.com/docs/guides/ai/langchain",
      "page_title": "LangChain | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "LangChain",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "\n``\n_32\nimport { SupabaseVectorStore } from 'langchain/vectorstores/supabase'\n_32\nimport { OpenAIEmbeddings } from 'langchain/embeddings/openai'\n_32\nimport { createClient } from '@supabase/supabase-js'\n_32\n_32\n// First, follow set-up instructions above\n_32\n_32\nconst privateKey = process.env.SUPABASE_SERVICE_ROLE_KEY\n_32\nif (!privateKey) throw new Error(`Expected env var SUPABASE_SERVICE_ROLE_KEY`)\n_32\n_32\nconst url = process.env.SUPABASE_URL\n_32\nif (!url) throw new Error(`Expected env var SUPABASE_URL`)\n_32\n_32\nexport const run = async () => {\n_32\nconst client = createClient(url, privateKey)\n_32\n_32\nconst vectorStore = await SupabaseVectorStore.fromTexts(\n_32\n    ['Hello world', 'Hello world', 'Hello world'],\n_32\n    [{ user_id: 2 }, { user_id: 1 }, { user_id: 3 }],\n_32\n    new OpenAIEmbeddings(),\n_32\n    {\n_32\n      client,\n_32\n      tableName: 'documents',\n_32\n      queryName: 'match_documents',\n_32\n    }\n_32\n)\n_32\n_32\nconst result = await vectorStore.similaritySearch('Hello world', 1, {\n_32\n    user_id: 3,\n_32\n})\n_32\n_32\nconsole.log(result)\n_32\n}\n``\n\n",
      "overlap_text": {
        "previous_chunk_id": "9990a444-9337-4eed-a1d7-850e62fdfbf5",
        "text": "Content of the previous chunk for context: h1: LangChain h2: Usage [\\#](\\#usage)\n\n `@>` to filter documents by the metadata field values you specify. See details on the [Postgres JSONB Containment operator](https://www.postgresql.org/docs/current/datatype-json.html#JSON-CONTAINMENT) for more information.\n"
      }
    }
  },
  {
    "chunk_id": "732bed15-f982-4508-aa93-68ef4fe0c1d5",
    "metadata": {
      "token_count": 149,
      "source_url": "https://supabase.com/docs/guides/ai/langchain",
      "page_title": "LangChain | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "LangChain",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "### Advanced metadata filtering [\\#](\\#advanced-metadata-filtering)\n\nYou can also use query builder-style filtering ( [similar to how the Supabase JavaScript library works](https://supabase.com/docs/reference/javascript/using-filters)) instead of passing an object. Note that since the filter properties will be in the metadata column, you need to use arrow operators ( `->` for integer or `->>` for text) as defined in [Postgrest API documentation](https://postgrest.org/en/stable/references/api/tables_views.html?highlight=operators#json-columns) and specify the data type of the property (e.g. the column should look something like `metadata->some_int_value::int`).\n",
      "overlap_text": {
        "previous_chunk_id": "7dd7f2bd-853a-4523-b19e-d19a4d302261",
        "text": "Content of the previous chunk for context: h1: LangChain h2: Usage [\\#](\\#usage)\n\n_32\nconst result = await vectorStore.similaritySearch('Hello world', 1, {\n_32\n    user_id: 3,\n_32\n})\n_32\n_32\nconsole.log(result)\n_32\n}\n``\n\n"
      }
    }
  },
  {
    "chunk_id": "9c3c23a2-208e-48e2-a941-66d8a67f2310",
    "metadata": {
      "token_count": 949,
      "source_url": "https://supabase.com/docs/guides/ai/langchain",
      "page_title": "LangChain | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "LangChain",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "\n``\n_62\nimport { SupabaseFilterRPCCall, SupabaseVectorStore } from 'langchain/vectorstores/supabase'\n_62\nimport { OpenAIEmbeddings } from 'langchain/embeddings/openai'\n_62\nimport { createClient } from '@supabase/supabase-js'\n_62\n_62\n// First, follow set-up instructions above\n_62\n_62\nconst privateKey = process.env.SUPABASE_SERVICE_ROLE_KEY\n_62\nif (!privateKey) throw new Error(`Expected env var SUPABASE_SERVICE_ROLE_KEY`)\n_62\n_62\nconst url = process.env.SUPABASE_URL\n_62\nif (!url) throw new Error(`Expected env var SUPABASE_URL`)\n_62\n_62\nexport const run = async () => {\n_62\nconst client = createClient(url, privateKey)\n_62\n_62\nconst embeddings = new OpenAIEmbeddings()\n_62\n_62\nconst store = new SupabaseVectorStore(embeddings, {\n_62\n    client,\n_62\n    tableName: 'documents',\n_62\n})\n_62\n_62\nconst docs = [\\\n_62\\\n    {\\\n_62\\\n      pageContent:\\\n_62\\\n        'This is a long text, but it actually means something because vector database does not understand Lorem Ipsum. So I would need to expand upon the notion of quantum fluff, a theoretical concept where subatomic particles coalesce to form transient multidimensional spaces. Yet, this abstraction holds no real-world application or comprehensible meaning, reflecting a cosmic puzzle.',\\\n_62\\\n      metadata: { b: 1, c: 10, stuff: 'right' },\\\n_62\\\n    },\\\n_62\\\n    {\\\n_62\\\n      pageContent:\\\n_62\\\n        'This is a long text, but it actually means something because vector database does not understand Lorem Ipsum. So I would need to proceed by discussing the echo of virtual tweets in the binary corridors of the digital universe. Each tweet, like a pixelated canary, hums in an unseen frequency, a fascinatingly perplexing phenomenon that, while conjuring vivid imagery, lacks any concrete implication or real-world relevance, portraying a paradox of multidimensional spaces in the age of cyber folklore.',\\\n_62\\\n      metadata: { b: 2, c: 9, stuff: 'right' },\\\n_62\\\n    },\\\n_62\\\n    { pageContent: 'hello', metadata: { b: 1, c: 9, stuff: 'right' } },\\\n_62\\\n    { pageContent: 'hello', metadata: { b: 1, c: 9, stuff: 'wrong' } },\\\n_62\\\n    { pageContent: 'hi', metadata: { b: 2, c: 8, stuff: 'right' } },\\\n_62\\\n    { pageContent: 'bye', metadata: { b: 3, c: 7, stuff: 'right' } },\\\n_62\\\n    { pageContent: \"what's this\", metadata: { b: 4, c: 6, stuff: 'right' } },\\\n_62\\\n]\n_62\n_62\nawait store.addDocuments(docs)\n_62\n_62\nconst funcFilterA: SupabaseFilterRPCCall = (rpc) =>\n_62\n    rpc\n_62\n      .filter('metadata->b::int', 'lt', 3)\n_62\n      .filter('metadata->c::int', 'gt', 7)\n_62\n      .textSearch('content', `'multidimensional' & 'spaces'`, {\n_62\n        config: 'english',\n_62\n      })\n_62\n_62\nconst resultA = await store.similaritySearch('quantum', 4, funcFilterA)\n_62\n_62\nconst funcFilterB: SupabaseFilterRPCCall = (rpc) =>\n_62\n    rpc\n_62\n      .filter('metadata->b::int', 'lt', 3)\n_62\n      .filter('metadata->c::int', 'gt', 7)\n_62\n      .filter('metadata->>stuff', 'eq', 'right')\n_62\n_62\nconst resultB = await store.similaritySearch('hello', 2, funcFilterB)\n_62\n_62\nconsole.log(resultA, resultB)\n_62\n}\n",
      "overlap_text": {
        "previous_chunk_id": "732bed15-f982-4508-aa93-68ef4fe0c1d5",
        "text": "Content of the previous chunk for context: h1: LangChain h2: Usage [\\#](\\#usage)\n\npostgrest.org/en/stable/references/api/tables_views.html?highlight=operators#json-columns) and specify the data type of the property (e.g. the column should look something like `metadata->some_int_value::int`).\n"
      }
    }
  },
  {
    "chunk_id": "503ac291-3cde-4080-b790-835b1e5fe9c3",
    "metadata": {
      "token_count": 1,
      "source_url": "https://supabase.com/docs/guides/ai/langchain",
      "page_title": "LangChain | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "LangChain",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "``\n",
      "overlap_text": {
        "previous_chunk_id": "9c3c23a2-208e-48e2-a941-66d8a67f2310",
        "text": "Content of the previous chunk for context: h1: LangChain h2: Usage [\\#](\\#usage)\n\nadata->>stuff', 'eq', 'right')\n_62\n_62\nconst resultB = await store.similaritySearch('hello', 2, funcFilterB)\n_62\n_62\nconsole.log(resultA, resultB)\n_62\n}\n"
      }
    }
  },
  {
    "chunk_id": "796a5be4-0e1a-4846-b695-f16d8edab1f5",
    "metadata": {
      "token_count": 82,
      "source_url": "https://supabase.com/docs/guides/ai/langchain",
      "page_title": "LangChain | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "LangChain",
        "h2": "Hybrid search [\\#](\\#hybrid-search)"
      },
      "text": "LangChain supports the concept of a hybrid search, which combines Similarity Search with Full Text Search. Read the official docs to get started: [Supabase Hybrid Search](https://js.langchain.com/docs/modules/indexes/retrievers/supabase-hybrid).\n\nYou can install the LangChain Hybrid Search function though our [database.dev package manager](https://database.dev/langchain/hybrid_search).\n",
      "overlap_text": {
        "previous_chunk_id": "503ac291-3cde-4080-b790-835b1e5fe9c3",
        "text": "Content of the previous chunk for context: h1: LangChain h2: Usage [\\#](\\#usage)\n\n``\n"
      }
    }
  },
  {
    "chunk_id": "0aa25866-a727-4cb4-bc02-5f90f50d3892",
    "metadata": {
      "token_count": 71,
      "source_url": "https://supabase.com/docs/guides/ai/langchain",
      "page_title": "LangChain | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "LangChain",
        "h2": "Resources [\\#](\\#resources)"
      },
      "text": "- Official [LangChain site](https://langchain.com/).\n- Official [LangChain docs](https://js.langchain.com/docs/modules/indexes/vector_stores/integrations/supabase).\n- Supabase [Hybrid Search](https://js.langchain.com/docs/modules/indexes/retrievers/supabase-hybrid).\n",
      "overlap_text": {
        "previous_chunk_id": "796a5be4-0e1a-4846-b695-f16d8edab1f5",
        "text": "Content of the previous chunk for context: h1: LangChain h2: Hybrid search [\\#](\\#hybrid-search)\n\n Hybrid Search](https://js.langchain.com/docs/modules/indexes/retrievers/supabase-hybrid).\n\nYou can install the LangChain Hybrid Search function though our [database.dev package manager](https://database.dev/langchain/hybrid_search).\n"
      }
    }
  },
  {
    "chunk_id": "018a975d-690d-4083-9163-2ec10265c490",
    "metadata": {
      "token_count": 68,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "Combine keyword search with semantic search."
      },
      "text": "* * *\n\nHybrid search combines [full text search](/docs/guides/ai/keyword-search) (searching by keyword) with [semantic search](/docs/guides/ai/semantic-search) (searching by meaning) to identify results that are both directly and contextually relevant to the user's query.\n"
    }
  },
  {
    "chunk_id": "63faffa1-c3e8-4ccb-897a-1430be2940ae",
    "metadata": {
      "token_count": 191,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "Why would I want to use hybrid search? [\\#](\\#why-would-i-want-to-use-hybrid-search)"
      },
      "text": "Sometimes a single search method doesn't quite capture what a user is really looking for. For example, if a user searches for \"Italian recipes with tomato sauce\" on a cooking app, a keyword search would pull up recipes that specifically mention \"Italian,\" \"recipes,\" and \"tomato sauce\" in the text. However, it might miss out on dishes that are quintessentially Italian and use tomato sauce but don't explicitly label themselves with these words, or use variations like \"pasta sauce\" or \"marinara.\" On the other hand, a semantic search might understand the culinary context and find recipes that match the intent, such as a traditional \"Spaghetti Marinara,\" even if they don't match the exact keyword phrase. However, it could also suggest recipes that are contextually related but not what the user is looking for, like a \"Mexican salsa\" recipe, because it understands the context to be broadly about tomato-based sauces.\n",
      "overlap_text": {
        "previous_chunk_id": "018a975d-690d-4083-9163-2ec10265c490",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: Combine keyword search with semantic search.\n\nai/keyword-search) (searching by keyword) with [semantic search](/docs/guides/ai/semantic-search) (searching by meaning) to identify results that are both directly and contextually relevant to the user's query.\n"
      }
    }
  },
  {
    "chunk_id": "cc7bc0e5-3ebe-4482-834e-44923661b519",
    "metadata": {
      "token_count": 103,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "Why would I want to use hybrid search? [\\#](\\#why-would-i-want-to-use-hybrid-search)"
      },
      "text": "\nHybrid search combines the strengths of both these methods. It would ensure that recipes explicitly mentioning the keywords are prioritized, thus capturing direct hits that satisfy the keyword criteria. At the same time, it would include recipes identified through semantic understanding as being related in meaning or context, like different Italian dishes that traditionally use tomato sauce but might not have been tagged explicitly with the user's search terms. It identifies results that are both directly and contextually relevant to the user's query while ideally minimizing misses and irrelevant suggestions.\n",
      "overlap_text": {
        "previous_chunk_id": "63faffa1-c3e8-4ccb-897a-1430be2940ae",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: Why would I want to use hybrid search? [\\#](\\#why-would-i-want-to-use-hybrid-search)\n\n't match the exact keyword phrase. However, it could also suggest recipes that are contextually related but not what the user is looking for, like a \"Mexican salsa\" recipe, because it understands the context to be broadly about tomato-based sauces.\n"
      }
    }
  },
  {
    "chunk_id": "a8c596f2-3fe4-48ca-8d0a-573d9c7d2914",
    "metadata": {
      "token_count": 129,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "When would I want to use hybrid search? [\\#](\\#when-would-i-want-to-use-hybrid-search)"
      },
      "text": "The decision to use hybrid search depends on what your users are looking for in your app. For a code repository where developers need to find exact lines of code or error messages, keyword search is likely ideal because it matches specific terms. In a mental health forum where users search for advice or experiences related to their feelings, semantic search may be better because it finds results based on the meaning of a query, not just specific words. For a shopping app where customers might search for specific product names yet also be open to related suggestions, hybrid search combines the best of both worlds - finding exact matches while also uncovering similar products based on the shopping context.\n",
      "overlap_text": {
        "previous_chunk_id": "cc7bc0e5-3ebe-4482-834e-44923661b519",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: Why would I want to use hybrid search? [\\#](\\#why-would-i-want-to-use-hybrid-search)\n\n or context, like different Italian dishes that traditionally use tomato sauce but might not have been tagged explicitly with the user's search terms. It identifies results that are both directly and contextually relevant to the user's query while ideally minimizing misses and irrelevant suggestions.\n"
      }
    }
  },
  {
    "chunk_id": "6a158665-e7f6-466a-b63b-107d131a762b",
    "metadata": {
      "token_count": 180,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "How to combine search methods [\\#](\\#how-to-combine-search-methods)"
      },
      "text": "Hybrid search merges keyword search and semantic search, but how does this process work?\n\nFirst, each search method is executed separately. Keyword search, which involves searching by specific words or phrases present in the content, will yield its own set of results. Similarly, semantic search, which involves understanding the context or meaning behind the search query rather than the specific words used, will generate its own unique results.\n\nNow with these separate result lists available, the next step is to combine them into a single, unified list. This is achieved through a process known as \u201cfusion\u201d. Fusion takes the results from both search methods and merges them together based on a certain ranking or scoring system. This system may prioritize certain results based on factors like their relevance to the search query, their ranking in the individual lists, or other criteria. The result is a final list that integrates the strengths of both keyword and semantic search methods.\n",
      "overlap_text": {
        "previous_chunk_id": "a8c596f2-3fe4-48ca-8d0a-573d9c7d2914",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: When would I want to use hybrid search? [\\#](\\#when-would-i-want-to-use-hybrid-search)\n\n, not just specific words. For a shopping app where customers might search for specific product names yet also be open to related suggestions, hybrid search combines the best of both worlds - finding exact matches while also uncovering similar products based on the shopping context.\n"
      }
    }
  },
  {
    "chunk_id": "8c532678-82ca-4db8-80bd-95051c0afc57",
    "metadata": {
      "token_count": 224,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "Reciprocal Ranked Fusion (RRF) [\\#](\\#reciprocal-ranked-fusion-rrf)"
      },
      "text": "One of the most common fusion methods is Reciprocal Ranked Fusion (RRF). The key idea behind RRF is to give more weight to the top-ranked items in each individual result list when building the final combined list.\n\nIn RRF, we iterate over each record and assign a score (noting that each record could exist in one or both lists). The score is calculated as 1 divided by that record's rank in each list, summed together between both lists. For example, if a record with an ID of `123` was ranked third in the keyword search and ninth in semantic search, it would receive a score of 13+19=0.444\\\\dfrac{1}{3} + \\\\dfrac{1}{9} = 0.44431\u200b+91\u200b=0.444. If the record was found in only one list and not the other, it would receive a score of 0 for the other list. The records are then sorted by this score to create the final list. The items with the highest scores are ranked first, and lowest scores ranked last.\n",
      "overlap_text": {
        "previous_chunk_id": "6a158665-e7f6-466a-b63b-107d131a762b",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: How to combine search methods [\\#](\\#how-to-combine-search-methods)\n\n or scoring system. This system may prioritize certain results based on factors like their relevance to the search query, their ranking in the individual lists, or other criteria. The result is a final list that integrates the strengths of both keyword and semantic search methods.\n"
      }
    }
  },
  {
    "chunk_id": "bbd812c2-063b-4967-94f6-5ed8ee1d66e6",
    "metadata": {
      "token_count": 124,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "Reciprocal Ranked Fusion (RRF) [\\#](\\#reciprocal-ranked-fusion-rrf)"
      },
      "text": "\nThis method ensures that items that are ranked high in multiple lists are given a high rank in the final list. It also ensures that items that are ranked high in only a few lists but low in others are not given a high rank in the final list. Placing the rank in the denominator when calculating score helps penalize the low ranking records.\n\n### Smoothing constant `k` [\\#](\\#smoothing-constant-k)\n\nTo prevent extremely high scores for items that are ranked first (since we're dividing by the rank), a `k` constant is often added to the denominator to smooth the score:\n",
      "overlap_text": {
        "previous_chunk_id": "8c532678-82ca-4db8-80bd-95051c0afc57",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: Reciprocal Ranked Fusion (RRF) [\\#](\\#reciprocal-ranked-fusion-rrf)\n\n one list and not the other, it would receive a score of 0 for the other list. The records are then sorted by this score to create the final list. The items with the highest scores are ranked first, and lowest scores ranked last.\n"
      }
    }
  },
  {
    "chunk_id": "88e43760-da2c-474b-8fd9-0d85331db0fa",
    "metadata": {
      "token_count": 109,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "Reciprocal Ranked Fusion (RRF) [\\#](\\#reciprocal-ranked-fusion-rrf)"
      },
      "text": "\n1k+rank\\\\dfrac{1}{k+rank}k+rank1\u200b\n\nThis constant can be any positive number, but is typically small. A constant of 1 would mean that a record ranked first would have a score of 11+1=0.5\\\\dfrac{1}{1+1} = 0.51+11\u200b=0.5 instead of 111. This adjustment can help balance the influence of items that are ranked very high in individual lists when creating the final combined list.\n",
      "overlap_text": {
        "previous_chunk_id": "bbd812c2-063b-4967-94f6-5ed8ee1d66e6",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: Reciprocal Ranked Fusion (RRF) [\\#](\\#reciprocal-ranked-fusion-rrf)\n\n `k` [\\#](\\#smoothing-constant-k)\n\nTo prevent extremely high scores for items that are ranked first (since we're dividing by the rank), a `k` constant is often added to the denominator to smooth the score:\n"
      }
    }
  },
  {
    "chunk_id": "56917d91-241e-44fc-ad22-ee4f825db2a9",
    "metadata": {
      "token_count": 114,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "Hybrid search in Postgres [\\#](\\#hybrid-search-in-postgres)"
      },
      "text": "Let's implement hybrid search in Postgres using `tsvector` (keyword search) and `pgvector` (semantic search).\n\nFirst we'll create a `documents` table to store the documents that we will search over. This is just an example - adjust this to match the structure of your application.\n\n`\n1\ncreate table documents (\n2\nid bigint primary key generated always as identity,\n3\ncontent text,\n4\nfts tsvector generated always as (to_tsvector('english', content)) stored,\n5\nembedding vector(512)\n6\n);\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "88e43760-da2c-474b-8fd9-0d85331db0fa",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: Reciprocal Ranked Fusion (RRF) [\\#](\\#reciprocal-ranked-fusion-rrf)\n\ndfrac{1}{1+1} = 0.51+11\u200b=0.5 instead of 111. This adjustment can help balance the influence of items that are ranked very high in individual lists when creating the final combined list.\n"
      }
    }
  },
  {
    "chunk_id": "1c24adff-db3a-4480-afbe-4d9cd7835040",
    "metadata": {
      "token_count": 177,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "Hybrid search in Postgres [\\#](\\#hybrid-search-in-postgres)"
      },
      "text": "The table contains 4 columns:\n\n- `id` is an auto-generated unique ID for the record. We'll use this later to match records when performing RRF.\n- `content` contains the actual text we will be searching over.\n- `fts` is an auto-generated `tsvector` column that is generated using the text in `content`. We will use this for [full text search](/docs/guides/database/full-text-search) (search by keyword).\n- `embedding` is a [vector column](/docs/guides/ai/vector-columns) that stores the vector generated from our embedding model. We will use this for [semantic search](/docs/guides/ai/semantic-search) (search by meaning). We chose 512 dimensions for this example, but adjust this to match the size of the embedding vectors generated from your preferred model.\n",
      "overlap_text": {
        "previous_chunk_id": "56917d91-241e-44fc-ad22-ee4f825db2a9",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: Hybrid search in Postgres [\\#](\\#hybrid-search-in-postgres)\n\ncreate table documents (\n2\nid bigint primary key generated always as identity,\n3\ncontent text,\n4\nfts tsvector generated always as (to_tsvector('english', content)) stored,\n5\nembedding vector(512)\n6\n);\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "592cd2bb-8529-4b11-8ceb-854f7e0874af",
    "metadata": {
      "token_count": 126,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "Hybrid search in Postgres [\\#](\\#hybrid-search-in-postgres)"
      },
      "text": "\nNext we'll create indexes on the `fts` and `embedding` columns so that their individual queries will remain fast at scale:\n\n`\n1\n-- Create an index for the full-text search\n2\ncreate index on documents using gin(fts);\n3\n4\n-- Create an index for the semantic vector search\n5\ncreate index on documents using hnsw (embedding vector_ip_ops);\n`\n\nFor full text search we use a [generalized inverted (GIN) index](https://www.postgresql.org/docs/current/gin-intro.html) which is designed for handling composite values like those stored in a `tsvector`.\n",
      "overlap_text": {
        "previous_chunk_id": "1c24adff-db3a-4480-afbe-4d9cd7835040",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: Hybrid search in Postgres [\\#](\\#hybrid-search-in-postgres)\n\n will use this for [semantic search](/docs/guides/ai/semantic-search) (search by meaning). We chose 512 dimensions for this example, but adjust this to match the size of the embedding vectors generated from your preferred model.\n"
      }
    }
  },
  {
    "chunk_id": "3980094f-313d-4404-bb7e-7e3175e49594",
    "metadata": {
      "token_count": 130,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "Hybrid search in Postgres [\\#](\\#hybrid-search-in-postgres)"
      },
      "text": "\nFor semantic vector search we use an [HNSW index](/docs/guides/ai/vector-indexes/hnsw-indexes), which is a high performing approximate nearest neighbor (ANN) search algorithm. Note that we are using the `vector_ip_ops` (inner product) operator with this index because we plan on using the inner product ( `<#>`) operator later in our query. If you plan to use a different operator like cosine distance ( `<=>`), be sure to update the index accordingly. For more information, see [distance operators](/docs/guides/ai/vector-indexes#distance-operators).\n",
      "overlap_text": {
        "previous_chunk_id": "592cd2bb-8529-4b11-8ceb-854f7e0874af",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: Hybrid search in Postgres [\\#](\\#hybrid-search-in-postgres)\n\n vector_ip_ops);\n`\n\nFor full text search we use a [generalized inverted (GIN) index](https://www.postgresql.org/docs/current/gin-intro.html) which is designed for handling composite values like those stored in a `tsvector`.\n"
      }
    }
  },
  {
    "chunk_id": "a855be7a-ef9e-478d-96bf-58ab73fdd9e8",
    "metadata": {
      "token_count": 430,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "Hybrid search in Postgres [\\#](\\#hybrid-search-in-postgres)"
      },
      "text": "\nFinally we'll create our `hybrid_search` function:\n\n`\n1\ncreate or replace function hybrid_search(\n2\nquery_text text,\n3\nquery_embedding vector(512),\n4\nmatch_count int,\n5\nfull_text_weight float = 1,\n6\nsemantic_weight float = 1,\n7\nrrf_k int = 50\n8\n)\n9\nreturns setof documents\n10\nlanguage sql\n11\nas $$\n12\nwith full_text as (\n13\nselect\n14\n    id,\n15\n    -- Note: ts_rank_cd is not indexable but will only rank matches of the where clause\n16\n    -- which shouldn't be too big\n17\n    row_number() over(order by ts_rank_cd(fts, websearch_to_tsquery(query_text)) desc) as rank_ix\n18\nfrom\n19\n    documents\n20\nwhere\n21\n    fts @@ websearch_to_tsquery(query_text)\n22\norder by rank_ix\n23\nlimit least(match_count, 30) * 2\n24\n),\n25\nsemantic as (\n26\nselect\n27\n    id,\n28\n    row_number() over (order by embedding <#> query_embedding) as rank_ix\n29\nfrom\n30\n    documents\n31\norder by rank_ix\n32\nlimit least(match_count, 30) * 2\n33\n)\n34\nselect\n35\ndocuments.*\n36\nfrom\n37\nfull_text\n38\nfull outer join semantic\n39\n    on full_text.id = semantic.id\n40\njoin documents\n41\n    on coalesce(full_text.id, semantic.id) = documents.id\n42\norder by\n43\ncoalesce(1.0 / (rrf_k + full_text.rank_ix), 0.0) * full_text_weight +\n44\ncoalesce(1.0 / (rrf_k + semantic.rank_ix), 0.0) * semantic_weight\n45\ndesc\n46\nlimit\n47\nleast(match_count, 30)\n48\n$$;\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "3980094f-313d-4404-bb7e-7e3175e49594",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: Hybrid search in Postgres [\\#](\\#hybrid-search-in-postgres)\n\n query. If you plan to use a different operator like cosine distance ( `<=>`), be sure to update the index accordingly. For more information, see [distance operators](/docs/guides/ai/vector-indexes#distance-operators).\n"
      }
    }
  },
  {
    "chunk_id": "6d0823e4-35ad-4cb0-bc4c-6435ba1e75e4",
    "metadata": {
      "token_count": 129,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "Hybrid search in Postgres [\\#](\\#hybrid-search-in-postgres)"
      },
      "text": "Let's break this down:\n\n- **Parameters:** The function accepts quite a few parameters, but the main (required) ones are `query_text`, `query_embedding`, and `match_count`.\n\n\n  - `query_text` is the user's query text (more on this shortly)\n  - `query_embedding` is the vector representation of the user's query produced by the embedding model. We chose 512 dimensions for this example, but adjust this to match the size of the embedding vectors generated from your preferred model. This must match the size of the `embedding` vector on the `documents` table (and use the same model).\n",
      "overlap_text": {
        "previous_chunk_id": "a855be7a-ef9e-478d-96bf-58ab73fdd9e8",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: Hybrid search in Postgres [\\#](\\#hybrid-search-in-postgres)\n\n +\n44\ncoalesce(1.0 / (rrf_k + semantic.rank_ix), 0.0) * semantic_weight\n45\ndesc\n46\nlimit\n47\nleast(match_count, 30)\n48\n$$;\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "12bc4957-455f-431b-b488-1f573987d6e6",
    "metadata": {
      "token_count": 107,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "Hybrid search in Postgres [\\#](\\#hybrid-search-in-postgres)"
      },
      "text": "  - `match_count` is the number of records returned in the `limit` clause.\n\nThe other parameters are optional, but give more control over the fusion process.\n  - `full_text_weight` and `semantic_weight` decide how much weight each search method gets in the final score. These are both 1 by default which means they both equally contribute towards the final rank. A `full_text_weight` of 2 and `semantic_weight` of 1 would give full-text search twice as much weight as semantic search.\n",
      "overlap_text": {
        "previous_chunk_id": "6d0823e4-35ad-4cb0-bc4c-6435ba1e75e4",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: Hybrid search in Postgres [\\#](\\#hybrid-search-in-postgres)\n\n We chose 512 dimensions for this example, but adjust this to match the size of the embedding vectors generated from your preferred model. This must match the size of the `embedding` vector on the `documents` table (and use the same model).\n"
      }
    }
  },
  {
    "chunk_id": "339fb9f1-4910-46aa-a57e-0920fc8e9a24",
    "metadata": {
      "token_count": 106,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "Hybrid search in Postgres [\\#](\\#hybrid-search-in-postgres)"
      },
      "text": "  - `rrf_k` is the `k` [smoothing constant](#smoothing-constant-k) added to the reciprocal rank. The default is 50.\n- **Return type:** The function returns a set of records from our `documents` table.\n\n- **CTE:** We create two [common table expressions (CTE)](https://www.postgresql.org/docs/current/queries-with.html), one for full-text search and one for semantic search. These perform each query individually prior to joining them.\n",
      "overlap_text": {
        "previous_chunk_id": "12bc4957-455f-431b-b488-1f573987d6e6",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: Hybrid search in Postgres [\\#](\\#hybrid-search-in-postgres)\n\n score. These are both 1 by default which means they both equally contribute towards the final rank. A `full_text_weight` of 2 and `semantic_weight` of 1 would give full-text search twice as much weight as semantic search.\n"
      }
    }
  },
  {
    "chunk_id": "b7a0ff67-40a0-4371-aaf8-7bb245fe9a46",
    "metadata": {
      "token_count": 40,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "Hybrid search in Postgres [\\#](\\#hybrid-search-in-postgres)"
      },
      "text": "\n- **RRF:** The final query combines the results from the two CTEs using [reciprocal rank fusion (RRF)](#reciprocal-ranked-fusion-rrf).\n",
      "overlap_text": {
        "previous_chunk_id": "339fb9f1-4910-46aa-a57e-0920fc8e9a24",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: Hybrid search in Postgres [\\#](\\#hybrid-search-in-postgres)\n\n **CTE:** We create two [common table expressions (CTE)](https://www.postgresql.org/docs/current/queries-with.html), one for full-text search and one for semantic search. These perform each query individually prior to joining them.\n"
      }
    }
  },
  {
    "chunk_id": "731ed040-3365-4571-b2ea-8f9576ae7b97",
    "metadata": {
      "token_count": 129,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "Running hybrid search [\\#](\\#running-hybrid-search)"
      },
      "text": "To use this function in SQL, we can run:\n\n`\n1\nselect\n2\n*\n3\nfrom\n4\nhybrid_search(\n5\n    'Italian recipes with tomato sauce', -- user query\n6\n    '[...]'::vector(512), -- embedding generated from user query\n7\n    10\n8\n);\n`\n\nIn practice, you will likely be calling this from the [Supabase client](/docs/reference/javascript/introduction) or through a custom backend layer. Here is a quick example of how you might call this from an [Edge Function](/docs/guides/functions) using JavaScript:\n",
      "overlap_text": {
        "previous_chunk_id": "b7a0ff67-40a0-4371-aaf8-7bb245fe9a46",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: Hybrid search in Postgres [\\#](\\#hybrid-search-in-postgres)\n\n\n- **RRF:** The final query combines the results from the two CTEs using [reciprocal rank fusion (RRF)](#reciprocal-ranked-fusion-rrf).\n"
      }
    }
  },
  {
    "chunk_id": "3625e295-468d-4037-a3b2-6d024dbdf666",
    "metadata": {
      "token_count": 389,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "Running hybrid search [\\#](\\#running-hybrid-search)"
      },
      "text": "\n`\n1\nimport { createClient } from 'jsr:@supabase/supabase-js@2'\n2\nimport OpenAI from 'npm:openai'\n3\n4\nconst supabaseUrl = Deno.env.get('SUPABASE_URL')!\n5\nconst supabaseServiceRoleKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!\n6\nconst openaiApiKey = Deno.env.get('OPENAI_API_KEY')!\n7\n8\nDeno.serve(async (req) => {\n9\n// Grab the user's query from the JSON payload\n10\nconst { query } = await req.json()\n11\n12\n// Instantiate OpenAI client\n13\nconst openai = new OpenAI({ apiKey: openaiApiKey })\n14\n15\n// Generate a one-time embedding for the user's query\n16\nconst embeddingResponse = await openai.embeddings.create({\n17\n    model: 'text-embedding-3-large',\n18\n    input: query,\n19\n    dimensions: 512,\n20\n})\n21\n22\nconst [{ embedding }] = embeddingResponse.data\n23\n24\n// Instantiate the Supabase client\n25\n// (replace service role key with user's JWT if using Supabase auth and RLS)\n26\nconst supabase = createClient(supabaseUrl, supabaseServiceRoleKey)\n27\n28\n// Call hybrid_search Postgres function via RPC\n29\nconst { data: documents } = await supabase.rpc('hybrid_search', {\n30\n    query_text: query,\n31\n    query_embedding: embedding,\n32\n    match_count: 10,\n33\n})\n34\n35\nreturn new Response(JSON.stringify(documents), {\n36\n    headers: { 'Content-Type': 'application/json' },\n37\n})\n38\n})\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "731ed040-3365-4571-b2ea-8f9576ae7b97",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: Running hybrid search [\\#](\\#running-hybrid-search)\n\n this from the [Supabase client](/docs/reference/javascript/introduction) or through a custom backend layer. Here is a quick example of how you might call this from an [Edge Function](/docs/guides/functions) using JavaScript:\n"
      }
    }
  },
  {
    "chunk_id": "01e324f6-5180-4fc7-8794-d73caa859850",
    "metadata": {
      "token_count": 158,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "Running hybrid search [\\#](\\#running-hybrid-search)"
      },
      "text": "This uses OpenAI's `text-embedding-3-large` model to generate embeddings (shortened to 512 dimensions for faster retrieval). Swap in your preferred embedding model (and dimension size) accordingly.\n\nTo test this, make a `POST` request to the function's endpoint while passing in a JSON payload containing the user's query. Here is an example `POST` request using cURL:\n\n`\n1\ncurl -i --location --request POST \\\n2\n'http://127.0.0.1:54321/functions/v1/hybrid-search' \\\n3\n  --header 'Authorization: Bearer <anonymous key>' \\\n4\n  --header 'Content-Type: application/json' \\\n5\n  --data '{\"query\":\"Italian recipes with tomato sauce\"}'\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "3625e295-468d-4037-a3b2-6d024dbdf666",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: Running hybrid search [\\#](\\#running-hybrid-search)\n\n: embedding,\n32\n    match_count: 10,\n33\n})\n34\n35\nreturn new Response(JSON.stringify(documents), {\n36\n    headers: { 'Content-Type': 'application/json' },\n37\n})\n38\n})\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "5874674d-78dc-4140-b569-a7a3fab09080",
    "metadata": {
      "token_count": 30,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "Running hybrid search [\\#](\\#running-hybrid-search)"
      },
      "text": "For more information on how to create, test, and deploy edge functions, see [Getting started](/docs/guides/functions/quickstart).\n",
      "overlap_text": {
        "previous_chunk_id": "01e324f6-5180-4fc7-8794-d73caa859850",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: Running hybrid search [\\#](\\#running-hybrid-search)\n\n1/hybrid-search' \\\n3\n  --header 'Authorization: Bearer <anonymous key>' \\\n4\n  --header 'Content-Type: application/json' \\\n5\n  --data '{\"query\":\"Italian recipes with tomato sauce\"}'\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "ce66daa9-7cf8-47f6-bfed-8e326f26778c",
    "metadata": {
      "token_count": 124,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "See also [\\#](\\#see-also)"
      },
      "text": "- [Embedding concepts](/docs/guides/ai/concepts)\n- [Vector columns](/docs/guides/ai/vector-columns)\n- [Vector indexes](/docs/guides/ai/vector-indexes)\n- [Semantic search](/docs/guides/ai/semantic-search)\n- [Full text (keyword) search](/docs/guides/database/full-text-search)\n\n### Is this helpful?\n\nYesNo\n\nThanks for your feedback!\n\nOn this page\n\n- [Why would I want to use hybrid search?](#why-would-i-want-to-use-hybrid-search)\n",
      "overlap_text": {
        "previous_chunk_id": "5874674d-78dc-4140-b569-a7a3fab09080",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: Running hybrid search [\\#](\\#running-hybrid-search)\n\nFor more information on how to create, test, and deploy edge functions, see [Getting started](/docs/guides/functions/quickstart).\n"
      }
    }
  },
  {
    "chunk_id": "d5f960f0-99af-420f-b371-295754413c99",
    "metadata": {
      "token_count": 107,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "See also [\\#](\\#see-also)"
      },
      "text": "- [When would I want to use hybrid search?](#when-would-i-want-to-use-hybrid-search)\n- [How to combine search methods](#how-to-combine-search-methods)\n- [Reciprocal Ranked Fusion (RRF)](#reciprocal-ranked-fusion-rrf)\n- [Smoothing constant k](#smoothing-constant-k)\n- [Hybrid search in Postgres](#hybrid-search-in-postgres)\n- [Running hybrid search](#running-hybrid-search)\n",
      "overlap_text": {
        "previous_chunk_id": "ce66daa9-7cf8-47f6-bfed-8e326f26778c",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: See also [\\#](\\#see-also)\n\n/guides/database/full-text-search)\n\n### Is this helpful?\n\nYesNo\n\nThanks for your feedback!\n\nOn this page\n\n- [Why would I want to use hybrid search?](#why-would-i-want-to-use-hybrid-search)\n"
      }
    }
  },
  {
    "chunk_id": "c6bbb662-7704-47b8-a720-bde674fe9602",
    "metadata": {
      "token_count": 55,
      "source_url": "https://supabase.com/docs/guides/ai/hybrid-search",
      "page_title": "Hybrid search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hybrid search",
        "h2": "See also [\\#](\\#see-also)"
      },
      "text": "- [See also](#see-also)\n\n1. We only collect analytics essential to ensuring smooth operation of our services. [Learn more](https://supabase.com/privacy)\n\n\n\n\n\n   AcceptOpt out[Learn more](https://supabase.com/privacy)\n",
      "overlap_text": {
        "previous_chunk_id": "d5f960f0-99af-420f-b371-295754413c99",
        "text": "Content of the previous chunk for context: h1: Hybrid search h2: See also [\\#](\\#see-also)\n\n-ranked-fusion-rrf)\n- [Smoothing constant k](#smoothing-constant-k)\n- [Hybrid search in Postgres](#hybrid-search-in-postgres)\n- [Running hybrid search](#running-hybrid-search)\n"
      }
    }
  },
  {
    "chunk_id": "60adf1fd-5393-479f-b044-201388400b17",
    "metadata": {
      "token_count": 76,
      "source_url": "https://supabase.com/docs/guides/ai/examples/openai",
      "page_title": "Generating OpenAI GPT3 completions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generating OpenAI GPT3 completions",
        "h2": "Generate GPT text completions using OpenAI and Supabase Edge Functions."
      },
      "text": "* * *\n\nOpenAI provides a [completions API](https://platform.openai.com/docs/api-reference/completions) that allows you to use their generative GPT models in your own applications.\n\nOpenAI's API is intended to be used from the server-side. Supabase offers Edge Functions to make it easy to interact with third party APIs like OpenAI.\n"
    }
  },
  {
    "chunk_id": "b071323d-f420-4ca9-bfc1-b1a1ee862686",
    "metadata": {
      "token_count": 35,
      "source_url": "https://supabase.com/docs/guides/ai/examples/openai",
      "page_title": "Generating OpenAI GPT3 completions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generating OpenAI GPT3 completions",
        "h2": "Setup Supabase project [\\#](\\#setup-supabase-project)"
      },
      "text": "If you haven't already, [install the Supabase CLI](/docs/guides/cli) and initialize your project:\n\n`\n1\nsupabase init\n`\n",
      "overlap_text": {
        "previous_chunk_id": "60adf1fd-5393-479f-b044-201388400b17",
        "text": "Content of the previous chunk for context: h1: Generating OpenAI GPT3 completions h2: Generate GPT text completions using OpenAI and Supabase Edge Functions.\n\n that allows you to use their generative GPT models in your own applications.\n\nOpenAI's API is intended to be used from the server-side. Supabase offers Edge Functions to make it easy to interact with third party APIs like OpenAI.\n"
      }
    }
  },
  {
    "chunk_id": "3e27538b-1a14-4f0b-8347-3709a3ba072c",
    "metadata": {
      "token_count": 299,
      "source_url": "https://supabase.com/docs/guides/ai/examples/openai",
      "page_title": "Generating OpenAI GPT3 completions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generating OpenAI GPT3 completions",
        "h2": "Create edge function [\\#](\\#create-edge-function)"
      },
      "text": "Scaffold a new edge function called `openai` by running:\n\n`\n1\nsupabase functions new openai\n`\n\nA new edge function will now exist under `./supabase/functions/openai/index.ts`.\n\nWe'll design the function to take your user's query (via POST request) and forward it to OpenAI's API.\n\nindex.ts\n\n`\n1\nimport OpenAI from 'https://deno.land/x/openai@v4.24.0/mod.ts'\n2\n3\nDeno.serve(async (req) => {\n4\nconst { query } = await req.json()\n5\nconst apiKey = Deno.env.get('OPENAI_API_KEY')\n6\nconst openai = new OpenAI({\n7\n    apiKey: apiKey,\n8\n})\n9\n10\n// Documentation here: https://github.com/openai/openai-node\n11\nconst chatCompletion = await openai.chat.completions.create({\n12\n    messages: [{ role: 'user', content: query }],\n13\n    // Choose model from here: https://platform.openai.com/docs/models\n14\n    model: 'gpt-3.5-turbo',\n15\n    stream: false,\n16\n})\n17\n18\nconst reply = chatCompletion.choices[0].message.content\n19\n20\nreturn new Response(reply, {\n21\n    headers: { 'Content-Type': 'text/plain' },\n22\n})\n23\n})\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "b071323d-f420-4ca9-bfc1-b1a1ee862686",
        "text": "Content of the previous chunk for context: h1: Generating OpenAI GPT3 completions h2: Setup Supabase project [\\#](\\#setup-supabase-project)\n\nIf you haven't already, [install the Supabase CLI](/docs/guides/cli) and initialize your project:\n\n`\n1\nsupabase init\n`\n"
      }
    }
  },
  {
    "chunk_id": "9beb5d5e-266d-43bc-9a38-7804d82c8361",
    "metadata": {
      "token_count": 49,
      "source_url": "https://supabase.com/docs/guides/ai/examples/openai",
      "page_title": "Generating OpenAI GPT3 completions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generating OpenAI GPT3 completions",
        "h2": "Create edge function [\\#](\\#create-edge-function)"
      },
      "text": "Note that we are setting `stream` to `false` which will wait until the entire response is complete before returning. If you wish to stream GPT's response word-by-word back to your client, set `stream` to `true`.\n",
      "overlap_text": {
        "previous_chunk_id": "3e27538b-1a14-4f0b-8347-3709a3ba072c",
        "text": "Content of the previous chunk for context: h1: Generating OpenAI GPT3 completions h2: Create edge function [\\#](\\#create-edge-function)\n\n\n})\n17\n18\nconst reply = chatCompletion.choices[0].message.content\n19\n20\nreturn new Response(reply, {\n21\n    headers: { 'Content-Type': 'text/plain' },\n22\n})\n23\n})\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "de71e734-48ca-4ffd-a535-97565768a911",
    "metadata": {
      "token_count": 96,
      "source_url": "https://supabase.com/docs/guides/ai/examples/openai",
      "page_title": "Generating OpenAI GPT3 completions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generating OpenAI GPT3 completions",
        "h2": "Create OpenAI key [\\#](\\#create-openai-key)"
      },
      "text": "You may have noticed we were passing `OPENAI_API_KEY` in the Authorization header to OpenAI. To generate this key, go to [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys) and create a new secret key.\n\nAfter getting the key, copy it into a new file called `.env.local` in your `./supabase` folder:\n\n`\n1\nOPENAI_API_KEY=your-key-here\n`\n",
      "overlap_text": {
        "previous_chunk_id": "9beb5d5e-266d-43bc-9a38-7804d82c8361",
        "text": "Content of the previous chunk for context: h1: Generating OpenAI GPT3 completions h2: Create edge function [\\#](\\#create-edge-function)\n\nNote that we are setting `stream` to `false` which will wait until the entire response is complete before returning. If you wish to stream GPT's response word-by-word back to your client, set `stream` to `true`.\n"
      }
    }
  },
  {
    "chunk_id": "9bd99ee1-e9bd-47cc-b100-54794a00f984",
    "metadata": {
      "token_count": 136,
      "source_url": "https://supabase.com/docs/guides/ai/examples/openai",
      "page_title": "Generating OpenAI GPT3 completions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generating OpenAI GPT3 completions",
        "h2": "Run locally [\\#](\\#run-locally)"
      },
      "text": "Serve the edge function locally by running:\n\n`\n1\nsupabase functions serve --env-file ./supabase/.env.local --no-verify-jwt\n`\n\nNotice how we are passing in the `.env.local` file.\n\nUse cURL or Postman to make a POST request to [http://localhost:54321/functions/v1/openai](http://localhost:54321/functions/v1/openai).\n\n`\n1\ncurl -i --location --request POST http://localhost:54321/functions/v1/openai \\\n2\n  --header 'Content-Type: application/json' \\\n3\n  --data '{\"query\":\"What is Supabase?\"}'\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "de71e734-48ca-4ffd-a535-97565768a911",
        "text": "Content of the previous chunk for context: h1: Generating OpenAI GPT3 completions h2: Create OpenAI key [\\#](\\#create-openai-key)\n\n/api-keys) and create a new secret key.\n\nAfter getting the key, copy it into a new file called `.env.local` in your `./supabase` folder:\n\n`\n1\nOPENAI_API_KEY=your-key-here\n`\n"
      }
    }
  },
  {
    "chunk_id": "1b9b69e4-0fb9-4f92-a6ce-aed8f446fb04",
    "metadata": {
      "token_count": 13,
      "source_url": "https://supabase.com/docs/guides/ai/examples/openai",
      "page_title": "Generating OpenAI GPT3 completions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generating OpenAI GPT3 completions",
        "h2": "Run locally [\\#](\\#run-locally)"
      },
      "text": "You should see a GPT response come back from OpenAI!\n",
      "overlap_text": {
        "previous_chunk_id": "9bd99ee1-e9bd-47cc-b100-54794a00f984",
        "text": "Content of the previous chunk for context: h1: Generating OpenAI GPT3 completions h2: Run locally [\\#](\\#run-locally)\n\n\ncurl -i --location --request POST http://localhost:54321/functions/v1/openai \\\n2\n  --header 'Content-Type: application/json' \\\n3\n  --data '{\"query\":\"What is Supabase?\"}'\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "17410b60-dfc7-4a13-b653-3c4743688b99",
    "metadata": {
      "token_count": 47,
      "source_url": "https://supabase.com/docs/guides/ai/examples/openai",
      "page_title": "Generating OpenAI GPT3 completions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generating OpenAI GPT3 completions",
        "h2": "Deploy [\\#](\\#deploy)"
      },
      "text": "Deploy your function to the cloud by runnning:\n\n`\n1\nsupabase functions deploy --no-verify-jwt openai\n2\nsupabase secrets set --env-file ./supabase/.env.local\n`\n",
      "overlap_text": {
        "previous_chunk_id": "1b9b69e4-0fb9-4f92-a6ce-aed8f446fb04",
        "text": "Content of the previous chunk for context: h1: Generating OpenAI GPT3 completions h2: Run locally [\\#](\\#run-locally)\n\nYou should see a GPT response come back from OpenAI!\n"
      }
    }
  },
  {
    "chunk_id": "b6eb0cc8-fe9b-4f35-bb4f-38fd24902850",
    "metadata": {
      "token_count": 131,
      "source_url": "https://supabase.com/docs/guides/ai/examples/openai",
      "page_title": "Generating OpenAI GPT3 completions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generating OpenAI GPT3 completions",
        "h2": "Go deeper [\\#](\\#go-deeper)"
      },
      "text": "If you're interesting in learning how to use this to build your own ChatGPT, read [the blog post](/blog/chatgpt-supabase-docs) and check out the video:\n\nWatch video guide\n\n![Video guide preview](https://supabase.com/docs/_next/image?url=http%3A%2F%2Fimg.youtube.com%2Fvi%2F29p8kIqyU_Y%2F0.jpg&w=3840&q=75&dpl=dpl_8T75GeYs2RqN59z5hY7ru4dxhiVp)\n\n",
      "overlap_text": {
        "previous_chunk_id": "17410b60-dfc7-4a13-b653-3c4743688b99",
        "text": "Content of the previous chunk for context: h1: Generating OpenAI GPT3 completions h2: Deploy [\\#](\\#deploy)\n\nDeploy your function to the cloud by runnning:\n\n`\n1\nsupabase functions deploy --no-verify-jwt openai\n2\nsupabase secrets set --env-file ./supabase/.env.local\n`\n"
      }
    }
  },
  {
    "chunk_id": "57344654-ec7b-4544-8c0b-ff86f55f6ac2",
    "metadata": {
      "token_count": 112,
      "source_url": "https://supabase.com/docs/guides/ai/examples/openai",
      "page_title": "Generating OpenAI GPT3 completions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generating OpenAI GPT3 completions",
        "h2": "Go deeper [\\#](\\#go-deeper)"
      },
      "text": "### Is this helpful?\n\nYesNo\n\nThanks for your feedback!\n\nOn this page\n\n- [Setup Supabase project](#setup-supabase-project)\n- [Create edge function](#create-edge-function)\n- [Create OpenAI key](#create-openai-key)\n- [Run locally](#run-locally)\n- [Deploy](#deploy)\n- [Go deeper](#go-deeper)\n\n1. We only collect analytics essential to ensuring smooth operation of our services. [Learn more](https://supabase.com/privacy)\n\n",
      "overlap_text": {
        "previous_chunk_id": "b6eb0cc8-fe9b-4f35-bb4f-38fd24902850",
        "text": "Content of the previous chunk for context: h1: Generating OpenAI GPT3 completions h2: Go deeper [\\#](\\#go-deeper)\n\n29p8kIqyU_Y%2F0.jpg&w=3840&q=75&dpl=dpl_8T75GeYs2RqN59z5hY7ru4dxhiVp)\n\n"
      }
    }
  },
  {
    "chunk_id": "5e5e8031-1e86-430f-b046-330f423d243e",
    "metadata": {
      "token_count": 18,
      "source_url": "https://supabase.com/docs/guides/ai/examples/openai",
      "page_title": "Generating OpenAI GPT3 completions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generating OpenAI GPT3 completions",
        "h2": "Go deeper [\\#](\\#go-deeper)"
      },
      "text": "\n\n\n\n   AcceptOpt out[Learn more](https://supabase.com/privacy)\n",
      "overlap_text": {
        "previous_chunk_id": "57344654-ec7b-4544-8c0b-ff86f55f6ac2",
        "text": "Content of the previous chunk for context: h1: Generating OpenAI GPT3 completions h2: Go deeper [\\#](\\#go-deeper)\n\nrun-locally)\n- [Deploy](#deploy)\n- [Go deeper](#go-deeper)\n\n1. We only collect analytics essential to ensuring smooth operation of our services. [Learn more](https://supabase.com/privacy)\n\n"
      }
    }
  },
  {
    "chunk_id": "c35f722e-e9ed-41ba-88bc-78c43f5b03c5",
    "metadata": {
      "token_count": 40,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes",
      "page_title": "IVFFlat indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "IVFFlat indexes"
      },
      "text": "* * *\n\nIVFFlat is a type of vector index for approximate nearest neighbor search. It is a frequently used index type that can improve performance when querying highly-dimensional vectors, like those representing embeddings.\n"
    }
  },
  {
    "chunk_id": "09ed180b-42f9-48d8-897f-c0c2b0abc7d1",
    "metadata": {
      "token_count": 167,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes",
      "page_title": "IVFFlat indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "IVFFlat indexes",
        "h2": "Choosing an index [\\#](\\#choosing-an-index)"
      },
      "text": "Today `pgvector` supports two types of indexes:\n\n- [HNSW](/docs/guides/ai/vector-indexes/hnsw-indexes)\n- [IVFFlat](/docs/guides/ai/vector-indexes/ivf-indexes)\n\nIn general we recommend using [HNSW](/docs/guides/ai/vector-indexes/hnsw-indexes) because of its [performance](https://supabase.com/blog/increase-performance-pgvector-hnsw#hnsw-performance-1536-dimensions) and [robustness against changing data](/docs/guides/ai/vector-indexes/hnsw-indexes#when-should-you-create-hnsw-indexes). If you have a special use case that requires IVFFlat instead, keep reading.\n",
      "overlap_text": {
        "previous_chunk_id": "c35f722e-e9ed-41ba-88bc-78c43f5b03c5",
        "text": "Content of the previous chunk for context: h1: IVFFlat indexes\n\n* * *\n\nIVFFlat is a type of vector index for approximate nearest neighbor search. It is a frequently used index type that can improve performance when querying highly-dimensional vectors, like those representing embeddings.\n"
      }
    }
  },
  {
    "chunk_id": "9c03d1ef-6577-4895-9892-9c05c5e7a2fd",
    "metadata": {
      "token_count": 107,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes",
      "page_title": "IVFFlat indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "IVFFlat indexes",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "The way you create an IVFFlat index depends on the distance operator you are using. `pgvector` includes 3 distance operators:\n\n| Operator | Description | [**Operator class**](https://www.postgresql.org/docs/current/sql-createopclass.html) |\n| --- | --- | --- |\n| `<->` | Euclidean distance | `vector_l2_ops` |\n| `<#>` | negative inner product | `vector_ip_ops` |\n| `<=>` | cosine distance | `vector_cosine_ops` |\n\n",
      "overlap_text": {
        "previous_chunk_id": "09ed180b-42f9-48d8-897f-c0c2b0abc7d1",
        "text": "Content of the previous chunk for context: h1: IVFFlat indexes h2: Choosing an index [\\#](\\#choosing-an-index)\n\nustness against changing data](/docs/guides/ai/vector-indexes/hnsw-indexes#when-should-you-create-hnsw-indexes). If you have a special use case that requires IVFFlat instead, keep reading.\n"
      }
    }
  },
  {
    "chunk_id": "0cad55e5-df67-4290-bc26-278a0cd8ecbe",
    "metadata": {
      "token_count": 102,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes",
      "page_title": "IVFFlat indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "IVFFlat indexes",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "Use the following SQL commands to create an IVFFlat index for the operator(s) used in your queries.\n\n### Euclidean L2 distance ( `vector_l2_ops`) [\\#](\\#euclidean-l2-distance--vectorl2ops-)\n\n`\n_10\ncreate index on items using ivfflat (column_name vector_l2_ops) with (lists = 100);\n`\n\n### Inner product ( `vector_ip_ops`) [\\#](\\#inner-product--vectoripops-)\n\n",
      "overlap_text": {
        "previous_chunk_id": "9c03d1ef-6577-4895-9892-9c05c5e7a2fd",
        "text": "Content of the previous chunk for context: h1: IVFFlat indexes h2: Usage [\\#](\\#usage)\n\n --- | --- |\n| `<->` | Euclidean distance | `vector_l2_ops` |\n| `<#>` | negative inner product | `vector_ip_ops` |\n| `<=>` | cosine distance | `vector_cosine_ops` |\n\n"
      }
    }
  },
  {
    "chunk_id": "93fdb3a3-dc9d-4b92-9bdf-9bd71afc1e33",
    "metadata": {
      "token_count": 95,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes",
      "page_title": "IVFFlat indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "IVFFlat indexes",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "`\n_10\ncreate index on items using ivfflat (column_name vector_ip_ops) with (lists = 100);\n`\n\n### Cosine distance ( `vector_cosine_ops`) [\\#](\\#cosine-distance--vectorcosineops-)\n\n`\n_10\ncreate index on items using ivfflat (column_name vector_cosine_ops) with (lists = 100);\n`\n\nCurrently vectors with up to 2,000 dimensions can be indexed.\n",
      "overlap_text": {
        "previous_chunk_id": "0cad55e5-df67-4290-bc26-278a0cd8ecbe",
        "text": "Content of the previous chunk for context: h1: IVFFlat indexes h2: Usage [\\#](\\#usage)\n\n`\n_10\ncreate index on items using ivfflat (column_name vector_l2_ops) with (lists = 100);\n`\n\n### Inner product ( `vector_ip_ops`) [\\#](\\#inner-product--vectoripops-)\n\n"
      }
    }
  },
  {
    "chunk_id": "927ad779-aeb0-4fe1-b940-7af2858e20bf",
    "metadata": {
      "token_count": 110,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes",
      "page_title": "IVFFlat indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "IVFFlat indexes",
        "h2": "How does IVFFlat work? [\\#](\\#how-does-ivfflat-work)"
      },
      "text": "IVF stands for 'inverted file indexes'. It works by clustering your vectors in order to reduce the similarity search scope. Rather than comparing a vector to every other vector, the vector is only compared against vectors within the same cell cluster (or nearby clusters, depending on your configuration).\n\n### Inverted lists (cell clusters) [\\#](\\#inverted-lists-cell-clusters)\n\nWhen you create the index, you choose the number of inverted lists (cell clusters). Increase this number to speed up queries, but at the expense of recall.\n",
      "overlap_text": {
        "previous_chunk_id": "93fdb3a3-dc9d-4b92-9bdf-9bd71afc1e33",
        "text": "Content of the previous chunk for context: h1: IVFFlat indexes h2: Usage [\\#](\\#usage)\n\n-distance--vectorcosineops-)\n\n`\n_10\ncreate index on items using ivfflat (column_name vector_cosine_ops) with (lists = 100);\n`\n\nCurrently vectors with up to 2,000 dimensions can be indexed.\n"
      }
    }
  },
  {
    "chunk_id": "0fcb1204-043f-421c-a2c4-babbab7f2737",
    "metadata": {
      "token_count": 111,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes",
      "page_title": "IVFFlat indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "IVFFlat indexes",
        "h2": "How does IVFFlat work? [\\#](\\#how-does-ivfflat-work)"
      },
      "text": "\nFor example, to create an index with 100 lists on a column that uses the cosine operator:\n\n`\n_10\ncreate index on items using ivfflat (column_name vector_cosine_ops) with (lists = 100);\n`\n\nFor more info on the different operators, see [Distance operations](#distance-operators).\n\nFor every query, you can set the number of probes (1 by default). The number of probes corresponds to the number of nearby cells to probe for a match. Increase this for better recall at the expense of speed.\n",
      "overlap_text": {
        "previous_chunk_id": "927ad779-aeb0-4fe1-b940-7af2858e20bf",
        "text": "Content of the previous chunk for context: h1: IVFFlat indexes h2: How does IVFFlat work? [\\#](\\#how-does-ivfflat-work)\n\n lists (cell clusters) [\\#](\\#inverted-lists-cell-clusters)\n\nWhen you create the index, you choose the number of inverted lists (cell clusters). Increase this number to speed up queries, but at the expense of recall.\n"
      }
    }
  },
  {
    "chunk_id": "743bde5d-66b8-483a-ac7b-78d3b935e195",
    "metadata": {
      "token_count": 104,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes",
      "page_title": "IVFFlat indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "IVFFlat indexes",
        "h2": "How does IVFFlat work? [\\#](\\#how-does-ivfflat-work)"
      },
      "text": "\nTo set the number of probes for the duration of the session run:\n\n`\n_10\nset ivfflat.probes = 10;\n`\n\nTo set the number of probes only for the current transaction run:\n\n`\n_10\nbegin;\n_10\nset local ivfflat.probes = 10;\n_10\nselect ...\n_10\ncommit;\n`\n\nIf the number of probes is the same as the number of lists, exact nearest neighbor search will be performed and the planner won't use the index.\n",
      "overlap_text": {
        "previous_chunk_id": "0fcb1204-043f-421c-a2c4-babbab7f2737",
        "text": "Content of the previous chunk for context: h1: IVFFlat indexes h2: How does IVFFlat work? [\\#](\\#how-does-ivfflat-work)\n\n](#distance-operators).\n\nFor every query, you can set the number of probes (1 by default). The number of probes corresponds to the number of nearby cells to probe for a match. Increase this for better recall at the expense of speed.\n"
      }
    }
  },
  {
    "chunk_id": "fcf2ac79-7f24-4108-a101-e9309aa645d7",
    "metadata": {
      "token_count": 69,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes",
      "page_title": "IVFFlat indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "IVFFlat indexes",
        "h2": "How does IVFFlat work? [\\#](\\#how-does-ivfflat-work)"
      },
      "text": "\n### Approximate nearest neighbor [\\#](\\#approximate-nearest-neighbor)\n\nOne important note with IVF indexes is that nearest neighbor search is approximate, since exact search on high dimensional data can't be indexed efficiently. This means that similarity results will change (slightly) after you add an index (trading recall for speed).\n",
      "overlap_text": {
        "previous_chunk_id": "743bde5d-66b8-483a-ac7b-78d3b935e195",
        "text": "Content of the previous chunk for context: h1: IVFFlat indexes h2: How does IVFFlat work? [\\#](\\#how-does-ivfflat-work)\n\n ivfflat.probes = 10;\n_10\nselect ...\n_10\ncommit;\n`\n\nIf the number of probes is the same as the number of lists, exact nearest neighbor search will be performed and the planner won't use the index.\n"
      }
    }
  },
  {
    "chunk_id": "7eb25dcb-8e83-4a59-9feb-e9fab636e56a",
    "metadata": {
      "token_count": 46,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes",
      "page_title": "IVFFlat indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "IVFFlat indexes",
        "h2": "When should you create IVFFlat indexes? [\\#](\\#when-should-you-create-ivfflat-indexes)"
      },
      "text": "`pgvector` recommends building IVFFlat indexes only after the table has sufficient data, so that the internal IVFFlat cell clusters are based on your data's distribution. Anytime the distribution changes significantly, consider rebuilding indexes.\n",
      "overlap_text": {
        "previous_chunk_id": "fcf2ac79-7f24-4108-a101-e9309aa645d7",
        "text": "Content of the previous chunk for context: h1: IVFFlat indexes h2: How does IVFFlat work? [\\#](\\#how-does-ivfflat-work)\n\n important note with IVF indexes is that nearest neighbor search is approximate, since exact search on high dimensional data can't be indexed efficiently. This means that similarity results will change (slightly) after you add an index (trading recall for speed).\n"
      }
    }
  },
  {
    "chunk_id": "0b8917c0-d51f-4b8d-b59e-8e129a3c2765",
    "metadata": {
      "token_count": 26,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes/ivf-indexes",
      "page_title": "IVFFlat indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "IVFFlat indexes",
        "h2": "Resources [\\#](\\#resources)"
      },
      "text": "Read more about indexing on `pgvector`'s [GitHub page](https://github.com/pgvector/pgvector#indexing).\n",
      "overlap_text": {
        "previous_chunk_id": "7eb25dcb-8e83-4a59-9feb-e9fab636e56a",
        "text": "Content of the previous chunk for context: h1: IVFFlat indexes h2: When should you create IVFFlat indexes? [\\#](\\#when-should-you-create-ivfflat-indexes)\n\n`pgvector` recommends building IVFFlat indexes only after the table has sufficient data, so that the internal IVFFlat cell clusters are based on your data's distribution. Anytime the distribution changes significantly, consider rebuilding indexes.\n"
      }
    }
  },
  {
    "chunk_id": "d6629a87-9e1c-4af7-8d74-8423a86241ed",
    "metadata": {
      "token_count": 124,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Fine-grain access control with Retrieval Augmented Generation."
      },
      "text": "* * *\n\nSince pgvector is built on top of Postgres, you can implement fine-grain access control on your vector database using [Row Level Security (RLS)](/docs/guides/database/postgres/row-level-security). This means you can restrict which documents are returned during a vector similarity search to users that have access to them. Supabase also supports [Foreign Data Wrappers (FDW)](/docs/guides/database/extensions/wrappers/overview) which means you can use an external database or data source to determine these permissions if your user data doesn't exist in Supabase.\n"
    }
  },
  {
    "chunk_id": "926b9c1c-55b3-47bb-9f87-4cc0ed91979d",
    "metadata": {
      "token_count": 21,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Fine-grain access control with Retrieval Augmented Generation."
      },
      "text": "\nUse this guide to learn how to restrict access to documents when performing retrieval augmented generation (RAG).\n",
      "overlap_text": {
        "previous_chunk_id": "d6629a87-9e1c-4af7-8d74-8423a86241ed",
        "text": "Content of the previous chunk for context: h1: RAG with Permissions h2: Fine-grain access control with Retrieval Augmented Generation.\n\n supports [Foreign Data Wrappers (FDW)](/docs/guides/database/extensions/wrappers/overview) which means you can use an external database or data source to determine these permissions if your user data doesn't exist in Supabase.\n"
      }
    }
  },
  {
    "chunk_id": "85ee1045-f300-4930-b1c9-fe56c16583f4",
    "metadata": {
      "token_count": 187,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Example [\\#](\\#example)"
      },
      "text": "In a typical RAG setup, your documents are chunked into small subsections and similarity is performed over those sections:\n\n`\n_16\n-- Track documents/pages/files/etc\n_16\ncreate table documents (\n_16\nid bigint primary key generated always as identity,\n_16\nname text not null,\n_16\nowner_id uuid not null references auth.users (id) default auth.uid(),\n_16\ncreated_at timestamp with time zone not null default now()\n_16\n);\n_16\n_16\n-- Store the content and embedding vector for each section in the document\n_16\n-- with a reference to original document (one-to-many)\n_16\ncreate table document_sections (\n_16\nid bigint primary key generated always as identity,\n_16\ndocument_id bigint not null references documents (id),\n_16\ncontent text not null,\n_16\nembedding vector (384)\n_16\n);\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "926b9c1c-55b3-47bb-9f87-4cc0ed91979d",
        "text": "Content of the previous chunk for context: h1: RAG with Permissions h2: Fine-grain access control with Retrieval Augmented Generation.\n\n\nUse this guide to learn how to restrict access to documents when performing retrieval augmented generation (RAG).\n"
      }
    }
  },
  {
    "chunk_id": "e9ac44e0-cf17-4290-9284-bd139bcd171e",
    "metadata": {
      "token_count": 146,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Example [\\#](\\#example)"
      },
      "text": "Notice how we record the `owner_id` on each document. Let's create an RLS policy that restricts access to `document_sections` based on whether or not they own the linked document:\n\n`\n_12\n-- enable row level security\n_12\nalter table document_sections enable row level security;\n_12\n_12\n-- setup RLS for select operations\n_12\ncreate policy \"Users can query their own document sections\"\n_12\non document_sections for select to authenticated using (\n_12\ndocument_id in (\n_12\n    select id\n_12\n    from documents\n_12\n    where (owner_id = (select auth.uid()))\n_12\n)\n_12\n);\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "85ee1045-f300-4930-b1c9-fe56c16583f4",
        "text": "Content of the previous chunk for context: h1: RAG with Permissions h2: Example [\\#](\\#example)\n\n table document_sections (\n_16\nid bigint primary key generated always as identity,\n_16\ndocument_id bigint not null references documents (id),\n_16\ncontent text not null,\n_16\nembedding vector (384)\n_16\n);\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "26e9bff2-d8c5-4e72-a1ee-52718dd2b121",
    "metadata": {
      "token_count": 114,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Example [\\#](\\#example)"
      },
      "text": "In this example, the current user is determined using the built-in `auth.uid()` function when the query is executed through your project's auto-generated [REST API](/docs/guides/api). If you are connecting to your Supabase database through a direct Postgres connection, see [Direct Postgres Connection](#direct-postgres-connection) below for directions on how to achieve the same access control.\n\nNow every `select` query executed on `document_sections` will implicitly filter the returned sections based on whether or not the current user has access to them.\n",
      "overlap_text": {
        "previous_chunk_id": "e9ac44e0-cf17-4290-9284-bd139bcd171e",
        "text": "Content of the previous chunk for context: h1: RAG with Permissions h2: Example [\\#](\\#example)\n\n for select to authenticated using (\n_12\ndocument_id in (\n_12\n    select id\n_12\n    from documents\n_12\n    where (owner_id = (select auth.uid()))\n_12\n)\n_12\n);\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "48775db8-dfa3-4f79-8f91-4d1a1dbfd531",
    "metadata": {
      "token_count": 122,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Example [\\#](\\#example)"
      },
      "text": "\nFor example, executing:\n\n`\n_10\nselect * from document_sections;\n`\n\nas an authenticated user will only return rows that they are the owner of (as determined by the linked document). More importantly, semantic search over these sections (or any additional filtering for that matter) will continue to respect these RLS policies:\n\n`\n_10\n-- Perform inner product similarity based on a match_threshold\n_10\nselect *\n_10\nfrom document_sections\n_10\nwhere document_sections.embedding <#> embedding < -match_threshold\n_10\norder by document_sections.embedding <#> embedding;\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "26e9bff2-d8c5-4e72-a1ee-52718dd2b121",
        "text": "Content of the previous chunk for context: h1: RAG with Permissions h2: Example [\\#](\\#example)\n\n#direct-postgres-connection) below for directions on how to achieve the same access control.\n\nNow every `select` query executed on `document_sections` will implicitly filter the returned sections based on whether or not the current user has access to them.\n"
      }
    }
  },
  {
    "chunk_id": "893443c0-ea1e-4e5e-90fe-77c0ba3161e5",
    "metadata": {
      "token_count": 74,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Example [\\#](\\#example)"
      },
      "text": "The above example only configures `select` access to users. If you wanted, you could create more RLS policies for inserts, updates, and deletes in order to apply the same permission logic for those other operations. See [Row Level Security](/docs/guides/database/postgres/row-level-security) for a more in-depth guide on RLS policies.\n",
      "overlap_text": {
        "previous_chunk_id": "48775db8-dfa3-4f79-8f91-4d1a1dbfd531",
        "text": "Content of the previous chunk for context: h1: RAG with Permissions h2: Example [\\#](\\#example)\n\n product similarity based on a match_threshold\n_10\nselect *\n_10\nfrom document_sections\n_10\nwhere document_sections.embedding <#> embedding < -match_threshold\n_10\norder by document_sections.embedding <#> embedding;\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "d23cbf1e-e43b-4ace-b1ca-a5371458a619",
    "metadata": {
      "token_count": 153,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Alternative scenarios [\\#](\\#alternative-scenarios)"
      },
      "text": "Every app has its own unique requirements and may differ from the above example. Here are some alternative scenarios we often see and how they are implemented in Supabase.\n\n### Documents owned by multiple people [\\#](\\#documents-owned-by-multiple-people)\n\nInstead of a one-to-many relationship between `users` and `documents`, you may require a many-to-many relationship so that multiple people can access the same document. Let's reimplement this using a join table:\n\n`\n_10\ncreate table document_owners (\n_10\nid bigint primary key generated always as identity,\n_10\nowner_id uuid not null references auth.users (id) default auth.uid(),\n_10\ndocument_id bigint not null references documents (id)\n_10\n);\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "893443c0-ea1e-4e5e-90fe-77c0ba3161e5",
        "text": "Content of the previous chunk for context: h1: RAG with Permissions h2: Example [\\#](\\#example)\n\n for inserts, updates, and deletes in order to apply the same permission logic for those other operations. See [Row Level Security](/docs/guides/database/postgres/row-level-security) for a more in-depth guide on RLS policies.\n"
      }
    }
  },
  {
    "chunk_id": "884fcde5-b786-46b4-977a-5c200ac862e9",
    "metadata": {
      "token_count": 127,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Alternative scenarios [\\#](\\#alternative-scenarios)"
      },
      "text": "Then your RLS policy would change to:\n\n`\n_10\ncreate policy \"Users can query their own document sections\"\n_10\non document_sections for select to authenticated using (\n_10\ndocument_id in (\n_10\n    select document_id\n_10\n    from document_owners\n_10\n    where (owner_id = (select auth.uid()))\n_10\n)\n_10\n);\n`\n\nInstead of directly querying the `documents` table, we query the join table.\n\n### User and document data live outside of Supabase [\\#](\\#user-and-document-data-live-outside-of-supabase)\n\n",
      "overlap_text": {
        "previous_chunk_id": "d23cbf1e-e43b-4ace-b1ca-a5371458a619",
        "text": "Content of the previous chunk for context: h1: RAG with Permissions h2: Alternative scenarios [\\#](\\#alternative-scenarios)\n\nowners (\n_10\nid bigint primary key generated always as identity,\n_10\nowner_id uuid not null references auth.users (id) default auth.uid(),\n_10\ndocument_id bigint not null references documents (id)\n_10\n);\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "a18b4e23-3f14-428e-94bf-d9042d970a29",
    "metadata": {
      "token_count": 144,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Alternative scenarios [\\#](\\#alternative-scenarios)"
      },
      "text": "You may have an existing system that stores users, documents, and their permissions in a separate database. Let's explore the scenario where this data exists in another Postgres database. We'll use a foreign data wrapper (FDW) to connect to the external DB from within your Supabase DB:\n\nRLS is latency-sensitive, so extra caution should be taken before implementing this method. Use the [query plan analyzer](https://supabase.com/docs/guides/platform/performance#optimizing-poor-performing-queries) to measure execution times for your queries to ensure they are within expected ranges. For enterprise applications, contact [enterprise@supabase.io](mailto:enterprise@supabase.io).\n",
      "overlap_text": {
        "previous_chunk_id": "884fcde5-b786-46b4-977a-5c200ac862e9",
        "text": "Content of the previous chunk for context: h1: RAG with Permissions h2: Alternative scenarios [\\#](\\#alternative-scenarios)\n\n)\n_10\n);\n`\n\nInstead of directly querying the `documents` table, we query the join table.\n\n### User and document data live outside of Supabase [\\#](\\#user-and-document-data-live-outside-of-supabase)\n\n"
      }
    }
  },
  {
    "chunk_id": "1b9397cb-abef-4e9c-86f5-b49a8992f95f",
    "metadata": {
      "token_count": 207,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Alternative scenarios [\\#](\\#alternative-scenarios)"
      },
      "text": "\nFor data sources other than Postgres, see [Foreign Data Wrappers](/docs/guides/database/extensions/wrappers/overview) for a list of external sources supported today. If your data lives in a source not provided in the list, please contact [support](https://supabase.com/dashboard/support/new) and we'll be happy to discuss your use case.\n\nLet's assume your external DB contains a `users` and `documents` table like this:\n\n`\n_12\ncreate table public.users (\n_12\nid bigint primary key generated always as identity,\n_12\nemail text not null,\n_12\ncreated_at timestamp with time zone not null default now()\n_12\n);\n_12\n_12\ncreate table public.documents (\n_12\nid bigint primary key generated always as identity,\n_12\nname text not null,\n_12\nowner_id bigint not null references public.users (id),\n_12\ncreated_at timestamp with time zone not null default now()\n_12\n);\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "a18b4e23-3f14-428e-94bf-d9042d970a29",
        "text": "Content of the previous chunk for context: h1: RAG with Permissions h2: Alternative scenarios [\\#](\\#alternative-scenarios)\n\n/platform/performance#optimizing-poor-performing-queries) to measure execution times for your queries to ensure they are within expected ranges. For enterprise applications, contact [enterprise@supabase.io](mailto:enterprise@supabase.io).\n"
      }
    }
  },
  {
    "chunk_id": "7621fc69-0b5a-4139-869a-dc05b2861cc9",
    "metadata": {
      "token_count": 187,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Alternative scenarios [\\#](\\#alternative-scenarios)"
      },
      "text": "In your Supabase DB, let's create foreign tables that link to the above tables:\n\n`\n_16\ncreate schema external;\n_16\ncreate extension postgres_fdw with schema extensions;\n_16\n_16\n-- Setup the foreign server\n_16\ncreate server foreign_server\n_16\nforeign data wrapper postgres_fdw\n_16\noptions (host '<db-host>', port '<db-port>', dbname '<db-name>');\n_16\n_16\n-- Map local 'authenticated' role to external 'postgres' user\n_16\ncreate user mapping for authenticated\n_16\nserver foreign_server\n_16\noptions (user 'postgres', password '<user-password>');\n_16\n_16\n-- Import foreign 'users' and 'documents' tables into 'external' schema\n_16\nimport foreign schema public limit to (users, documents)\n_16\nfrom server foreign_server into external;\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "1b9397cb-abef-4e9c-86f5-b49a8992f95f",
        "text": "Content of the previous chunk for context: h1: RAG with Permissions h2: Alternative scenarios [\\#](\\#alternative-scenarios)\n\nid bigint primary key generated always as identity,\n_12\nname text not null,\n_12\nowner_id bigint not null references public.users (id),\n_12\ncreated_at timestamp with time zone not null default now()\n_12\n);\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "e287ae23-3c3e-4a4d-aece-5a54768cb327",
    "metadata": {
      "token_count": 135,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Alternative scenarios [\\#](\\#alternative-scenarios)"
      },
      "text": "This example maps the `authenticated` role in Supabase to the `postgres` user in the external DB. In production, it's best to create a custom user on the external DB that has the minimum permissions necessary to access the information you need.\n\nOn the Supabase DB, we use the built-in `authenticated` role which is automatically used when end users make authenticated requests over your auto-generated REST API. If you plan to connect to your Supabase DB over a direct Postgres connection instead of the REST API, you can change this to any user you like. See [Direct Postgres Connection](#direct-postgres-connection) for more info.\n",
      "overlap_text": {
        "previous_chunk_id": "7621fc69-0b5a-4139-869a-dc05b2861cc9",
        "text": "Content of the previous chunk for context: h1: RAG with Permissions h2: Alternative scenarios [\\#](\\#alternative-scenarios)\n\n-password>');\n_16\n_16\n-- Import foreign 'users' and 'documents' tables into 'external' schema\n_16\nimport foreign schema public limit to (users, documents)\n_16\nfrom server foreign_server into external;\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "61e156aa-54b4-4b3f-bfec-9de11a4d39f0",
    "metadata": {
      "token_count": 127,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Alternative scenarios [\\#](\\#alternative-scenarios)"
      },
      "text": "\nWe'll store `document_sections` and their embeddings in Supabase so that we can perform similarity search over them via pgvector.\n\n`\n_10\ncreate table document_sections (\n_10\nid bigint primary key generated always as identity,\n_10\ndocument_id bigint not null,\n_10\ncontent text not null,\n_10\nembedding vector (384)\n_10\n);\n`\n\nWe maintain a reference to the foreign document via `document_id`, but without a foreign key reference since foreign keys can only be added to local tables. Be sure to use the same ID data type that you use on your external documents table.\n",
      "overlap_text": {
        "previous_chunk_id": "e287ae23-3c3e-4a4d-aece-5a54768cb327",
        "text": "Content of the previous chunk for context: h1: RAG with Permissions h2: Alternative scenarios [\\#](\\#alternative-scenarios)\n\n you plan to connect to your Supabase DB over a direct Postgres connection instead of the REST API, you can change this to any user you like. See [Direct Postgres Connection](#direct-postgres-connection) for more info.\n"
      }
    }
  },
  {
    "chunk_id": "03cee4fb-b706-4430-b3be-ea6f0d66a3b0",
    "metadata": {
      "token_count": 132,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Alternative scenarios [\\#](\\#alternative-scenarios)"
      },
      "text": "\nSince we're managing users and authentication outside of Supabase, we have two options:\n\n1. Make a direct Postgres connection to the Supabase DB and set the current user every request\n2. Issue a custom JWT from your system and use it to authenticate with the REST API\n\n#### Direct Postgres connection [\\#](\\#direct-postgres-connection)\n\nYou can directly connect to your Supabase Postgres DB using the [connection info](/dashboard/project/_/settings/database) on your project's database settings page. To use RLS with this method, we use a custom session variable that contains the current user's ID:\n",
      "overlap_text": {
        "previous_chunk_id": "61e156aa-54b4-4b3f-bfec-9de11a4d39f0",
        "text": "Content of the previous chunk for context: h1: RAG with Permissions h2: Alternative scenarios [\\#](\\#alternative-scenarios)\n\n);\n`\n\nWe maintain a reference to the foreign document via `document_id`, but without a foreign key reference since foreign keys can only be added to local tables. Be sure to use the same ID data type that you use on your external documents table.\n"
      }
    }
  },
  {
    "chunk_id": "4c4758a6-5a31-49d8-b0c4-9129cc014ab2",
    "metadata": {
      "token_count": 113,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Alternative scenarios [\\#](\\#alternative-scenarios)"
      },
      "text": "\n`\n_12\n-- enable row level security\n_12\nalter table document_sections enable row level security;\n_12\n_12\n-- setup RLS for select operations\n_12\ncreate policy \"Users can query their own document sections\"\n_12\non document_sections for select to authenticated using (\n_12\ndocument_id in (\n_12\n    select id\n_12\n    from external.documents\n_12\n    where owner_id = current_setting('app.current_user_id')::bigint\n_12\n)\n_12\n);\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "03cee4fb-b706-4430-b3be-ea6f0d66a3b0",
        "text": "Content of the previous chunk for context: h1: RAG with Permissions h2: Alternative scenarios [\\#](\\#alternative-scenarios)\n\n Supabase Postgres DB using the [connection info](/dashboard/project/_/settings/database) on your project's database settings page. To use RLS with this method, we use a custom session variable that contains the current user's ID:\n"
      }
    }
  },
  {
    "chunk_id": "f8365e92-8830-4266-bab6-70c17039fa93",
    "metadata": {
      "token_count": 105,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Alternative scenarios [\\#](\\#alternative-scenarios)"
      },
      "text": "The session variable is accessed through the `current_setting()` function. We name the variable `app.current_user_id` here, but you can modify this to any name you like. We also cast it to a `bigint` since that was the data type of the `user.id` column. Change this to whatever data type you use for your ID.\n\nNow for every request, we set the user's ID at the beginning of the session:\n\n`\n_10\nset app.current_user_id = '<current-user-id>';\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "4c4758a6-5a31-49d8-b0c4-9129cc014ab2",
        "text": "Content of the previous chunk for context: h1: RAG with Permissions h2: Alternative scenarios [\\#](\\#alternative-scenarios)\n\n_12\ndocument_id in (\n_12\n    select id\n_12\n    from external.documents\n_12\n    where owner_id = current_setting('app.current_user_id')::bigint\n_12\n)\n_12\n);\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "ea697c57-03ee-4b43-b87f-7467e66d3ede",
    "metadata": {
      "token_count": 123,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Alternative scenarios [\\#](\\#alternative-scenarios)"
      },
      "text": "Then all subsequent queries will inherit the permission of that user:\n\n`\n_10\n-- Only document sections owned by the user are returned\n_10\nselect *\n_10\nfrom document_sections\n_10\nwhere document_sections.embedding <#> embedding < -match_threshold\n_10\norder by document_sections.embedding <#> embedding;\n`\n\nYou might be tempted to discard RLS completely and simply filter by user within the `where` clause. Though this will work, we recommend RLS as a general best practice since RLS is always applied even as new queries and application logic is introduced in the future.\n",
      "overlap_text": {
        "previous_chunk_id": "f8365e92-8830-4266-bab6-70c17039fa93",
        "text": "Content of the previous chunk for context: h1: RAG with Permissions h2: Alternative scenarios [\\#](\\#alternative-scenarios)\n\n.id` column. Change this to whatever data type you use for your ID.\n\nNow for every request, we set the user's ID at the beginning of the session:\n\n`\n_10\nset app.current_user_id = '<current-user-id>';\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "53b4410f-a74c-4507-9009-181c9b5dcc55",
    "metadata": {
      "token_count": 112,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Alternative scenarios [\\#](\\#alternative-scenarios)"
      },
      "text": "\n#### Custom JWT with REST API [\\#](\\#custom-jwt-with-rest-api)\n\nIf you would like to use the auto-generated REST API to query your Supabase database using JWTs from an external auth provider, you can get your auth provider to issue a custom JWT for Supabase.\n\nSee the [Clerk Supabase docs](https://clerk.com/docs/integrations/databases/supabase) for an example of how this can be done. Modify the instructions to work with your own auth provider as needed.\n",
      "overlap_text": {
        "previous_chunk_id": "ea697c57-03ee-4b43-b87f-7467e66d3ede",
        "text": "Content of the previous chunk for context: h1: RAG with Permissions h2: Alternative scenarios [\\#](\\#alternative-scenarios)\n\n to discard RLS completely and simply filter by user within the `where` clause. Though this will work, we recommend RLS as a general best practice since RLS is always applied even as new queries and application logic is introduced in the future.\n"
      }
    }
  },
  {
    "chunk_id": "5d65434c-a396-48fb-b6b0-fadce6dd85ec",
    "metadata": {
      "token_count": 122,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Alternative scenarios [\\#](\\#alternative-scenarios)"
      },
      "text": "\nNow we can simply use the same RLS policy from our first example:\n\n`\n_12\n-- enable row level security\n_12\nalter table document_sections enable row level security;\n_12\n_12\n-- setup RLS for select operations\n_12\ncreate policy \"Users can query their own document sections\"\n_12\non document_sections for select to authenticated using (\n_12\ndocument_id in (\n_12\n    select id\n_12\n    from documents\n_12\n    where (owner_id = (select auth.uid()))\n_12\n)\n_12\n);\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "53b4410f-a74c-4507-9009-181c9b5dcc55",
        "text": "Content of the previous chunk for context: h1: RAG with Permissions h2: Alternative scenarios [\\#](\\#alternative-scenarios)\n\nSee the [Clerk Supabase docs](https://clerk.com/docs/integrations/databases/supabase) for an example of how this can be done. Modify the instructions to work with your own auth provider as needed.\n"
      }
    }
  },
  {
    "chunk_id": "91532258-cbc5-4a29-af1c-0e2bd52ad7d1",
    "metadata": {
      "token_count": 118,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Alternative scenarios [\\#](\\#alternative-scenarios)"
      },
      "text": "Under the hood, `auth.uid()` references `current_setting('request.jwt.claim.sub')` which corresponds to the JWT's `sub` (subject) claim. This setting is automatically set at the beginning of each request to the REST API.\n\nAll subsequent queries will inherit the permission of that user:\n\n`\n_10\n-- Only document sections owned by the user are returned\n_10\nselect *\n_10\nfrom document_sections\n_10\nwhere document_sections.embedding <#> embedding < -match_threshold\n_10\norder by document_sections.embedding <#> embedding;\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "5d65434c-a396-48fb-b6b0-fadce6dd85ec",
        "text": "Content of the previous chunk for context: h1: RAG with Permissions h2: Alternative scenarios [\\#](\\#alternative-scenarios)\n\n for select to authenticated using (\n_12\ndocument_id in (\n_12\n    select id\n_12\n    from documents\n_12\n    where (owner_id = (select auth.uid()))\n_12\n)\n_12\n);\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "2c9eecad-8a9c-4b47-a855-80d60142e80c",
    "metadata": {
      "token_count": 102,
      "source_url": "https://supabase.com/docs/guides/ai/rag-with-permissions",
      "page_title": "RAG with Permissions | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "RAG with Permissions",
        "h2": "Alternative scenarios [\\#](\\#alternative-scenarios)"
      },
      "text": "### Other scenarios [\\#](\\#other-scenarios)\n\nThere are endless approaches to this problem based on the complexities of each system. Luckily Postgres comes with all the primitives needed to provide access control in the way that works best for your project.\n\nIf the examples above didn't fit your use case or you need to adjust them slightly to better fit your existing system, feel free to reach out to [support](https://supabase.com/dashboard/support/new) and we'll be happy to assist you.\n",
      "overlap_text": {
        "previous_chunk_id": "91532258-cbc5-4a29-af1c-0e2bd52ad7d1",
        "text": "Content of the previous chunk for context: h1: RAG with Permissions h2: Alternative scenarios [\\#](\\#alternative-scenarios)\n\n sections owned by the user are returned\n_10\nselect *\n_10\nfrom document_sections\n_10\nwhere document_sections.embedding <#> embedding < -match_threshold\n_10\norder by document_sections.embedding <#> embedding;\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "ed5fbb9d-cb81-493e-bc57-33882a35cd9a",
    "metadata": {
      "token_count": 67,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/roboflow",
      "page_title": "Roboflow | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Roboflow",
        "h2": "Learn how to integrate Supabase with Roboflow, a tool for running fine-tuned and foundation vision models."
      },
      "text": "* * *\n\nIn this guide, we will walk through two examples of using [Roboflow Inference](https://inference.roboflow.com) to run fine-tuned and foundation models. We will run inference and save predictions using an object detection model and [CLIP](https://github.com/openai/CLIP).\n"
    }
  },
  {
    "chunk_id": "5cac1f96-cc1d-420b-8f46-b8151d468385",
    "metadata": {
      "token_count": 102,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/roboflow",
      "page_title": "Roboflow | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Roboflow",
        "h2": "Project setup [\\#](\\#project-setup)"
      },
      "text": "Let's create a new Postgres database. This is as simple as starting a new Project in Supabase:\n\n1. [Create a new project](https://database.new/) in the Supabase dashboard.\n2. Enter your project details. Remember to store your password somewhere safe.\n\nYour database will be available in less than a minute.\n\n**Finding your credentials:**\n\nYou can find your project credentials inside the project [settings](https://supabase.com/dashboard/project/_/settings/), including:\n",
      "overlap_text": {
        "previous_chunk_id": "ed5fbb9d-cb81-493e-bc57-33882a35cd9a",
        "text": "Content of the previous chunk for context: h1: Roboflow h2: Learn how to integrate Supabase with Roboflow, a tool for running fine-tuned and foundation vision models.\n\noflow Inference](https://inference.roboflow.com) to run fine-tuned and foundation models. We will run inference and save predictions using an object detection model and [CLIP](https://github.com/openai/CLIP).\n"
      }
    }
  },
  {
    "chunk_id": "598af236-dba8-4fb2-9d0e-5944fb45618f",
    "metadata": {
      "token_count": 61,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/roboflow",
      "page_title": "Roboflow | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Roboflow",
        "h2": "Project setup [\\#](\\#project-setup)"
      },
      "text": "\n- [Database credentials](https://supabase.com/dashboard/project/_/settings/database): connection strings and connection pooler details.\n- [API credentials](https://supabase.com/dashboard/project/_/settings/database): your serverless API URL and `anon` / `service_role` keys.\n",
      "overlap_text": {
        "previous_chunk_id": "5cac1f96-cc1d-420b-8f46-b8151d468385",
        "text": "Content of the previous chunk for context: h1: Roboflow h2: Project setup [\\#](\\#project-setup)\n\n store your password somewhere safe.\n\nYour database will be available in less than a minute.\n\n**Finding your credentials:**\n\nYou can find your project credentials inside the project [settings](https://supabase.com/dashboard/project/_/settings/), including:\n"
      }
    }
  },
  {
    "chunk_id": "ffdaf8ce-b479-422c-95a6-a5430967c069",
    "metadata": {
      "token_count": 152,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/roboflow",
      "page_title": "Roboflow | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Roboflow",
        "h2": "Save computer vision predictions [\\#](\\#save-computer-vision-predictions)"
      },
      "text": "Once you have a trained vision model, you need to create business logic for your application. In many cases, you want to save inference results to a file.\n\nThe steps below show you how to run a vision model locally and save predictions to Supabase.\n\n### Preparation: Set up a model [\\#](\\#preparation-set-up-a-model)\n\nBefore you begin, you will need an object detection model trained on your data.\n\nYou can [train a model on Roboflow](https://blog.roboflow.com/getting-started-with-roboflow/), leveraging end-to-end tools from data management and annotation to deployment, or [upload custom model weights](https://docs.roboflow.com/deploy/upload-custom-weights) for deployment.\n",
      "overlap_text": {
        "previous_chunk_id": "598af236-dba8-4fb2-9d0e-5944fb45618f",
        "text": "Content of the previous chunk for context: h1: Roboflow h2: Project setup [\\#](\\#project-setup)\n\n.com/dashboard/project/_/settings/database): connection strings and connection pooler details.\n- [API credentials](https://supabase.com/dashboard/project/_/settings/database): your serverless API URL and `anon` / `service_role` keys.\n"
      }
    }
  },
  {
    "chunk_id": "76c4ef53-89ae-4996-b5e9-d57e6071e678",
    "metadata": {
      "token_count": 114,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/roboflow",
      "page_title": "Roboflow | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Roboflow",
        "h2": "Save computer vision predictions [\\#](\\#save-computer-vision-predictions)"
      },
      "text": "\nAll models have an infinitely scalable API through which you can query your model, and can be run locally.\n\nFor this guide, we will use a demo [rock, paper, scissors](https://universe.roboflow.com/roboflow-58fyf/rock-paper-scissors-sxsw) model.\n\n### Step 1: Install and start Roboflow Inference [\\#](\\#step-1-install-and-start-roboflow-inference)\n\nYou will deploy our model locally using Roboflow Inference, a computer vision inference server.\n",
      "overlap_text": {
        "previous_chunk_id": "ffdaf8ce-b479-422c-95a6-a5430967c069",
        "text": "Content of the previous chunk for context: h1: Roboflow h2: Save computer vision predictions [\\#](\\#save-computer-vision-predictions)\n\nboflow.com/getting-started-with-roboflow/), leveraging end-to-end tools from data management and annotation to deployment, or [upload custom model weights](https://docs.roboflow.com/deploy/upload-custom-weights) for deployment.\n"
      }
    }
  },
  {
    "chunk_id": "2e7d3d98-00b4-4982-be48-d5a9f0c603ee",
    "metadata": {
      "token_count": 107,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/roboflow",
      "page_title": "Roboflow | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Roboflow",
        "h2": "Save computer vision predictions [\\#](\\#save-computer-vision-predictions)"
      },
      "text": "\nTo install and start Roboflow Inference, first install Docker on your machine.\n\nThen, run:\n\n`\n_10\npip install inference inference-cli inference-sdk && inference server start\n`\n\nAn inference server will be available at `http://localhost:9001`.\n\n### Step 2: Run inference on an image [\\#](\\#step-2-run-inference-on-an-image)\n\nYou can run inference on images and videos. Let's run inference on an image.\n\nCreate a new Python file and add the following code:\n",
      "overlap_text": {
        "previous_chunk_id": "76c4ef53-89ae-4996-b5e9-d57e6071e678",
        "text": "Content of the previous chunk for context: h1: Roboflow h2: Save computer vision predictions [\\#](\\#save-computer-vision-predictions)\n\n.\n\n### Step 1: Install and start Roboflow Inference [\\#](\\#step-1-install-and-start-roboflow-inference)\n\nYou will deploy our model locally using Roboflow Inference, a computer vision inference server.\n"
      }
    }
  },
  {
    "chunk_id": "a8ca21ef-a67d-494e-831b-827c3f58fdfb",
    "metadata": {
      "token_count": 120,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/roboflow",
      "page_title": "Roboflow | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Roboflow",
        "h2": "Save computer vision predictions [\\#](\\#save-computer-vision-predictions)"
      },
      "text": "\n`\n_13\nfrom inference_sdk import InferenceHTTPClient\n_13\n_13\nimage = \"example.jpg\"\n_13\nMODEL_ID = \"rock-paper-scissors-sxsw/11\"\n_13\n_13\nclient = InferenceHTTPClient(\n_13\n    api_url=\"http://localhost:9001\",\n_13\n    api_key=\"ROBOFLOW_API_KEY\"\n_13\n)\n_13\nwith client.use_model(MODEL_ID):\n_13\n    predictions = client.infer(image)\n_13\n_13\nprint(predictions)\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "2e7d3d98-00b4-4982-be48-d5a9f0c603ee",
        "text": "Content of the previous chunk for context: h1: Roboflow h2: Save computer vision predictions [\\#](\\#save-computer-vision-predictions)\n\n2: Run inference on an image [\\#](\\#step-2-run-inference-on-an-image)\n\nYou can run inference on images and videos. Let's run inference on an image.\n\nCreate a new Python file and add the following code:\n"
      }
    }
  },
  {
    "chunk_id": "71d487ca-7fba-4247-939e-12c94d25eae0",
    "metadata": {
      "token_count": 106,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/roboflow",
      "page_title": "Roboflow | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Roboflow",
        "h2": "Save computer vision predictions [\\#](\\#save-computer-vision-predictions)"
      },
      "text": "Above, replace:\n\n1. The image URL with the name of the image on which you want to run inference.\n2. `ROBOFLOW_API_KEY` with your Roboflow API key. [Learn how to retrieve your Roboflow API key](https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key).\n3. `MODEL_ID` with your Roboflow model ID. [Learn how to retrieve your model ID](https://docs.roboflow.com/api-reference/workspace-and-project-ids).\n",
      "overlap_text": {
        "previous_chunk_id": "a8ca21ef-a67d-494e-831b-827c3f58fdfb",
        "text": "Content of the previous chunk for context: h1: Roboflow h2: Save computer vision predictions [\\#](\\#save-computer-vision-predictions)\n\n_13\n    api_key=\"ROBOFLOW_API_KEY\"\n_13\n)\n_13\nwith client.use_model(MODEL_ID):\n_13\n    predictions = client.infer(image)\n_13\n_13\nprint(predictions)\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "d3ee6393-d0d2-45c6-9f9b-3fa2c5065b4a",
    "metadata": {
      "token_count": 114,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/roboflow",
      "page_title": "Roboflow | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Roboflow",
        "h2": "Save computer vision predictions [\\#](\\#save-computer-vision-predictions)"
      },
      "text": "\nWhen you run the code above, a list of predictions will be printed to the console:\n\n`\n_10\n{'time': 0.05402109300121083, 'image': {'width': 640, 'height': 480}, 'predictions': [{'x': 312.5, 'y': 392.0, 'width': 255.0, 'height': 110.0, 'confidence': 0.8620790839195251, 'class': 'Paper', 'class_id': 0}]}\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "71d487ca-7fba-4247-939e-12c94d25eae0",
        "text": "Content of the previous chunk for context: h1: Roboflow h2: Save computer vision predictions [\\#](\\#save-computer-vision-predictions)\n\nboflow.com/api-reference/authentication#retrieve-an-api-key).\n3. `MODEL_ID` with your Roboflow model ID. [Learn how to retrieve your model ID](https://docs.roboflow.com/api-reference/workspace-and-project-ids).\n"
      }
    }
  },
  {
    "chunk_id": "35619f4a-610a-40cd-a64b-ea6a7df7b3ef",
    "metadata": {
      "token_count": 153,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/roboflow",
      "page_title": "Roboflow | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Roboflow",
        "h2": "Save computer vision predictions [\\#](\\#save-computer-vision-predictions)"
      },
      "text": "### Step 3: Save results in Supabase [\\#](\\#step-3-save-results-in-supabase)\n\nTo save results in Supabase, add the following code to your script:\n\n`\n_10\nimport os\n_10\nfrom supabase import create_client, Client\n_10\n_10\nurl: str = os.environ.get(\"SUPABASE_URL\")\n_10\nkey: str = os.environ.get(\"SUPABASE_KEY\")\n_10\nsupabase: Client = create_client(url, key)\n_10\n_10\nresult = supabase.table('predictions') \\\n_10\n    .insert({\"filename\": image, \"predictions\": predictions}) \\\n_10\n    .execute()\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "d3ee6393-d0d2-45c6-9f9b-3fa2c5065b4a",
        "text": "Content of the previous chunk for context: h1: Roboflow h2: Save computer vision predictions [\\#](\\#save-computer-vision-predictions)\n\n': 392.0, 'width': 255.0, 'height': 110.0, 'confidence': 0.8620790839195251, 'class': 'Paper', 'class_id': 0}]}\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "ca20954c-b6c4-4b6f-99af-e83566cbc4f6",
    "metadata": {
      "token_count": 271,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/roboflow",
      "page_title": "Roboflow | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Roboflow",
        "h2": "Save computer vision predictions [\\#](\\#save-computer-vision-predictions)"
      },
      "text": "You can then query your predictions using the following code:\n\n`\n_10\nresult = supabase.table('predictions') \\\n_10\n    .select(\"predictions\") \\\n_10\n    .filter(\"filename\", \"eq\", image) \\\n_10\n    .execute()\n_10\n_10\nprint(result)\n`\n\nHere is an example result:\n\n`\n_10\ndata=[{'predictions': {'time': 0.08492901099998562, 'image': {'width': 640, 'height': 480}, 'predictions': [{'x': 312.5, 'y': 392.0, 'width': 255.0, 'height': 110.0, 'confidence': 0.8620790839195251, 'class': 'Paper', 'class_id': 0}]}}, {'predictions': {'time': 0.08818970100037404, 'image': {'width': 640, 'height': 480}, 'predictions': [{'x': 312.5, 'y': 392.0, 'width': 255.0, 'height': 110.0, 'confidence': 0.8620790839195251, 'class': 'Paper', 'class_id': 0}]}}] count=None\n`\n",
      "overlap_text": {
        "previous_chunk_id": "35619f4a-610a-40cd-a64b-ea6a7df7b3ef",
        "text": "Content of the previous chunk for context: h1: Roboflow h2: Save computer vision predictions [\\#](\\#save-computer-vision-predictions)\n\n: Client = create_client(url, key)\n_10\n_10\nresult = supabase.table('predictions') \\\n_10\n    .insert({\"filename\": image, \"predictions\": predictions}) \\\n_10\n    .execute()\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "e9734a57-a169-49ec-a163-e0e87cb6ca72",
    "metadata": {
      "token_count": 109,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/roboflow",
      "page_title": "Roboflow | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Roboflow",
        "h2": "Calculate and save CLIP embeddings [\\#](\\#calculate-and-save-clip-embeddings)"
      },
      "text": "You can use the Supabase vector database functionality to store and query CLIP embeddings.\n\nRoboflow Inference provides a HTTP interface through which you can calculate image and text embeddings using CLIP.\n\n### Step 1: Install and start Roboflow Inference [\\#](\\#step-1-install-and-start-roboflow-inference)\n\nSee [Step #1: Install and Start Roboflow Inference](#step-1-install-and-start-roboflow-inference) above to install and start Roboflow Inference.\n",
      "overlap_text": {
        "previous_chunk_id": "ca20954c-b6c4-4b6f-99af-e83566cbc4f6",
        "text": "Content of the previous chunk for context: h1: Roboflow h2: Save computer vision predictions [\\#](\\#save-computer-vision-predictions)\n\n0, 'width': 255.0, 'height': 110.0, 'confidence': 0.8620790839195251, 'class': 'Paper', 'class_id': 0}]}}] count=None\n`\n"
      }
    }
  },
  {
    "chunk_id": "38ce669c-f93c-4f55-862c-8ec7902f7da4",
    "metadata": {
      "token_count": 135,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/roboflow",
      "page_title": "Roboflow | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Roboflow",
        "h2": "Calculate and save CLIP embeddings [\\#](\\#calculate-and-save-clip-embeddings)"
      },
      "text": "\n### Step 2: Run CLIP on an image [\\#](\\#step-2-run-clip-on-an-image)\n\nCreate a new Python file and add the following code:\n\n`\n_32\nimport cv2\n_32\nimport supervision as sv\n_32\nimport requests\n_32\nimport base64\n_32\nimport os\n_32\n_32\nIMAGE_DIR = \"images/train/images/\"\n_32\nAPI_KEY = \"\"\n_32\nSERVER_URL = \"http://localhost:9001\"\n_32\n_32\nresults = []\n_32\n_32\nfor i, image in enumerate(os.listdir(IMAGE_DIR)):\n",
      "overlap_text": {
        "previous_chunk_id": "e9734a57-a169-49ec-a163-e0e87cb6ca72",
        "text": "Content of the previous chunk for context: h1: Roboflow h2: Calculate and save CLIP embeddings [\\#](\\#calculate-and-save-clip-embeddings)\n\n-1-install-and-start-roboflow-inference)\n\nSee [Step #1: Install and Start Roboflow Inference](#step-1-install-and-start-roboflow-inference) above to install and start Roboflow Inference.\n"
      }
    }
  },
  {
    "chunk_id": "900fe129-8c3e-41bc-ab70-aa652b6c1ac1",
    "metadata": {
      "token_count": 176,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/roboflow",
      "page_title": "Roboflow | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Roboflow",
        "h2": "Calculate and save CLIP embeddings [\\#](\\#calculate-and-save-clip-embeddings)"
      },
      "text": "_32\n    print(f\"Processing image {image}\")\n_32\n    infer_clip_payload = {\n_32\n        \"image\": {\n_32\n            \"type\": \"base64\",\n_32\n            \"value\": base64.b64encode(open(IMAGE_DIR + image, \"rb\").read()).decode(\"utf-8\"),\n_32\n        },\n_32\n    }\n_32\n_32\n    res = requests.post(\n_32\n        f\"{SERVER_URL}/clip/embed_image?api_key={API_KEY}\",\n_32\n        json=infer_clip_payload,\n_32\n    )\n_32\n_32\n    embeddings = res.json()['embeddings']\n_32\n_32\n    results.append({\n_32\n        \"filename\": image,\n_32\n        \"embeddings\": embeddings\n_32\n    })\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "38ce669c-f93c-4f55-862c-8ec7902f7da4",
        "text": "Content of the previous chunk for context: h1: Roboflow h2: Calculate and save CLIP embeddings [\\#](\\#calculate-and-save-clip-embeddings)\n\n/images/\"\n_32\nAPI_KEY = \"\"\n_32\nSERVER_URL = \"http://localhost:9001\"\n_32\n_32\nresults = []\n_32\n_32\nfor i, image in enumerate(os.listdir(IMAGE_DIR)):\n"
      }
    }
  },
  {
    "chunk_id": "1e988f3e-1302-47d1-b995-ce8eb4a87db8",
    "metadata": {
      "token_count": 116,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/roboflow",
      "page_title": "Roboflow | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Roboflow",
        "h2": "Calculate and save CLIP embeddings [\\#](\\#calculate-and-save-clip-embeddings)"
      },
      "text": "This code will calculate CLIP embeddings for each image in the directory and print the results to the console.\n\nAbove, replace:\n\n1. `IMAGE_DIR` with the directory containing the images on which you want to run inference.\n2. `ROBOFLOW_API_KEY` with your Roboflow API key. [Learn how to retrieve your Roboflow API key](https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key).\n\nYou can also calculate CLIP embeddings in the cloud by setting `SERVER_URL` to `https://infer.roboflow.com`.\n",
      "overlap_text": {
        "previous_chunk_id": "900fe129-8c3e-41bc-ab70-aa652b6c1ac1",
        "text": "Content of the previous chunk for context: h1: Roboflow h2: Calculate and save CLIP embeddings [\\#](\\#calculate-and-save-clip-embeddings)\n\n_32\n_32\n    embeddings = res.json()['embeddings']\n_32\n_32\n    results.append({\n_32\n        \"filename\": image,\n_32\n        \"embeddings\": embeddings\n_32\n    })\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "c709b106-00ef-426a-82c6-05573f807bfd",
    "metadata": {
      "token_count": 179,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/roboflow",
      "page_title": "Roboflow | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Roboflow",
        "h2": "Calculate and save CLIP embeddings [\\#](\\#calculate-and-save-clip-embeddings)"
      },
      "text": "\n### Step 3: Save embeddings in Supabase [\\#](\\#step-3-save-embeddings-in-supabase)\n\nYou can store your image embeddings in Supabase using the Supabase `vecs` Python package:\n\nFirst, install `vecs`:\n\n`\n_10\npip install vecs\n`\n\nNext, add the following code to your script to create an index:\n\n`\n_26\n_26\nimport vecs\n_26\n_26\nDB_CONNECTION = \"postgresql://postgres:[password]@[host]:[port]/[database]\"\n_26\n_26\nvx = vecs.create_client(DB_CONNECTION)\n_26\n_26\n# create a collection of vectors with 3 dimensions\n_26\nimages = vx.get_or_create_collection(name=\"image_vectors\", dimension=512)\n_26\n_26\nfor result in results:\n",
      "overlap_text": {
        "previous_chunk_id": "1e988f3e-1302-47d1-b995-ce8eb4a87db8",
        "text": "Content of the previous chunk for context: h1: Roboflow h2: Calculate and save CLIP embeddings [\\#](\\#calculate-and-save-clip-embeddings)\n\n retrieve your Roboflow API key](https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key).\n\nYou can also calculate CLIP embeddings in the cloud by setting `SERVER_URL` to `https://infer.roboflow.com`.\n"
      }
    }
  },
  {
    "chunk_id": "9ab66a9d-9c62-4096-841b-68c884cd8ce4",
    "metadata": {
      "token_count": 106,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/roboflow",
      "page_title": "Roboflow | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Roboflow",
        "h2": "Calculate and save CLIP embeddings [\\#](\\#calculate-and-save-clip-embeddings)"
      },
      "text": "_26\n    image = result[\"filename\"]\n_26\n    embeddings = result[\"embeddings\"][0]\n_26\n_26\n    # insert a vector into the collection\n_26\n    images.upsert(\n_26\n        records=[\\\n_26\\\n            (\\\n_26\\\n                image,\\\n_26\\\n                embeddings,\\\n_26\\\n                {} # metadata\\\n_26\\\n            )\\\n_26\\\n        ]\n_26\n    )\n_26\n_26\nimages.create_index()\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "c709b106-00ef-426a-82c6-05573f807bfd",
        "text": "Content of the previous chunk for context: h1: Roboflow h2: Calculate and save CLIP embeddings [\\#](\\#calculate-and-save-clip-embeddings)\n\n(DB_CONNECTION)\n_26\n_26\n# create a collection of vectors with 3 dimensions\n_26\nimages = vx.get_or_create_collection(name=\"image_vectors\", dimension=512)\n_26\n_26\nfor result in results:\n"
      }
    }
  },
  {
    "chunk_id": "19730635-acbd-490d-a0b6-e5f89b4350dd",
    "metadata": {
      "token_count": 170,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/roboflow",
      "page_title": "Roboflow | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Roboflow",
        "h2": "Calculate and save CLIP embeddings [\\#](\\#calculate-and-save-clip-embeddings)"
      },
      "text": "Replace `DB_CONNECTION` with the authentication information for your database. You can retrieve this from the Supabase dashboard in `Project Settings > Database Settings`.\n\nYou can then query your embeddings using the following code:\n\n`\n_17\ninfer_clip_payload = {\n_17\n    \"text\": \"cat\",\n_17\n}\n_17\n_17\nres = requests.post(\n_17\n    f\"{SERVER_URL}/clip/embed_text?api_key={API_KEY}\",\n_17\n    json=infer_clip_payload,\n_17\n)\n_17\n_17\nembeddings = res.json()['embeddings']\n_17\n_17\nresult = images.query(\n_17\n    data=embeddings[0],\n_17\n    limit=1\n_17\n)\n_17\n_17\nprint(result[0])\n`\n",
      "overlap_text": {
        "previous_chunk_id": "9ab66a9d-9c62-4096-841b-68c884cd8ce4",
        "text": "Content of the previous chunk for context: h1: Roboflow h2: Calculate and save CLIP embeddings [\\#](\\#calculate-and-save-clip-embeddings)\n\n            (\\\n_26\\\n                image,\\\n_26\\\n                embeddings,\\\n_26\\\n                {} # metadata\\\n_26\\\n            )\\\n_26\\\n        ]\n_26\n    )\n_26\n_26\nimages.create_index()\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "f69bb40d-3f60-470a-af47-a84ba804735f",
    "metadata": {
      "token_count": 84,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/roboflow",
      "page_title": "Roboflow | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Roboflow",
        "h2": "Resources [\\#](\\#resources)"
      },
      "text": "- [Roboflow Inference documentation](https://inference.roboflow.com)\n- [Roboflow Getting Started guide](https://blog.roboflow.com/getting-started-with-roboflow/)\n- [How to Build a Semantic Image Search Engine with Supabase and OpenAI CLIP](https://blog.roboflow.com/how-to-use-semantic-search-supabase-openai-clip/)\n",
      "overlap_text": {
        "previous_chunk_id": "19730635-acbd-490d-a0b6-e5f89b4350dd",
        "text": "Content of the previous chunk for context: h1: Roboflow h2: Calculate and save CLIP embeddings [\\#](\\#calculate-and-save-clip-embeddings)\n\n()['embeddings']\n_17\n_17\nresult = images.query(\n_17\n    data=embeddings[0],\n_17\n    limit=1\n_17\n)\n_17\n_17\nprint(result[0])\n`\n"
      }
    }
  },
  {
    "chunk_id": "61c39fb3-08c2-4cb2-8549-be30207d0dc9",
    "metadata": {
      "token_count": 88,
      "source_url": "https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins",
      "page_title": "Building ChatGPT plugins | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Building ChatGPT plugins",
        "h2": "Use Supabase as a Retrieval Store for your ChatGPT plugin."
      },
      "text": "* * *\n\nChatGPT recently released [Plugins](https://openai.com/blog/chatgpt-plugins) which help ChatGPT access up-to-date information, run computations, or use third-party services.\nIf you're building a plugin for ChatGPT, you'll probably want to answer questions from a specific source. We can solve this with \u201cretrieval plugins\u201d, which allow ChatGPT to access information from a database.\n"
    }
  },
  {
    "chunk_id": "d3e5d8ab-2fe4-46a9-b5fe-69f342ca8bcf",
    "metadata": {
      "token_count": 129,
      "source_url": "https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins",
      "page_title": "Building ChatGPT plugins | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Building ChatGPT plugins",
        "h2": "What is ChatGPT Retrieval Plugin? [\\#](\\#what-is-chatgpt-retrieval-plugin)"
      },
      "text": "A [Retrieval Plugin](https://github.com/openai/chatgpt-retrieval-plugin) is a Python project designed to inject external data into a ChatGPT conversation. It does a few things:\n\n1. Turn documents into smaller chunks.\n2. Converts chunks into embeddings using OpenAI's `text-embedding-ada-002` model.\n3. Stores the embeddings into a vector database.\n4. Queries the vector database for relevant documents when a question is asked.\n\nIt allows ChatGPT to dynamically pull relevant information into conversations from your data sources. This could be PDF documents, Confluence, or Notion knowledge bases.\n",
      "overlap_text": {
        "previous_chunk_id": "61c39fb3-08c2-4cb2-8549-be30207d0dc9",
        "text": "Content of the previous chunk for context: h1: Building ChatGPT plugins h2: Use Supabase as a Retrieval Store for your ChatGPT plugin.\n\n third-party services.\nIf you're building a plugin for ChatGPT, you'll probably want to answer questions from a specific source. We can solve this with \u201cretrieval plugins\u201d, which allow ChatGPT to access information from a database.\n"
      }
    }
  },
  {
    "chunk_id": "a122f0cc-c623-41be-a56e-746be8d629be",
    "metadata": {
      "token_count": 125,
      "source_url": "https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins",
      "page_title": "Building ChatGPT plugins | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Building ChatGPT plugins",
        "h2": "Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)"
      },
      "text": "Let\u2019s build an example where we can \u201cask ChatGPT questions\u201d about the Postgres documentation. Although ChatGPT already knows about the Postgres documentation because it is publicly available, this is a simple example which demonstrates how to work with PDF files.\n\nThis plugin requires several steps:\n\n1. Download all the [Postgres docs as a PDF](https://www.postgresql.org/files/documentation/pdf/15/postgresql-15-US.pdf)\n2. Convert the docs into chunks of embedded text and store them in Supabase\n3. Run our plugin locally so that we can ask questions about the Postgres docs.\n",
      "overlap_text": {
        "previous_chunk_id": "d3e5d8ab-2fe4-46a9-b5fe-69f342ca8bcf",
        "text": "Content of the previous chunk for context: h1: Building ChatGPT plugins h2: What is ChatGPT Retrieval Plugin? [\\#](\\#what-is-chatgpt-retrieval-plugin)\n\n vector database.\n4. Queries the vector database for relevant documents when a question is asked.\n\nIt allows ChatGPT to dynamically pull relevant information into conversations from your data sources. This could be PDF documents, Confluence, or Notion knowledge bases.\n"
      }
    }
  },
  {
    "chunk_id": "2aa36d5a-1323-4cd0-b35d-093f973da0e6",
    "metadata": {
      "token_count": 100,
      "source_url": "https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins",
      "page_title": "Building ChatGPT plugins | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Building ChatGPT plugins",
        "h2": "Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)"
      },
      "text": "\nWe'll be saving the Postgres documentation in Postgres, and ChatGPT will be retrieving the documentation whenever a user asks a question:\n\n### Step 1: Fork the ChatGPT Retrieval Plugin repository [\\#](\\#step-1-fork-the-chatgpt-retrieval-plugin-repository)\n\nFork the ChatGPT Retrieval Plugin repository to your GitHub account and clone it to your local machine. Read through the `README.md` file to understand the project structure.\n",
      "overlap_text": {
        "previous_chunk_id": "a122f0cc-c623-41be-a56e-746be8d629be",
        "text": "Content of the previous chunk for context: h1: Building ChatGPT plugins h2: Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)\n\ngresql.org/files/documentation/pdf/15/postgresql-15-US.pdf)\n2. Convert the docs into chunks of embedded text and store them in Supabase\n3. Run our plugin locally so that we can ask questions about the Postgres docs.\n"
      }
    }
  },
  {
    "chunk_id": "8e9725a4-a698-459a-9798-aff0a129d991",
    "metadata": {
      "token_count": 137,
      "source_url": "https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins",
      "page_title": "Building ChatGPT plugins | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Building ChatGPT plugins",
        "h2": "Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)"
      },
      "text": "\n### Step 2: Install dependencies [\\#](\\#step-2-install-dependencies)\n\nChoose your desired datastore provider and remove unused dependencies from `pyproject.toml`. For this example, we'll use Supabase. And install dependencies with Poetry:\n\n`\n_10\npoetry install\n`\n\n### Step 3: Create a Supabase project [\\#](\\#step-3-create-a-supabase-project)\n\nCreate a [Supabase project](https://supabase.com/dashboard) and database by following the instructions [here](https://supabase.com/docs/guides/platform). Export the environment variables required for the retrieval plugin to work:\n",
      "overlap_text": {
        "previous_chunk_id": "2aa36d5a-1323-4cd0-b35d-093f973da0e6",
        "text": "Content of the previous chunk for context: h1: Building ChatGPT plugins h2: Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)\n\n1-fork-the-chatgpt-retrieval-plugin-repository)\n\nFork the ChatGPT Retrieval Plugin repository to your GitHub account and clone it to your local machine. Read through the `README.md` file to understand the project structure.\n"
      }
    }
  },
  {
    "chunk_id": "bf2d2314-72cf-4c31-bd8f-79547a13203c",
    "metadata": {
      "token_count": 119,
      "source_url": "https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins",
      "page_title": "Building ChatGPT plugins | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Building ChatGPT plugins",
        "h2": "Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)"
      },
      "text": "\n`\n_10\nexport OPENAI_API_KEY=<open_ai_api_key>\n_10\nexport DATASTORE=supabase\n_10\nexport SUPABASE_URL=<supabase_url>\n_10\nexport SUPABASE_SERVICE_ROLE_KEY=<supabase_key>\n`\n\nFor Postgres datastore, you'll need to export these environment variables instead:\n\n`\n_10\nexport OPENAI_API_KEY=<open_ai_api_key>\n_10\nexport DATASTORE=postgres\n_10\nexport PG_HOST=<postgres_host_url>\n_10\nexport PG_PASSWORD=<postgres_password>\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "8e9725a4-a698-459a-9798-aff0a129d991",
        "text": "Content of the previous chunk for context: h1: Building ChatGPT plugins h2: Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)\n\n)\n\nCreate a [Supabase project](https://supabase.com/dashboard) and database by following the instructions [here](https://supabase.com/docs/guides/platform). Export the environment variables required for the retrieval plugin to work:\n"
      }
    }
  },
  {
    "chunk_id": "fb88a3d0-60e5-4e4c-a71c-6206b443b36c",
    "metadata": {
      "token_count": 137,
      "source_url": "https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins",
      "page_title": "Building ChatGPT plugins | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Building ChatGPT plugins",
        "h2": "Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)"
      },
      "text": "### Step 4: Run Postgres locally [\\#](\\#step-4-run-postgres-locally)\n\nTo start quicker you may use Supabase CLI to spin everything up locally as it already includes pgvector from the start. Install `supabase-cli`, go to the `examples/providers` folder in the repo and run:\n\n`\n_10\nsupabase start\n`\n\nThis will pull all docker images and run supabase stack in docker on your local machine. It will also apply all the necessary migrations to set the whole thing up. You can then use your local setup the same way, just export the environment variables and follow to the next steps.\n",
      "overlap_text": {
        "previous_chunk_id": "bf2d2314-72cf-4c31-bd8f-79547a13203c",
        "text": "Content of the previous chunk for context: h1: Building ChatGPT plugins h2: Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)\n\n environment variables instead:\n\n`\n_10\nexport OPENAI_API_KEY=<open_ai_api_key>\n_10\nexport DATASTORE=postgres\n_10\nexport PG_HOST=<postgres_host_url>\n_10\nexport PG_PASSWORD=<postgres_password>\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "5fab6af7-9c86-4526-834d-d8093471ce20",
    "metadata": {
      "token_count": 192,
      "source_url": "https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins",
      "page_title": "Building ChatGPT plugins | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Building ChatGPT plugins",
        "h2": "Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)"
      },
      "text": "\nUsing `supabase-cli` is not required and you can use any other docker image or hosted version of PostgresDB that includes `pgvector`. Just make sure you run migrations from `examples/providers/supabase/migrations/20230414142107_init_pg_vector.sql`.\n\n### Step 5: Obtain OpenAI API key [\\#](\\#step-5-obtain-openai-api-key)\n\nTo create embeddings Plugin uses OpenAI API and `text-embedding-ada-002` model. Each time we add some data to our datastore, or try to query relevant information from it, embedding will be created either for inserted data chunk, or for the query itself. To make it work we need to export `OPENAI_API_KEY`. If you already have an account in OpenAI, you just need to go to [User Settings - API keys](https://platform.openai.com/account/api-keys) and Create new secret key.\n",
      "overlap_text": {
        "previous_chunk_id": "fb88a3d0-60e5-4e4c-a71c-6206b443b36c",
        "text": "Content of the previous chunk for context: h1: Building ChatGPT plugins h2: Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)\n\n run supabase stack in docker on your local machine. It will also apply all the necessary migrations to set the whole thing up. You can then use your local setup the same way, just export the environment variables and follow to the next steps.\n"
      }
    }
  },
  {
    "chunk_id": "4c4a91f2-da03-4bfd-8873-17ad0c1e6561",
    "metadata": {
      "token_count": 160,
      "source_url": "https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins",
      "page_title": "Building ChatGPT plugins | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Building ChatGPT plugins",
        "h2": "Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)"
      },
      "text": "\n![OpenAI Secret Keys](https://supabase.com/docs/img/ai/chatgpt-plugins/openai-secret-keys.png)\n\n### Step 6: Run the plugin [\\#](\\#step-6-run-the-plugin)\n\nExecute the following command to run the plugin:\n\n`\n_10\npoetry run dev\n_10\n# output\n_10\nINFO:     Will watch for changes in these directories: ['./chatgpt-retrieval-plugin']\n_10\nINFO:     Uvicorn running on http://localhost:3333 (Press CTRL+C to quit)\n_10\nINFO:     Started reloader process [87843] using WatchFiles\n_10\nINFO:     Started server process [87849]\n_10\nINFO:     Waiting for application startup.\n",
      "overlap_text": {
        "previous_chunk_id": "5fab6af7-9c86-4526-834d-d8093471ce20",
        "text": "Content of the previous chunk for context: h1: Building ChatGPT plugins h2: Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)\n\n work we need to export `OPENAI_API_KEY`. If you already have an account in OpenAI, you just need to go to [User Settings - API keys](https://platform.openai.com/account/api-keys) and Create new secret key.\n"
      }
    }
  },
  {
    "chunk_id": "55bdfce2-7d21-448c-885a-466a07a7ed2c",
    "metadata": {
      "token_count": 107,
      "source_url": "https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins",
      "page_title": "Building ChatGPT plugins | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Building ChatGPT plugins",
        "h2": "Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)"
      },
      "text": "_10\nINFO:     Application startup complete.\n`\n\nThe plugin will start on your localhost - port `:3333` by default.\n\n### Step 6: Populating data in the datastore [\\#](\\#step-6-populating-data-in-the-datastore)\n\nFor this example, we'll upload Postgres documentation to the datastore. Download the [Postgres documentation](https://www.postgresql.org/files/documentation/pdf/15/postgresql-15-US.pdf) and use the `/upsert-file` endpoint to upload it:\n",
      "overlap_text": {
        "previous_chunk_id": "4c4a91f2-da03-4bfd-8873-17ad0c1e6561",
        "text": "Content of the previous chunk for context: h1: Building ChatGPT plugins h2: Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)\n\n3 (Press CTRL+C to quit)\n_10\nINFO:     Started reloader process [87843] using WatchFiles\n_10\nINFO:     Started server process [87849]\n_10\nINFO:     Waiting for application startup.\n"
      }
    }
  },
  {
    "chunk_id": "381cd0d8-943a-4c70-95a6-478bb2a0a86c",
    "metadata": {
      "token_count": 122,
      "source_url": "https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins",
      "page_title": "Building ChatGPT plugins | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Building ChatGPT plugins",
        "h2": "Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)"
      },
      "text": "\n`\n_10\ncurl -X POST -F \\\\\"file=@./postgresql-15-US.pdf\\\\\" <http://localhost:3333/upsert-file>\n`\n\nThe plugin will split your data and documents into smaller chunks automatically. You can view the chunks using the Supabase dashboard or any other SQL client you prefer. For the whole Postgres Documentation I got 7,904 records in my documents table, which is not a lot, but we can try to add index for `embedding` column to speed things up by a little. To do so, you should run the following SQL command:\n",
      "overlap_text": {
        "previous_chunk_id": "55bdfce2-7d21-448c-885a-466a07a7ed2c",
        "text": "Content of the previous chunk for context: h1: Building ChatGPT plugins h2: Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)\n\n example, we'll upload Postgres documentation to the datastore. Download the [Postgres documentation](https://www.postgresql.org/files/documentation/pdf/15/postgresql-15-US.pdf) and use the `/upsert-file` endpoint to upload it:\n"
      }
    }
  },
  {
    "chunk_id": "1f78ed38-e003-48af-aa4b-a6129903ec7c",
    "metadata": {
      "token_count": 122,
      "source_url": "https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins",
      "page_title": "Building ChatGPT plugins | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Building ChatGPT plugins",
        "h2": "Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)"
      },
      "text": "\n`\n_10\ncreate index on documents\n_10\nusing hnsw (embedding vector_ip_ops)\n_10\nwith (lists = 10);\n`\n\nThis will create an index for the inner product distance function. Important to note that it is an approximate index. It will change the logic from performing the exact nearest neighbor search to the approximate nearest neighbor search.\n\nWe are using `lists = 10`, because as a general guideline, you should start looking for optimal lists constant value with the formula: `rows / 1000` when you have less than 1 million records in your table.\n",
      "overlap_text": {
        "previous_chunk_id": "381cd0d8-943a-4c70-95a6-478bb2a0a86c",
        "text": "Content of the previous chunk for context: h1: Building ChatGPT plugins h2: Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)\n\n I got 7,904 records in my documents table, which is not a lot, but we can try to add index for `embedding` column to speed things up by a little. To do so, you should run the following SQL command:\n"
      }
    }
  },
  {
    "chunk_id": "235f2513-a21d-4516-835b-a537a36b1c55",
    "metadata": {
      "token_count": 107,
      "source_url": "https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins",
      "page_title": "Building ChatGPT plugins | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Building ChatGPT plugins",
        "h2": "Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)"
      },
      "text": "\n### Step 7: Using our plugin within ChatGPT [\\#](\\#step-7-using-our-plugin-within-chatgpt)\n\nTo integrate our plugin with ChatGPT, register it in the ChatGPT dashboard. Assuming you have access to ChatGPT Plugins and plugin development, select the Plugins model in a new chat, then choose \"Plugin store\" and \"Develop your own plugin.\" Enter `localhost:3333` into the domain input, and your plugin is now part of ChatGPT.\n",
      "overlap_text": {
        "previous_chunk_id": "1f78ed38-e003-48af-aa4b-a6129903ec7c",
        "text": "Content of the previous chunk for context: h1: Building ChatGPT plugins h2: Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)\n\n search.\n\nWe are using `lists = 10`, because as a general guideline, you should start looking for optimal lists constant value with the formula: `rows / 1000` when you have less than 1 million records in your table.\n"
      }
    }
  },
  {
    "chunk_id": "11aa1afb-5722-4a2b-bd4a-cba0db6e600e",
    "metadata": {
      "token_count": 118,
      "source_url": "https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins",
      "page_title": "Building ChatGPT plugins | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Building ChatGPT plugins",
        "h2": "Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)"
      },
      "text": "\n![ChatGPT Plugin Store](https://supabase.com/docs/img/ai/chatgpt-plugins/chatgpt-plugin-store.png)\n\n![ChatGPT Local Plugin](https://supabase.com/docs/img/ai/chatgpt-plugins/chatgpt-local-plugin.png)\n\nYou can now ask questions about Postgres and receive answers derived from the documentation.\n\nLet's try it out: ask ChatGPT to find out when to use `check` and when to use `using`. You will be able to see what queries were sent to our plugin and what it responded to.\n",
      "overlap_text": {
        "previous_chunk_id": "235f2513-a21d-4516-835b-a537a36b1c55",
        "text": "Content of the previous chunk for context: h1: Building ChatGPT plugins h2: Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)\n\n Plugins and plugin development, select the Plugins model in a new chat, then choose \"Plugin store\" and \"Develop your own plugin.\" Enter `localhost:3333` into the domain input, and your plugin is now part of ChatGPT.\n"
      }
    }
  },
  {
    "chunk_id": "2ae37c3e-d51c-41b3-afa0-631076052749",
    "metadata": {
      "token_count": 77,
      "source_url": "https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins",
      "page_title": "Building ChatGPT plugins | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Building ChatGPT plugins",
        "h2": "Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)"
      },
      "text": "\n![Ask ChatGPT](https://supabase.com/docs/img/ai/chatgpt-plugins/ask-chatgpt.png)\n\nAnd after ChatGPT receives a response from the plugin it will answer your question with the data from the documentation.\n\n![ChatGPT Reply](https://supabase.com/docs/img/ai/chatgpt-plugins/chatgpt-reply.png)\n",
      "overlap_text": {
        "previous_chunk_id": "11aa1afb-5722-4a2b-bd4a-cba0db6e600e",
        "text": "Content of the previous chunk for context: h1: Building ChatGPT plugins h2: Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)\n\n derived from the documentation.\n\nLet's try it out: ask ChatGPT to find out when to use `check` and when to use `using`. You will be able to see what queries were sent to our plugin and what it responded to.\n"
      }
    }
  },
  {
    "chunk_id": "dbd06f70-3182-4fed-817f-c9061743af0a",
    "metadata": {
      "token_count": 56,
      "source_url": "https://supabase.com/docs/guides/ai/examples/building-chatgpt-plugins",
      "page_title": "Building ChatGPT plugins | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Building ChatGPT plugins",
        "h2": "Resources [\\#](\\#resources)"
      },
      "text": "- ChatGPT Retrieval Plugin: [github.com/openai/chatgpt-retrieval-plugin](https://github.com/openai/chatgpt-retrieval-plugin)\n- ChatGPT Plugins: [official documentation](https://platform.openai.com/docs/plugins/introduction)\n",
      "overlap_text": {
        "previous_chunk_id": "2ae37c3e-d51c-41b3-afa0-631076052749",
        "text": "Content of the previous chunk for context: h1: Building ChatGPT plugins h2: Example: Chat with Postgres docs [\\#](\\#example-chat-with-postgres-docs)\n\n)\n\nAnd after ChatGPT receives a response from the plugin it will answer your question with the data from the documentation.\n\n![ChatGPT Reply](https://supabase.com/docs/img/ai/chatgpt-plugins/chatgpt-reply.png)\n"
      }
    }
  },
  {
    "chunk_id": "af2c7624-4396-4c7b-8f3d-e8deb0b7ef6d",
    "metadata": {
      "token_count": 101,
      "source_url": "https://supabase.com/docs/guides/ai/hugging-face",
      "page_title": "Hugging Face Inference API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hugging Face Inference API"
      },
      "text": "* * *\n\n[Hugging Face](https://huggingface.co) is an open source hub for AI/ML models and tools. With over 100,000 machine learning models available, Hugging Face provides a great way to integrate specialized AI & ML tasks into your application.\n\nThere are 3 ways to use Hugging Face models in your application:\n\n1. Use the [Transformers](https://huggingface.co/docs/transformers/index) Python library to perform inference in a Python backend.\n"
    }
  },
  {
    "chunk_id": "a01ff081-df80-4f6a-b4d0-cda5d110a611",
    "metadata": {
      "token_count": 74,
      "source_url": "https://supabase.com/docs/guides/ai/hugging-face",
      "page_title": "Hugging Face Inference API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hugging Face Inference API"
      },
      "text": "2. [Generate embeddings](/docs/guides/ai/quickstarts/generate-text-embeddings) directly in Edge Functions using Transformers.js.\n3. Use Hugging Face's hosted [Inference API](https://huggingface.co/inference-api) to execute AI tasks remotely on Hugging Face servers. This guide will walk you through this approach.\n",
      "overlap_text": {
        "previous_chunk_id": "af2c7624-4396-4c7b-8f3d-e8deb0b7ef6d",
        "text": "Content of the previous chunk for context: h1: Hugging Face Inference API\n\n tasks into your application.\n\nThere are 3 ways to use Hugging Face models in your application:\n\n1. Use the [Transformers](https://huggingface.co/docs/transformers/index) Python library to perform inference in a Python backend.\n"
      }
    }
  },
  {
    "chunk_id": "d497c9f8-667d-4b03-a3b6-82668fb9cd50",
    "metadata": {
      "token_count": 108,
      "source_url": "https://supabase.com/docs/guides/ai/hugging-face",
      "page_title": "Hugging Face Inference API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hugging Face Inference API",
        "h2": "AI tasks [\\#](\\#ai-tasks)"
      },
      "text": "Below are some of the types of tasks you can perform with Hugging Face:\n\n### Natural language [\\#](\\#natural-language)\n\n- [Summarization](https://huggingface.co/tasks/summarization)\n- [Text classification](https://huggingface.co/tasks/text-classification)\n- [Text generation](https://huggingface.co/tasks/text-generation)\n- [Translation](https://huggingface.co/tasks/translation)\n- [Fill in the blank](https://huggingface.co/tasks/fill-mask)\n",
      "overlap_text": {
        "previous_chunk_id": "a01ff081-df80-4f6a-b4d0-cda5d110a611",
        "text": "Content of the previous chunk for context: h1: Hugging Face Inference API\n\n in Edge Functions using Transformers.js.\n3. Use Hugging Face's hosted [Inference API](https://huggingface.co/inference-api) to execute AI tasks remotely on Hugging Face servers. This guide will walk you through this approach.\n"
      }
    }
  },
  {
    "chunk_id": "4fb3be5a-23e9-40df-b8bb-14a591981e9b",
    "metadata": {
      "token_count": 112,
      "source_url": "https://supabase.com/docs/guides/ai/hugging-face",
      "page_title": "Hugging Face Inference API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hugging Face Inference API",
        "h2": "AI tasks [\\#](\\#ai-tasks)"
      },
      "text": "\n### Computer vision [\\#](\\#computer-vision)\n\n- [Image to text](https://huggingface.co/tasks/image-to-text)\n- [Text to image](https://huggingface.co/tasks/text-to-image)\n- [Image classification](https://huggingface.co/tasks/image-classification)\n- [Video classification](https://huggingface.co/tasks/video-classification)\n- [Object detection](https://huggingface.co/tasks/object-detection)\n- [Image segmentation](https://huggingface.co/tasks/image-segmentation)\n",
      "overlap_text": {
        "previous_chunk_id": "d497c9f8-667d-4b03-a3b6-82668fb9cd50",
        "text": "Content of the previous chunk for context: h1: Hugging Face Inference API h2: AI tasks [\\#](\\#ai-tasks)\n\n-classification)\n- [Text generation](https://huggingface.co/tasks/text-generation)\n- [Translation](https://huggingface.co/tasks/translation)\n- [Fill in the blank](https://huggingface.co/tasks/fill-mask)\n"
      }
    }
  },
  {
    "chunk_id": "032469df-7572-429d-8f74-abd7534b06d3",
    "metadata": {
      "token_count": 80,
      "source_url": "https://supabase.com/docs/guides/ai/hugging-face",
      "page_title": "Hugging Face Inference API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hugging Face Inference API",
        "h2": "AI tasks [\\#](\\#ai-tasks)"
      },
      "text": "\n### Audio [\\#](\\#audio)\n\n- [Text to speech](https://huggingface.co/tasks/text-to-speech)\n- [Speech to text](https://huggingface.co/tasks/automatic-speech-recognition)\n- [Audio classification](https://huggingface.co/tasks/audio-classification)\n\nSee a [full list of tasks](https://huggingface.co/tasks).\n",
      "overlap_text": {
        "previous_chunk_id": "4fb3be5a-23e9-40df-b8bb-14a591981e9b",
        "text": "Content of the previous chunk for context: h1: Hugging Face Inference API h2: AI tasks [\\#](\\#ai-tasks)\n\n)\n- [Video classification](https://huggingface.co/tasks/video-classification)\n- [Object detection](https://huggingface.co/tasks/object-detection)\n- [Image segmentation](https://huggingface.co/tasks/image-segmentation)\n"
      }
    }
  },
  {
    "chunk_id": "21651a71-b6e8-49ee-94ca-536b2f2f1b1d",
    "metadata": {
      "token_count": 101,
      "source_url": "https://supabase.com/docs/guides/ai/hugging-face",
      "page_title": "Hugging Face Inference API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hugging Face Inference API",
        "h2": "Access token [\\#](\\#access-token)"
      },
      "text": "First generate a Hugging Face access token for your app:\n\n[https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)\n\nName your token based on the app its being used for and the environment. For example, if you are building an image generation app you might create 2 tokens:\n\n- \"My Image Generator (Dev)\"\n- \"My Image Generator (Prod)\"\n\nSince we will be using this token for the inference API, choose the `read` role.\n",
      "overlap_text": {
        "previous_chunk_id": "032469df-7572-429d-8f74-abd7534b06d3",
        "text": "Content of the previous chunk for context: h1: Hugging Face Inference API h2: AI tasks [\\#](\\#ai-tasks)\n\nSpeech to text](https://huggingface.co/tasks/automatic-speech-recognition)\n- [Audio classification](https://huggingface.co/tasks/audio-classification)\n\nSee a [full list of tasks](https://huggingface.co/tasks).\n"
      }
    }
  },
  {
    "chunk_id": "6938012a-b168-430a-9fa2-19a84bc6dcca",
    "metadata": {
      "token_count": 63,
      "source_url": "https://supabase.com/docs/guides/ai/hugging-face",
      "page_title": "Hugging Face Inference API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hugging Face Inference API",
        "h2": "Access token [\\#](\\#access-token)"
      },
      "text": "\nThough it is possible to use the Hugging Face inference API today without an access token, [you may be rate limited](https://huggingface.co/docs/huggingface.js/inference/README#usage).\n\nTo ensure you don't experience any unexpected downtime or errors, we recommend creating an access token.\n",
      "overlap_text": {
        "previous_chunk_id": "21651a71-b6e8-49ee-94ca-536b2f2f1b1d",
        "text": "Content of the previous chunk for context: h1: Hugging Face Inference API h2: Access token [\\#](\\#access-token)\n\n if you are building an image generation app you might create 2 tokens:\n\n- \"My Image Generator (Dev)\"\n- \"My Image Generator (Prod)\"\n\nSince we will be using this token for the inference API, choose the `read` role.\n"
      }
    }
  },
  {
    "chunk_id": "97e89ff8-8dc0-4acc-820c-74814dee2ea8",
    "metadata": {
      "token_count": 100,
      "source_url": "https://supabase.com/docs/guides/ai/hugging-face",
      "page_title": "Hugging Face Inference API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hugging Face Inference API",
        "h2": "Edge Functions [\\#](\\#edge-functions)"
      },
      "text": "Edge Functions are server-side TypeScript functions that run on-demand. Since Edge Functions run on a server, you can safely give them access to your Hugging Face access token.\n\nYou will need the `supabase` CLI [installed](/docs/guides/cli) for the following commands to work.\n\nTo create a new Edge Function, navigate to your local project and initialize Supabase if you haven't already:\n\n`\n_10\nsupabase init\n`\n\nThen create an Edge Function:\n",
      "overlap_text": {
        "previous_chunk_id": "6938012a-b168-430a-9fa2-19a84bc6dcca",
        "text": "Content of the previous chunk for context: h1: Hugging Face Inference API h2: Access token [\\#](\\#access-token)\n\n today without an access token, [you may be rate limited](https://huggingface.co/docs/huggingface.js/inference/README#usage).\n\nTo ensure you don't experience any unexpected downtime or errors, we recommend creating an access token.\n"
      }
    }
  },
  {
    "chunk_id": "c6a74833-bc63-45ef-b0ea-ab1f5c32752f",
    "metadata": {
      "token_count": 270,
      "source_url": "https://supabase.com/docs/guides/ai/hugging-face",
      "page_title": "Hugging Face Inference API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hugging Face Inference API",
        "h2": "Edge Functions [\\#](\\#edge-functions)"
      },
      "text": "\n`\n_10\nsupabase functions new text-to-image\n`\n\nCreate a file called `.env.local` to store your Hugging Face access token:\n\n`\n_10\nHUGGING_FACE_ACCESS_TOKEN=<your-token-here>\n`\n\nLet's modify the Edge Function to import Hugging Face's inference client and perform a `text-to-image` request:\n\n`\n_20\nimport { serve } from 'https://deno.land/std@0.168.0/http/server.ts'\n_20\nimport { HfInference } from 'https://esm.sh/@huggingface/inference@2.3.2'\n_20\n_20\nconst hf = new HfInference(Deno.env.get('HUGGING_FACE_ACCESS_TOKEN'))\n_20\n_20\nserve(async (req) => {\n_20\nconst { prompt } = await req.json()\n_20\n_20\nconst image = await hf.textToImage(\n_20\n    {\n_20\n      inputs: prompt,\n_20\n      model: 'stabilityai/stable-diffusion-2',\n_20\n    },\n_20\n    {\n_20\n      use_cache: false,\n_20\n    }\n_20\n)\n_20\n_20\nreturn new Response(image)\n_20\n})\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "97e89ff8-8dc0-4acc-820c-74814dee2ea8",
        "text": "Content of the previous chunk for context: h1: Hugging Face Inference API h2: Edge Functions [\\#](\\#edge-functions)\n\nuides/cli) for the following commands to work.\n\nTo create a new Edge Function, navigate to your local project and initialize Supabase if you haven't already:\n\n`\n_10\nsupabase init\n`\n\nThen create an Edge Function:\n"
      }
    }
  },
  {
    "chunk_id": "8e2ab079-5f92-43cb-b7ac-573b1d65adf0",
    "metadata": {
      "token_count": 174,
      "source_url": "https://supabase.com/docs/guides/ai/hugging-face",
      "page_title": "Hugging Face Inference API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hugging Face Inference API",
        "h2": "Edge Functions [\\#](\\#edge-functions)"
      },
      "text": "1. This function creates a new instance of `HfInference` using the `HUGGING_FACE_ACCESS_TOKEN` environment variable.\n\n2. It expects a POST request that includes a JSON request body. The JSON body should include a parameter called `prompt` that represents the text-to-image prompt that we will pass to Hugging Face's inference API.\n\n3. Next we call `textToImage()`, passing in the user's prompt along with the model that we would like to use for the image generation. Today Hugging Face recommends `stabilityai/stable-diffusion-2`, but you can change this to any other text-to-image model. You can see a list of which models are supported for each task by navigating to their [models page](https://huggingface.co/models?pipeline_tag=text-to-image) and filtering by task.\n",
      "overlap_text": {
        "previous_chunk_id": "c6a74833-bc63-45ef-b0ea-ab1f5c32752f",
        "text": "Content of the previous chunk for context: h1: Hugging Face Inference API h2: Edge Functions [\\#](\\#edge-functions)\n\n-diffusion-2',\n_20\n    },\n_20\n    {\n_20\n      use_cache: false,\n_20\n    }\n_20\n)\n_20\n_20\nreturn new Response(image)\n_20\n})\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "c93ce715-c293-4497-b262-188dd68a2642",
    "metadata": {
      "token_count": 111,
      "source_url": "https://supabase.com/docs/guides/ai/hugging-face",
      "page_title": "Hugging Face Inference API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hugging Face Inference API",
        "h2": "Edge Functions [\\#](\\#edge-functions)"
      },
      "text": "\n4. We set `use_cache` to `false` so that repeat queries with the same prompt will produce new images. If the task and model you are using is deterministic (will always produce the same result based on the same input), consider setting `use_cache` to `true` for faster responses.\n\n5. The `image` result returned from the API will be a `Blob`. We can pass the `Blob` directly into a `new Response()` which will automatically set the content type and body of the response from the `image`.\n",
      "overlap_text": {
        "previous_chunk_id": "8e2ab079-5f92-43cb-b7ac-573b1d65adf0",
        "text": "Content of the previous chunk for context: h1: Hugging Face Inference API h2: Edge Functions [\\#](\\#edge-functions)\n\n change this to any other text-to-image model. You can see a list of which models are supported for each task by navigating to their [models page](https://huggingface.co/models?pipeline_tag=text-to-image) and filtering by task.\n"
      }
    }
  },
  {
    "chunk_id": "33366e8f-ffa5-441f-ae3d-8ed5d2d42cce",
    "metadata": {
      "token_count": 123,
      "source_url": "https://supabase.com/docs/guides/ai/hugging-face",
      "page_title": "Hugging Face Inference API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hugging Face Inference API",
        "h2": "Edge Functions [\\#](\\#edge-functions)"
      },
      "text": "\n\nFinally let's serve the Edge Function locally to test it:\n\n`\n_10\nsupabase functions serve --env-file .env.local --no-verify-jwt\n`\n\nRemember to pass in the `.env.local` file using the `--env-file` parameter so that the Edge Function can access the `HUGGING_FACE_ACCESS_TOKEN`.\n\nFor demo purposes we set `--no-verify-jwt` to make it easy to test the Edge Function without passing in a JWT token. In a real application you will need to pass the JWT as a `Bearer` token in the `Authorization` header.\n",
      "overlap_text": {
        "previous_chunk_id": "c93ce715-c293-4497-b262-188dd68a2642",
        "text": "Content of the previous chunk for context: h1: Hugging Face Inference API h2: Edge Functions [\\#](\\#edge-functions)\n\n responses.\n\n5. The `image` result returned from the API will be a `Blob`. We can pass the `Blob` directly into a `new Response()` which will automatically set the content type and body of the response from the `image`.\n"
      }
    }
  },
  {
    "chunk_id": "49b02016-4bb6-4597-8b6b-33a9268b9bdd",
    "metadata": {
      "token_count": 101,
      "source_url": "https://supabase.com/docs/guides/ai/hugging-face",
      "page_title": "Hugging Face Inference API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hugging Face Inference API",
        "h2": "Edge Functions [\\#](\\#edge-functions)"
      },
      "text": "\nAt this point, you can make an API request to your Edge Function using your preferred frontend framework (Next.js, React, Expo, etc). We can also test from the terminal using `curl`:\n\n`\n_10\ncurl --output result.jpg --location --request POST 'http://localhost:54321/functions/v1/text-to-image' \\\n_10\n  --header 'Content-Type: application/json' \\\n_10\n  --data '{\"prompt\":\"Llama wearing sunglasses\"}'\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "33366e8f-ffa5-441f-ae3d-8ed5d2d42cce",
        "text": "Content of the previous chunk for context: h1: Hugging Face Inference API h2: Edge Functions [\\#](\\#edge-functions)\n\n we set `--no-verify-jwt` to make it easy to test the Edge Function without passing in a JWT token. In a real application you will need to pass the JWT as a `Bearer` token in the `Authorization` header.\n"
      }
    }
  },
  {
    "chunk_id": "3978efbf-99e5-4f79-ad7a-3d23716b9a46",
    "metadata": {
      "token_count": 44,
      "source_url": "https://supabase.com/docs/guides/ai/hugging-face",
      "page_title": "Hugging Face Inference API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hugging Face Inference API",
        "h2": "Edge Functions [\\#](\\#edge-functions)"
      },
      "text": "In this example, your generated image will save to `result.jpg`:\n\n![Llama wearing sunglasses example](https://supabase.com/docs/img/ai/hugging-face/llama-sunglasses-example.png)\n",
      "overlap_text": {
        "previous_chunk_id": "49b02016-4bb6-4597-8b6b-33a9268b9bdd",
        "text": "Content of the previous chunk for context: h1: Hugging Face Inference API h2: Edge Functions [\\#](\\#edge-functions)\n\n --location --request POST 'http://localhost:54321/functions/v1/text-to-image' \\\n_10\n  --header 'Content-Type: application/json' \\\n_10\n  --data '{\"prompt\":\"Llama wearing sunglasses\"}'\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "7a233189-a7bf-4aed-94b8-3657bc08c739",
    "metadata": {
      "token_count": 33,
      "source_url": "https://supabase.com/docs/guides/ai/hugging-face",
      "page_title": "Hugging Face Inference API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hugging Face Inference API",
        "h2": "Next steps [\\#](\\#next-steps)"
      },
      "text": "You can now create an Edge Function that invokes a Hugging Face task using your model of choice.\n\nTry running some other [AI tasks](#ai-tasks).\n",
      "overlap_text": {
        "previous_chunk_id": "3978efbf-99e5-4f79-ad7a-3d23716b9a46",
        "text": "Content of the previous chunk for context: h1: Hugging Face Inference API h2: Edge Functions [\\#](\\#edge-functions)\n\nIn this example, your generated image will save to `result.jpg`:\n\n![Llama wearing sunglasses example](https://supabase.com/docs/img/ai/hugging-face/llama-sunglasses-example.png)\n"
      }
    }
  },
  {
    "chunk_id": "22e6b157-0000-427c-9844-ca39d8f54e58",
    "metadata": {
      "token_count": 63,
      "source_url": "https://supabase.com/docs/guides/ai/hugging-face",
      "page_title": "Hugging Face Inference API | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Hugging Face Inference API",
        "h2": "Resources [\\#](\\#resources)"
      },
      "text": "- Official [Hugging Face site](https://huggingface.co/).\n- Official [Hugging Face JS docs](https://huggingface.co/docs/huggingface.js).\n- [Generate image captions](/docs/guides/ai/examples/huggingface-image-captioning) using Hugging Face.\n",
      "overlap_text": {
        "previous_chunk_id": "7a233189-a7bf-4aed-94b8-3657bc08c739",
        "text": "Content of the previous chunk for context: h1: Hugging Face Inference API h2: Next steps [\\#](\\#next-steps)\n\nYou can now create an Edge Function that invokes a Hugging Face task using your model of choice.\n\nTry running some other [AI tasks](#ai-tasks).\n"
      }
    }
  },
  {
    "chunk_id": "261c733a-d9a8-4b24-b34d-93b437e5fbf4",
    "metadata": {
      "token_count": 57,
      "source_url": "https://supabase.com/docs/guides/ai/examples/huggingface-image-captioning",
      "page_title": "Generate image captions using Hugging Face | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generate image captions using Hugging Face",
        "h2": "Use the Hugging Face Inference API to make calls to 100,000+ Machine Learning models from Supabase Edge Functions."
      },
      "text": "* * *\n\nWe can combine Hugging Face with [Supabase Storage](https://supabase.com/storage) and [Database Webhooks](https://supabase.com/docs/guides/database/webhooks) to automatically caption for any image we upload to a storage bucket.\n"
    }
  },
  {
    "chunk_id": "f5f80e5c-b938-431a-b5ac-cbfcb78dbe55",
    "metadata": {
      "token_count": 82,
      "source_url": "https://supabase.com/docs/guides/ai/examples/huggingface-image-captioning",
      "page_title": "Generate image captions using Hugging Face | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generate image captions using Hugging Face",
        "h2": "About Hugging Face [\\#](\\#about-hugging-face)"
      },
      "text": "[Hugging Face](https://huggingface.co/) is the collaboration platform for the machine learning community.\n\n[Huggingface.js](https://huggingface.co/docs/huggingface.js/index) provides a convenient way to make calls to 100,000+ Machine Learning models, making it easy to incorporate AI functionality into your [Supabase Edge Functions](https://supabase.com/edge-functions).\n",
      "overlap_text": {
        "previous_chunk_id": "261c733a-d9a8-4b24-b34d-93b437e5fbf4",
        "text": "Content of the previous chunk for context: h1: Generate image captions using Hugging Face h2: Use the Hugging Face Inference API to make calls to 100,000+ Machine Learning models from Supabase Edge Functions.\n\nugging Face with [Supabase Storage](https://supabase.com/storage) and [Database Webhooks](https://supabase.com/docs/guides/database/webhooks) to automatically caption for any image we upload to a storage bucket.\n"
      }
    }
  },
  {
    "chunk_id": "c25c05e1-456c-4067-a50d-ae77ea7d03e0",
    "metadata": {
      "token_count": 100,
      "source_url": "https://supabase.com/docs/guides/ai/examples/huggingface-image-captioning",
      "page_title": "Generate image captions using Hugging Face | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generate image captions using Hugging Face",
        "h2": "Setup [\\#](\\#setup)"
      },
      "text": "- Open your Supabase project dashboard or [create a new project](https://supabase.com/dashboard/projects).\n- [Create a new bucket](https://supabase.com/dashboard/project/_/storage/buckets) called `images`.\n- Generate TypeScript types from remote Database.\n- Create a new Database table called `image_caption`.\n  - Create `id` column of type `uuid` which references `storage.objects.id`.\n  - Create a `caption` column of type `text`.\n",
      "overlap_text": {
        "previous_chunk_id": "f5f80e5c-b938-431a-b5ac-cbfcb78dbe55",
        "text": "Content of the previous chunk for context: h1: Generate image captions using Hugging Face h2: About Hugging Face [\\#](\\#about-hugging-face)\n\n/docs/huggingface.js/index) provides a convenient way to make calls to 100,000+ Machine Learning models, making it easy to incorporate AI functionality into your [Supabase Edge Functions](https://supabase.com/edge-functions).\n"
      }
    }
  },
  {
    "chunk_id": "23b2fccc-683e-410c-9297-208de24ecfa3",
    "metadata": {
      "token_count": 88,
      "source_url": "https://supabase.com/docs/guides/ai/examples/huggingface-image-captioning",
      "page_title": "Generate image captions using Hugging Face | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generate image captions using Hugging Face",
        "h2": "Setup [\\#](\\#setup)"
      },
      "text": "- Regenerate TypeScript types to include new `image_caption` table.\n- Deploy the function to Supabase: `supabase functions deploy huggingface-image-captioning`.\n- Create the Database Webhook in the [Supabase Dashboard](https://supabase.com/dashboard/project/_/database/hooks) to trigger the `huggingface-image-captioning` function anytime a record is added to the `storage.objects` table.\n",
      "overlap_text": {
        "previous_chunk_id": "c25c05e1-456c-4067-a50d-ae77ea7d03e0",
        "text": "Content of the previous chunk for context: h1: Generate image captions using Hugging Face h2: Setup [\\#](\\#setup)\n\n Generate TypeScript types from remote Database.\n- Create a new Database table called `image_caption`.\n  - Create `id` column of type `uuid` which references `storage.objects.id`.\n  - Create a `caption` column of type `text`.\n"
      }
    }
  },
  {
    "chunk_id": "b7693e5a-03e9-4332-94fa-667cd0a01eb4",
    "metadata": {
      "token_count": 60,
      "source_url": "https://supabase.com/docs/guides/ai/examples/huggingface-image-captioning",
      "page_title": "Generate image captions using Hugging Face | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generate image captions using Hugging Face",
        "h2": "Generate TypeScript types [\\#](\\#generate-typescript-types)"
      },
      "text": "To generate the types.ts file for the storage and public schemas, run the following command in the terminal:\n\n`\n_10\nsupabase gen types typescript --project-id=your-project-ref --schema=storage,public > supabase/functions/huggingface-image-captioning/types.ts\n`\n",
      "overlap_text": {
        "previous_chunk_id": "23b2fccc-683e-410c-9297-208de24ecfa3",
        "text": "Content of the previous chunk for context: h1: Generate image captions using Hugging Face h2: Setup [\\#](\\#setup)\n\n the Database Webhook in the [Supabase Dashboard](https://supabase.com/dashboard/project/_/database/hooks) to trigger the `huggingface-image-captioning` function anytime a record is added to the `storage.objects` table.\n"
      }
    }
  },
  {
    "chunk_id": "20ba06c0-86ae-4426-8a0c-2bfac27a1c58",
    "metadata": {
      "token_count": 618,
      "source_url": "https://supabase.com/docs/guides/ai/examples/huggingface-image-captioning",
      "page_title": "Generate image captions using Hugging Face | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generate image captions using Hugging Face",
        "h2": "Code [\\#](\\#code)"
      },
      "text": "Find the complete code on [GitHub](https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/huggingface-image-captioning).\n\n``\n_49\nimport { serve } from 'https://deno.land/std@0.168.0/http/server.ts'\n_49\nimport { HfInference } from 'https://esm.sh/@huggingface/inference@2.3.2'\n_49\nimport { createClient } from 'jsr:@supabase/supabase-js@2'\n_49\nimport { Database } from './types.ts'\n_49\n_49\nconsole.log('Hello from `huggingface-image-captioning` function!')\n_49\n_49\nconst hf = new HfInference(Deno.env.get('HUGGINGFACE_ACCESS_TOKEN'))\n_49\n_49\ntype SoRecord = Database['storage']['Tables']['objects']['Row']\n_49\ninterface WebhookPayload {\n_49\ntype: 'INSERT' | 'UPDATE' | 'DELETE'\n_49\ntable: string\n_49\nrecord: SoRecord\n_49\nschema: 'public'\n_49\nold_record: null | SoRecord\n_49\n}\n_49\n_49\nserve(async (req) => {\n_49\nconst payload: WebhookPayload = await req.json()\n_49\nconst soRecord = payload.record\n_49\nconst supabaseAdminClient = createClient<Database>(\n_49\n    // Supabase API URL - env var exported by default when deployed.\n_49\n    Deno.env.get('SUPABASE_URL') ?? '',\n_49\n    // Supabase API SERVICE ROLE KEY - env var exported by default when deployed.\n_49\n    Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? ''\n_49\n)\n_49\n_49\n// Construct image url from storage\n_49\nconst { data, error } = await supabaseAdminClient.storage\n_49\n    .from(soRecord.bucket_id!)\n_49\n    .createSignedUrl(soRecord.path_tokens!.join('/'), 60)\n_49\nif (error) throw error\n_49\nconst { signedUrl } = data\n_49\n_49\n// Run image captioning with Huggingface\n_49\nconst imgDesc = await hf.imageToText({\n_49\n    data: await (await fetch(signedUrl)).blob(),\n_49\n    model: 'nlpconnect/vit-gpt2-image-captioning',\n_49\n})\n_49\n_49\n// Store image caption in Database table\n_49\nawait supabaseAdminClient\n_49\n    .from('image_caption')\n_49\n    .insert({ id: soRecord.id!, caption: imgDesc.generated_text })\n_49\n    .throwOnError()\n_49\n_49\nreturn new Response('ok')\n_49\n})\n``\n",
      "overlap_text": {
        "previous_chunk_id": "b7693e5a-03e9-4332-94fa-667cd0a01eb4",
        "text": "Content of the previous chunk for context: h1: Generate image captions using Hugging Face h2: Generate TypeScript types [\\#](\\#generate-typescript-types)\n\n public schemas, run the following command in the terminal:\n\n`\n_10\nsupabase gen types typescript --project-id=your-project-ref --schema=storage,public > supabase/functions/huggingface-image-captioning/types.ts\n`\n"
      }
    }
  },
  {
    "chunk_id": "abc43ad8-1c67-488a-9cf1-18a513d7cec8",
    "metadata": {
      "token_count": 57,
      "source_url": "https://supabase.com/docs/guides/ai/semantic-search",
      "page_title": "Semantic search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic search",
        "h2": "Learn how to search by meaning rather than exact keywords."
      },
      "text": "* * *\n\nSemantic search interprets the meaning behind user queries rather than exact [keywords](/docs/guides/ai/keyword-search). It uses machine learning to capture the intent and context behind the query, handling language nuances like synonyms, phrasing variations, and word relationships.\n"
    }
  },
  {
    "chunk_id": "abc39c6d-48a8-4fba-aeb3-9f306f4e0ba8",
    "metadata": {
      "token_count": 150,
      "source_url": "https://supabase.com/docs/guides/ai/semantic-search",
      "page_title": "Semantic search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic search",
        "h2": "When to use semantic search [\\#](\\#when-to-use-semantic-search)"
      },
      "text": "Semantic search is useful in applications where the depth of understanding and context is important for delivering relevant results. A good example is in customer support or knowledge base search engines. Users often phrase their problems or questions in various ways, and a traditional keyword-based search might not always retrieve the most helpful documents. With semantic search, the system can understand the meaning behind the queries and match them with relevant solutions or articles, even if the exact wording differs.\n\nFor instance, a user searching for \"increase text size on display\" might miss articles titled \"How to adjust font size in settings\" in a keyword-based search system. However, a semantic search engine would understand the intent behind the query and correctly match it to relevant articles, regardless of the specific terminology used.\n",
      "overlap_text": {
        "previous_chunk_id": "abc43ad8-1c67-488a-9cf1-18a513d7cec8",
        "text": "Content of the previous chunk for context: h1: Semantic search h2: Learn how to search by meaning rather than exact keywords.\n\n the meaning behind user queries rather than exact [keywords](/docs/guides/ai/keyword-search). It uses machine learning to capture the intent and context behind the query, handling language nuances like synonyms, phrasing variations, and word relationships.\n"
      }
    }
  },
  {
    "chunk_id": "a15633db-6094-4ce0-9157-a149f544d7a8",
    "metadata": {
      "token_count": 41,
      "source_url": "https://supabase.com/docs/guides/ai/semantic-search",
      "page_title": "Semantic search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic search",
        "h2": "When to use semantic search [\\#](\\#when-to-use-semantic-search)"
      },
      "text": "\nIt's also possible to combine semantic search with keyword search to get the best of both worlds. See [Hybrid search](/docs/guides/ai/hybrid-search) for more details.\n",
      "overlap_text": {
        "previous_chunk_id": "abc39c6d-48a8-4fba-aeb3-9f306f4e0ba8",
        "text": "Content of the previous chunk for context: h1: Semantic search h2: When to use semantic search [\\#](\\#when-to-use-semantic-search)\n\n display\" might miss articles titled \"How to adjust font size in settings\" in a keyword-based search system. However, a semantic search engine would understand the intent behind the query and correctly match it to relevant articles, regardless of the specific terminology used.\n"
      }
    }
  },
  {
    "chunk_id": "4dcff068-e3c3-4fd7-a942-8e8bba8ba1ff",
    "metadata": {
      "token_count": 138,
      "source_url": "https://supabase.com/docs/guides/ai/semantic-search",
      "page_title": "Semantic search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic search",
        "h2": "How semantic search works [\\#](\\#how-semantic-search-works)"
      },
      "text": "Semantic search uses an intermediate representation called an \u201cembedding vector\u201d to link database records with search queries. A vector, in the context of semantic search, is a list of numerical values. They represent various features of the text and allow for the semantic comparison between different pieces of text.\n\nThe best way to think of embeddings is by plotting them on a graph, where each embedding is a single point whose coordinates are the numerical values within its vector. Importantly, embeddings are plotted such that similar concepts are positioned close together while dissimilar concepts are far apart. For more details, see [What are embeddings?](/docs/guides/ai/concepts#what-are-embeddings)\n\n",
      "overlap_text": {
        "previous_chunk_id": "a15633db-6094-4ce0-9157-a149f544d7a8",
        "text": "Content of the previous chunk for context: h1: Semantic search h2: When to use semantic search [\\#](\\#when-to-use-semantic-search)\n\n\nIt's also possible to combine semantic search with keyword search to get the best of both worlds. See [Hybrid search](/docs/guides/ai/hybrid-search) for more details.\n"
      }
    }
  },
  {
    "chunk_id": "6fe6c829-9404-4c8e-ad2f-489937960280",
    "metadata": {
      "token_count": 125,
      "source_url": "https://supabase.com/docs/guides/ai/semantic-search",
      "page_title": "Semantic search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic search",
        "h2": "How semantic search works [\\#](\\#how-semantic-search-works)"
      },
      "text": "Embeddings are generated using a language model, and embeddings are compared to each other using a similarity metric. The language model is trained to understand the semantics of language, including syntax, context, and the relationships between words. It generates embeddings for both the content in the database and the search queries. Then the similarity metric, often a function like cosine similarity or dot product, is used to compare the query embeddings with the document embeddings (in other words, to measure how close they are to each other on the graph). The documents with embeddings most similar to the query's are deemed the most relevant and are returned as search results.\n",
      "overlap_text": {
        "previous_chunk_id": "4dcff068-e3c3-4fd7-a942-8e8bba8ba1ff",
        "text": "Content of the previous chunk for context: h1: Semantic search h2: How semantic search works [\\#](\\#how-semantic-search-works)\n\n Importantly, embeddings are plotted such that similar concepts are positioned close together while dissimilar concepts are far apart. For more details, see [What are embeddings?](/docs/guides/ai/concepts#what-are-embeddings)\n\n"
      }
    }
  },
  {
    "chunk_id": "159ea8e0-13af-4cf6-84f3-bd091e3de5cd",
    "metadata": {
      "token_count": 128,
      "source_url": "https://supabase.com/docs/guides/ai/semantic-search",
      "page_title": "Semantic search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic search",
        "h2": "Embedding models [\\#](\\#embedding-models)"
      },
      "text": "There are many embedding models available today. Supabase Edge Functions has [built in support](/docs/guides/functions/examples/semantic-search) for the `gte-small` model. Others can be accessed through third-party APIs like [OpenAI](https://platform.openai.com/docs/guides/embeddings), where you send your text in the request and receive an embedding vector in the response. Others can run locally on your own compute, such as through Transformers.js for JavaScript implementations. For more information on local implementation, see [Generate embeddings](/docs/guides/ai/quickstarts/generate-text-embeddings).\n",
      "overlap_text": {
        "previous_chunk_id": "6fe6c829-9404-4c8e-ad2f-489937960280",
        "text": "Content of the previous chunk for context: h1: Semantic search h2: How semantic search works [\\#](\\#how-semantic-search-works)\n\n used to compare the query embeddings with the document embeddings (in other words, to measure how close they are to each other on the graph). The documents with embeddings most similar to the query's are deemed the most relevant and are returned as search results.\n"
      }
    }
  },
  {
    "chunk_id": "11c52703-1cef-457f-a174-dd1360a86d9a",
    "metadata": {
      "token_count": 38,
      "source_url": "https://supabase.com/docs/guides/ai/semantic-search",
      "page_title": "Semantic search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic search",
        "h2": "Embedding models [\\#](\\#embedding-models)"
      },
      "text": "\nIt's crucial to remember that when using embedding models with semantic search, you must use the same model for all embedding comparisons. Comparing embeddings created by different models will yield meaningless results.\n",
      "overlap_text": {
        "previous_chunk_id": "159ea8e0-13af-4cf6-84f3-bd091e3de5cd",
        "text": "Content of the previous chunk for context: h1: Semantic search h2: Embedding models [\\#](\\#embedding-models)\n\n the response. Others can run locally on your own compute, such as through Transformers.js for JavaScript implementations. For more information on local implementation, see [Generate embeddings](/docs/guides/ai/quickstarts/generate-text-embeddings).\n"
      }
    }
  },
  {
    "chunk_id": "23d6fe2e-4f50-4fa7-ae13-2bc5b490d683",
    "metadata": {
      "token_count": 129,
      "source_url": "https://supabase.com/docs/guides/ai/semantic-search",
      "page_title": "Semantic search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic search",
        "h2": "Semantic search in Postgres [\\#](\\#semantic-search-in-postgres)"
      },
      "text": "To implement semantic search in Postgres we use `pgvector` \\- an extension that allows for efficient storage and retrieval of high-dimensional vectors. These vectors are numerical representations of text (or other types of data) generated by embedding models.\n\n1. Enable the `pgvector` extension by running:\n\n\n\n`\n_10\ncreate extension vector\n_10\nwith\n_10\nschema extensions;\n`\n\n2. Create a table to store the embeddings:\n\n\n\n`\n_10\ncreate table documents (\n_10\nid bigint primary key generated always as identity,\n_10\ncontent text,\n_10\nembedding vector(512)\n_10\n);\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "11c52703-1cef-457f-a174-dd1360a86d9a",
        "text": "Content of the previous chunk for context: h1: Semantic search h2: Embedding models [\\#](\\#embedding-models)\n\n\nIt's crucial to remember that when using embedding models with semantic search, you must use the same model for all embedding comparisons. Comparing embeddings created by different models will yield meaningless results.\n"
      }
    }
  },
  {
    "chunk_id": "87f634b3-a8dd-48ab-9ba5-d198653c2186",
    "metadata": {
      "token_count": 102,
      "source_url": "https://supabase.com/docs/guides/ai/semantic-search",
      "page_title": "Semantic search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic search",
        "h2": "Semantic search in Postgres [\\#](\\#semantic-search-in-postgres)"
      },
      "text": "\n\nOr if you have an existing table, you can add a vector column like so:\n\n\n\n`\n_10\nalter table documents\n_10\nadd column embedding vector(512);\n`\n\n\n\nIn this example, we create a column named `embedding` which uses the newly enabled `vector` data type. The size of the vector (as indicated in parentheses) represents the number of dimensions in the embedding. Here we use 512, but adjust this to match the number of dimensions produced by your embedding model.\n",
      "overlap_text": {
        "previous_chunk_id": "23d6fe2e-4f50-4fa7-ae13-2bc5b490d683",
        "text": "Content of the previous chunk for context: h1: Semantic search h2: Semantic search in Postgres [\\#](\\#semantic-search-in-postgres)\n\n`\n\n2. Create a table to store the embeddings:\n\n\n\n`\n_10\ncreate table documents (\n_10\nid bigint primary key generated always as identity,\n_10\ncontent text,\n_10\nembedding vector(512)\n_10\n);\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "c340bef7-4211-4578-b4e7-f5af2a4240cf",
    "metadata": {
      "token_count": 100,
      "source_url": "https://supabase.com/docs/guides/ai/semantic-search",
      "page_title": "Semantic search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic search",
        "h2": "Semantic search in Postgres [\\#](\\#semantic-search-in-postgres)"
      },
      "text": "\n\nFor more details on vector columns, including how to generate embeddings and store them, see [Vector columns](/docs/guides/ai/vector-columns).\n\n### Similarity metric [\\#](\\#similarity-metric)\n\n`pgvector` support 3 operators for computing distance between embeddings:\n\n| **Operator** | **Description** |\n| --- | --- |\n| `<->` | Euclidean distance |\n| `<#>` | negative inner product |\n| `<=>` | cosine distance |\n\n",
      "overlap_text": {
        "previous_chunk_id": "87f634b3-a8dd-48ab-9ba5-d198653c2186",
        "text": "Content of the previous chunk for context: h1: Semantic search h2: Semantic search in Postgres [\\#](\\#semantic-search-in-postgres)\n\n the newly enabled `vector` data type. The size of the vector (as indicated in parentheses) represents the number of dimensions in the embedding. Here we use 512, but adjust this to match the number of dimensions produced by your embedding model.\n"
      }
    }
  },
  {
    "chunk_id": "9fe94f2c-24dc-4dd3-a15a-276b601d0ae0",
    "metadata": {
      "token_count": 194,
      "source_url": "https://supabase.com/docs/guides/ai/semantic-search",
      "page_title": "Semantic search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic search",
        "h2": "Semantic search in Postgres [\\#](\\#semantic-search-in-postgres)"
      },
      "text": "These operators are used directly in your SQL query to retrieve records that are most similar to the user's search query. Choosing the right operator depends on your needs. Inner product (also known as dot product) tends to be the fastest if your vectors are normalized.\n\nThe easiest way to perform semantic search in Postgres in by creating a function:\n\n`\n_15\n-- Match documents using cosine distance (<=>)\n_15\ncreate or replace function match_documents (\n_15\nquery_embedding vector(512),\n_15\nmatch_threshold float,\n_15\nmatch_count int\n_15\n)\n_15\nreturns setof documents\n_15\nlanguage sql\n_15\nas $$\n_15\nselect *\n_15\nfrom documents\n_15\nwhere documents.embedding <=> query_embedding < 1 - match_threshold\n_15\norder by documents.embedding <=> query_embedding asc\n_15\nlimit least(match_count, 200);\n_15\n$$;\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "c340bef7-4211-4578-b4e7-f5af2a4240cf",
        "text": "Content of the previous chunk for context: h1: Semantic search h2: Semantic search in Postgres [\\#](\\#semantic-search-in-postgres)\n\n support 3 operators for computing distance between embeddings:\n\n| **Operator** | **Description** |\n| --- | --- |\n| `<->` | Euclidean distance |\n| `<#>` | negative inner product |\n| `<=>` | cosine distance |\n\n"
      }
    }
  },
  {
    "chunk_id": "c0c651a0-87b3-47fa-92e5-fce8617db7b4",
    "metadata": {
      "token_count": 142,
      "source_url": "https://supabase.com/docs/guides/ai/semantic-search",
      "page_title": "Semantic search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic search",
        "h2": "Semantic search in Postgres [\\#](\\#semantic-search-in-postgres)"
      },
      "text": "Here we create a function `match_documents` that accepts three parameters:\n\n1. `query_embedding`: a one-time embedding generated for the user's search query. Here we set the size to 512, but adjust this to match the number of dimensions produced by your embedding model.\n2. `match_threshold`: the minimum similarity between embeddings. This is a value between 1 and -1, where 1 is most similar and -1 is most dissimilar.\n3. `match_count`: the maximum number of results to return. Note the query may return less than this number if `match_threshold` resulted in a small shortlist. Limited to 200 records to avoid unintentionally overloading your database.\n",
      "overlap_text": {
        "previous_chunk_id": "9fe94f2c-24dc-4dd3-a15a-276b601d0ae0",
        "text": "Content of the previous chunk for context: h1: Semantic search h2: Semantic search in Postgres [\\#](\\#semantic-search-in-postgres)\n\n15\nfrom documents\n_15\nwhere documents.embedding <=> query_embedding < 1 - match_threshold\n_15\norder by documents.embedding <=> query_embedding asc\n_15\nlimit least(match_count, 200);\n_15\n$$;\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "8f846126-0f06-48fd-a3f7-1515ba907e31",
    "metadata": {
      "token_count": 109,
      "source_url": "https://supabase.com/docs/guides/ai/semantic-search",
      "page_title": "Semantic search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic search",
        "h2": "Semantic search in Postgres [\\#](\\#semantic-search-in-postgres)"
      },
      "text": "\nIn this example, we return a `setof documents` and refer to `documents` throughout the query. Adjust this to use the relevant tables in your application.\n\nYou'll notice we are using the cosine distance ( `<=>`) operator in our query. Cosine distance is a safe default when you don't know whether or not your embeddings are normalized. If you know for a fact that they are normalized (for example, your embedding is returned from OpenAI), you can use negative inner product ( `<#>`) for better performance:\n",
      "overlap_text": {
        "previous_chunk_id": "c0c651a0-87b3-47fa-92e5-fce8617db7b4",
        "text": "Content of the previous chunk for context: h1: Semantic search h2: Semantic search in Postgres [\\#](\\#semantic-search-in-postgres)\n\n.\n3. `match_count`: the maximum number of results to return. Note the query may return less than this number if `match_threshold` resulted in a small shortlist. Limited to 200 records to avoid unintentionally overloading your database.\n"
      }
    }
  },
  {
    "chunk_id": "ccfdf7d3-8669-4576-bae9-f379ac629494",
    "metadata": {
      "token_count": 130,
      "source_url": "https://supabase.com/docs/guides/ai/semantic-search",
      "page_title": "Semantic search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic search",
        "h2": "Semantic search in Postgres [\\#](\\#semantic-search-in-postgres)"
      },
      "text": "\n`\n_15\n-- Match documents using negative inner product (<#>)\n_15\ncreate or replace function match_documents (\n_15\nquery_embedding vector(512),\n_15\nmatch_threshold float,\n_15\nmatch_count int\n_15\n)\n_15\nreturns setof documents\n_15\nlanguage sql\n_15\nas $$\n_15\nselect *\n_15\nfrom documents\n_15\nwhere documents.embedding <#> query_embedding < -match_threshold\n_15\norder by documents.embedding <#> query_embedding asc\n_15\nlimit least(match_count, 200);\n_15\n$$;\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "8f846126-0f06-48fd-a3f7-1515ba907e31",
        "text": "Content of the previous chunk for context: h1: Semantic search h2: Semantic search in Postgres [\\#](\\#semantic-search-in-postgres)\n\n when you don't know whether or not your embeddings are normalized. If you know for a fact that they are normalized (for example, your embedding is returned from OpenAI), you can use negative inner product ( `<#>`) for better performance:\n"
      }
    }
  },
  {
    "chunk_id": "38a7838c-9e72-4456-a837-57285f7f45d8",
    "metadata": {
      "token_count": 126,
      "source_url": "https://supabase.com/docs/guides/ai/semantic-search",
      "page_title": "Semantic search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic search",
        "h2": "Semantic search in Postgres [\\#](\\#semantic-search-in-postgres)"
      },
      "text": "Note that since `<#>` is negative, we negate `match_threshold` accordingly in the `where` clause. For more information on the different operators, see the [pgvector docs](https://github.com/pgvector/pgvector?tab=readme-ov-file#vector-operators).\n\n### Calling from your application [\\#](\\#calling-from-your-application)\n\nFinally you can execute this function from your application. If you are using a Supabase client library such as [`supabase-js`](https://github.com/supabase/supabase-js), you can invoke it using the `rpc()` method:\n",
      "overlap_text": {
        "previous_chunk_id": "ccfdf7d3-8669-4576-bae9-f379ac629494",
        "text": "Content of the previous chunk for context: h1: Semantic search h2: Semantic search in Postgres [\\#](\\#semantic-search-in-postgres)\n\nfrom documents\n_15\nwhere documents.embedding <#> query_embedding < -match_threshold\n_15\norder by documents.embedding <#> query_embedding asc\n_15\nlimit least(match_count, 200);\n_15\n$$;\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "21bb5eda-7e56-419a-8efc-9e10fc9ee0fd",
    "metadata": {
      "token_count": 149,
      "source_url": "https://supabase.com/docs/guides/ai/semantic-search",
      "page_title": "Semantic search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic search",
        "h2": "Semantic search in Postgres [\\#](\\#semantic-search-in-postgres)"
      },
      "text": "\n`\n_10\nconst { data: documents } = await supabase.rpc('match_documents', {\n_10\nquery_embedding: embedding, // pass the query embedding\n_10\nmatch_threshold: 0.78, // choose an appropriate threshold for your data\n_10\nmatch_count: 10, // choose the number of matches\n_10\n})\n`\n\nYou can also call this method directly from SQL:\n\n`\n_10\nselect *\n_10\nfrom match_documents(\n_10\n'[...]'::vector(512), -- pass the query embedding\n_10\n0.78, -- chose an appropriate threshold for your data\n_10\n10 -- choose the number of matches\n_10\n);\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "38a7838c-9e72-4456-a837-57285f7f45d8",
        "text": "Content of the previous chunk for context: h1: Semantic search h2: Semantic search in Postgres [\\#](\\#semantic-search-in-postgres)\n\n execute this function from your application. If you are using a Supabase client library such as [`supabase-js`](https://github.com/supabase/supabase-js), you can invoke it using the `rpc()` method:\n"
      }
    }
  },
  {
    "chunk_id": "f3da50c7-01f0-450e-b4ce-f2ad64d84beb",
    "metadata": {
      "token_count": 39,
      "source_url": "https://supabase.com/docs/guides/ai/semantic-search",
      "page_title": "Semantic search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic search",
        "h2": "Semantic search in Postgres [\\#](\\#semantic-search-in-postgres)"
      },
      "text": "In this scenario, you'll likely use a Postgres client library to establish a direct connection from your application to the database. It's best practice to parameterize your arguments before executing the query.\n",
      "overlap_text": {
        "previous_chunk_id": "21bb5eda-7e56-419a-8efc-9e10fc9ee0fd",
        "text": "Content of the previous chunk for context: h1: Semantic search h2: Semantic search in Postgres [\\#](\\#semantic-search-in-postgres)\n\n(\n_10\n'[...]'::vector(512), -- pass the query embedding\n_10\n0.78, -- chose an appropriate threshold for your data\n_10\n10 -- choose the number of matches\n_10\n);\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "120262c1-404f-4ac9-947c-d414edee5e44",
    "metadata": {
      "token_count": 52,
      "source_url": "https://supabase.com/docs/guides/ai/semantic-search",
      "page_title": "Semantic search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic search",
        "h2": "Next steps [\\#](\\#next-steps)"
      },
      "text": "As your database scales, you will need an index on your vector columns to maintain fast query speeds. See [Vector indexes](/docs/guides/ai/vector-indexes) for an in-depth guide on the different types of indexes and how they work.\n",
      "overlap_text": {
        "previous_chunk_id": "f3da50c7-01f0-450e-b4ce-f2ad64d84beb",
        "text": "Content of the previous chunk for context: h1: Semantic search h2: Semantic search in Postgres [\\#](\\#semantic-search-in-postgres)\n\nIn this scenario, you'll likely use a Postgres client library to establish a direct connection from your application to the database. It's best practice to parameterize your arguments before executing the query.\n"
      }
    }
  },
  {
    "chunk_id": "4ac5bfb8-93e6-4d2e-8005-03f91afc1805",
    "metadata": {
      "token_count": 80,
      "source_url": "https://supabase.com/docs/guides/ai/semantic-search",
      "page_title": "Semantic search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic search",
        "h2": "See also [\\#](\\#see-also)"
      },
      "text": "- [Embedding concepts](/docs/guides/ai/concepts)\n- [Vector columns](/docs/guides/ai/vector-columns)\n- [Vector indexes](/docs/guides/ai/vector-indexes)\n- [Hybrid search](/docs/guides/ai/hybrid-search)\n- [Keyword search](/docs/guides/ai/keyword-search)\n",
      "overlap_text": {
        "previous_chunk_id": "120262c1-404f-4ac9-947c-d414edee5e44",
        "text": "Content of the previous chunk for context: h1: Semantic search h2: Next steps [\\#](\\#next-steps)\n\n database scales, you will need an index on your vector columns to maintain fast query speeds. See [Vector indexes](/docs/guides/ai/vector-indexes) for an in-depth guide on the different types of indexes and how they work.\n"
      }
    }
  },
  {
    "chunk_id": "dc9818ef-534c-43a7-877a-63a9fd5f6ddf",
    "metadata": {
      "token_count": 119,
      "source_url": "https://supabase.com/docs/guides/ai/python/indexes",
      "page_title": "Indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Indexes"
      },
      "text": "* * *\n\n# Indexes\n\nIndexes are tools for optimizing query performance of a [collection](collections).\n\nCollections can be [queried](https://supabase.github.io/vecs/../api.md#query) without an index, but that will emit a python warning and should never be done in production.\n\n`\n_10\nquery does not have a covering index for cosine_similarity. See Collection.create_index\n`\n\nAs each query vector must be checked against every record in the collection. When the number of dimensions and/or number of records becomes large, that becomes extremely slow and computationally expensive.\n"
    }
  },
  {
    "chunk_id": "8dff8b3a-41b4-4b2c-bc5e-7832410183fb",
    "metadata": {
      "token_count": 100,
      "source_url": "https://supabase.com/docs/guides/ai/python/indexes",
      "page_title": "Indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Indexes"
      },
      "text": "\nAn index is a heuristic data structure that pre-computes distances between key points in the vector space. It is smaller and can be traversed more quickly than the whole collection enabling much more performant searching.\n\nOnly one index may exist per-collection. An index optimizes a collection for searching according to a selected distance measure.\n\nTo create an index:\n\n`\n_10\ndocs.create_index()\n`\n\nYou may optionally provide a distance measure and index method.\n\nAvailable options for distance `measure` are:\n",
      "overlap_text": {
        "previous_chunk_id": "dc9818ef-534c-43a7-877a-63a9fd5f6ddf",
        "text": "Content of the previous chunk for context: h1: Indexes\n\n have a covering index for cosine_similarity. See Collection.create_index\n`\n\nAs each query vector must be checked against every record in the collection. When the number of dimensions and/or number of records becomes large, that becomes extremely slow and computationally expensive.\n"
      }
    }
  },
  {
    "chunk_id": "00bd93b4-e476-4789-962b-0333373e845c",
    "metadata": {
      "token_count": 106,
      "source_url": "https://supabase.com/docs/guides/ai/python/indexes",
      "page_title": "Indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Indexes"
      },
      "text": "\n- `vecs.IndexMeasure.cosine_distance`\n- `vecs.IndexMeasure.l2_distance`\n- `vecs.IndexMeasure.max_inner_product`\n\nwhich correspond to different methods for comparing query vectors to the vectors in the database.\n\nIf you aren't sure which to use, the default of cosine\\_distance is the most widely compatible with off-the-shelf embedding methods.\n\nAvailable options for index `method` are:\n\n- `vecs.IndexMethod.auto`\n- `vecs.IndexMethod.hnsw`\n- `vecs.IndexMethod.ivfflat`\n",
      "overlap_text": {
        "previous_chunk_id": "8dff8b3a-41b4-4b2c-bc5e-7832410183fb",
        "text": "Content of the previous chunk for context: h1: Indexes\n\n. An index optimizes a collection for searching according to a selected distance measure.\n\nTo create an index:\n\n`\n_10\ndocs.create_index()\n`\n\nYou may optionally provide a distance measure and index method.\n\nAvailable options for distance `measure` are:\n"
      }
    }
  },
  {
    "chunk_id": "6a54877e-ab98-4802-b61a-26ccda640f8f",
    "metadata": {
      "token_count": 161,
      "source_url": "https://supabase.com/docs/guides/ai/python/indexes",
      "page_title": "Indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Indexes"
      },
      "text": "\nWhere `auto` selects the best available index method, `hnsw` uses the [HNSW](https://github.com/pgvector/pgvector#hnsw) method and `ivfflat` uses [IVFFlat](https://github.com/pgvector/pgvector#ivfflat).\n\nHNSW and IVFFlat indexes both allow for parameterization to control the speed/accuracy tradeoff. vecs provides sane defaults for these parameters. For a greater level of control you can optionally pass an instance of `vecs.IndexArgsIVFFlat` or `vecs.IndexArgsHNSW` to `create_index`'s `index_arguments` argument. Descriptions of the impact for each parameter are available in the [pgvector docs](https://github.com/pgvector/pgvector).\n",
      "overlap_text": {
        "previous_chunk_id": "00bd93b4-e476-4789-962b-0333373e845c",
        "text": "Content of the previous chunk for context: h1: Indexes\n\n cosine\\_distance is the most widely compatible with off-the-shelf embedding methods.\n\nAvailable options for index `method` are:\n\n- `vecs.IndexMethod.auto`\n- `vecs.IndexMethod.hnsw`\n- `vecs.IndexMethod.ivfflat`\n"
      }
    }
  },
  {
    "chunk_id": "a31c9611-69ae-4d69-9b91-15bad035b60f",
    "metadata": {
      "token_count": 118,
      "source_url": "https://supabase.com/docs/guides/ai/python/indexes",
      "page_title": "Indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Indexes"
      },
      "text": "\nWhen using IVFFlat indexes, the index must be created **after** the collection has been populated with records. Building an IVFFlat index on an empty collection will result in significantly reduced recall. You can continue upserting new documents after the index has been created, but should rebuild the index if the size of the collection more than doubles since the last index operation.\n\nHNSW indexes can be created immediately after the collection without populating records.\n\nTo manually specify `method`, `measure`, and `index_arguments` add them as arguments to `create_index` for example:\n",
      "overlap_text": {
        "previous_chunk_id": "6a54877e-ab98-4802-b61a-26ccda640f8f",
        "text": "Content of the previous chunk for context: h1: Indexes\n\nlat` or `vecs.IndexArgsHNSW` to `create_index`'s `index_arguments` argument. Descriptions of the impact for each parameter are available in the [pgvector docs](https://github.com/pgvector/pgvector).\n"
      }
    }
  },
  {
    "chunk_id": "b7fa1013-1859-4a36-a745-198185cce32b",
    "metadata": {
      "token_count": 98,
      "source_url": "https://supabase.com/docs/guides/ai/python/indexes",
      "page_title": "Indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Indexes"
      },
      "text": "\n`\n_10\ndocs.create_index(\n_10\n    method=IndexMethod.hnsw,\n_10\n    measure=IndexMeasure.cosine_distance,\n_10\n    index_arguments=IndexArgsHNSW(m=8),\n_10\n)\n`\n\nThe time required to create an index grows with the number of records and size of vectors.\nFor a few thousand records expect sub-minute a response in under a minute. It may take a few\nminutes for larger collections.\n",
      "overlap_text": {
        "previous_chunk_id": "a31c9611-69ae-4d69-9b91-15bad035b60f",
        "text": "Content of the previous chunk for context: h1: Indexes\n\n than doubles since the last index operation.\n\nHNSW indexes can be created immediately after the collection without populating records.\n\nTo manually specify `method`, `measure`, and `index_arguments` add them as arguments to `create_index` for example:\n"
      }
    }
  },
  {
    "chunk_id": "8b4ebaf6-5cfe-41a5-bacb-97e00055baca",
    "metadata": {
      "token_count": 170,
      "source_url": "https://supabase.com/docs/guides/ai/python-clients",
      "page_title": "Choosing a Client | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Choosing a Client"
      },
      "text": "* * *\n\nAs described in [Structured & Unstructured Embeddings](/docs/guides/ai/structured-unstructured), AI workloads come in many forms.\n\nFor data science or ephemeral workloads, the [Supabase Vecs](https://supabase.github.io/vecs/) client gets you started quickly. All you need is a connection string and vecs handles setting up your database to store and query vectors with associated metadata.\n\nYou can get your connection string from the [**Database Settings**](https://supabase.com/dashboard/project/_/settings/database) page in your dashboard. Make sure to check **Use connection pooling**, then copy the URI. Also, change the URI scheme from `postgres` to `postgresql`. `vecs` uses SQLAlchemy under the hood, which only supports `postgresql` as a dialect.\n"
    }
  },
  {
    "chunk_id": "9c136710-638b-44c6-87f7-02514b7ba99e",
    "metadata": {
      "token_count": 72,
      "source_url": "https://supabase.com/docs/guides/ai/python-clients",
      "page_title": "Choosing a Client | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Choosing a Client"
      },
      "text": "\nFor production python applications with version controlled migrations, we recommend adding first class vector support to your toolchain by [registering the vector type with your ORM](https://github.com/pgvector/pgvector-python). pgvector provides bindings for the most commonly used SQL drivers/libraries including Django, SQLAlchemy, SQLModel, psycopg, asyncpg and Peewee.\n",
      "overlap_text": {
        "previous_chunk_id": "8b4ebaf6-5cfe-41a5-bacb-97e00055baca",
        "text": "Content of the previous chunk for context: h1: Choosing a Client\n\n your dashboard. Make sure to check **Use connection pooling**, then copy the URI. Also, change the URI scheme from `postgres` to `postgresql`. `vecs` uses SQLAlchemy under the hood, which only supports `postgresql` as a dialect.\n"
      }
    }
  },
  {
    "chunk_id": "1c9ec8f0-74b1-4c88-b214-62ffe40fe0d8",
    "metadata": {
      "token_count": 37,
      "source_url": "https://supabase.com/docs/guides/ai/python/metadata",
      "page_title": "Metadata | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Metadata"
      },
      "text": "* * *\n\n# Metadata\n\nvecs allows you to associate key-value pairs of metadata with indexes and ids in your collections.\nYou can then add filters to queries that reference the metadata metadata.\n"
    }
  },
  {
    "chunk_id": "6f5c873e-695f-49ba-b4b0-dd0f7708c2de",
    "metadata": {
      "token_count": 61,
      "source_url": "https://supabase.com/docs/guides/ai/python/metadata",
      "page_title": "Metadata | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Metadata",
        "h2": "Types [\\#](\\#types)"
      },
      "text": "Metadata is stored as binary JSON. As a result, allowed metadata types are drawn from JSON primitive types.\n\n- Boolean\n- String\n- Number\n\nThe technical limit of a metadata field associated with a vector is 1GB.\nIn practice you should keep metadata fields as small as possible to maximize performance.\n",
      "overlap_text": {
        "previous_chunk_id": "1c9ec8f0-74b1-4c88-b214-62ffe40fe0d8",
        "text": "Content of the previous chunk for context: h1: Metadata\n\n* * *\n\n# Metadata\n\nvecs allows you to associate key-value pairs of metadata with indexes and ids in your collections.\nYou can then add filters to queries that reference the metadata metadata.\n"
      }
    }
  },
  {
    "chunk_id": "572cdb3e-1258-44e4-ae59-4da047c0fec7",
    "metadata": {
      "token_count": 200,
      "source_url": "https://supabase.com/docs/guides/ai/python/metadata",
      "page_title": "Metadata | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Metadata",
        "h2": "Metadata Query Language [\\#](\\#metadata-query-language)"
      },
      "text": "The metadata query language is based loosely on [mongodb's selectors](https://www.mongodb.com/docs/manual/reference/operator/query/).\n\n`vecs` currently supports a subset of those operators.\n\n### Comparison Operators [\\#](\\#comparison-operators)\n\nComparison operators compare a provided value with a value stored in metadata field of the vector store.\n\n| Operator | Description |\n| --- | --- |\n| $eq | Matches values that are equal to a specified value |\n| $ne | Matches values that are not equal to a specified value |\n| $gt | Matches values that are greater than a specified value |\n| $gte | Matches values that are greater than or equal to a specified value |\n| $lt | Matches values that are less than a specified value |\n| $lte | Matches values that are less than or equal to a specified value |\n| $in | Matches values that are contained by scalar list of specified values |\n| $contains | Matches values where a scalar is contained within an array metadata field |\n\n",
      "overlap_text": {
        "previous_chunk_id": "6f5c873e-695f-49ba-b4b0-dd0f7708c2de",
        "text": "Content of the previous chunk for context: h1: Metadata h2: Types [\\#](\\#types)\n\n allowed metadata types are drawn from JSON primitive types.\n\n- Boolean\n- String\n- Number\n\nThe technical limit of a metadata field associated with a vector is 1GB.\nIn practice you should keep metadata fields as small as possible to maximize performance.\n"
      }
    }
  },
  {
    "chunk_id": "f3409c4f-c190-42dd-b86b-0f496f1b1a23",
    "metadata": {
      "token_count": 117,
      "source_url": "https://supabase.com/docs/guides/ai/python/metadata",
      "page_title": "Metadata | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Metadata",
        "h2": "Metadata Query Language [\\#](\\#metadata-query-language)"
      },
      "text": "### Logical Operators [\\#](\\#logical-operators)\n\nLogical operators compose other operators, and can be nested.\n\n| Operator | Description |\n| --- | --- |\n| $and | Joins query clauses with a logical AND returns all documents that match the conditions of both clauses. |\n| $or | Joins query clauses with a logical OR returns all documents that match the conditions of either clause. |\n\n### Performance [\\#](\\#performance)\n\nFor best performance, use scalar key-value pairs for metadata and prefer `$eq`, `$and` and `$or` filters where possible.\n",
      "overlap_text": {
        "previous_chunk_id": "572cdb3e-1258-44e4-ae59-4da047c0fec7",
        "text": "Content of the previous chunk for context: h1: Metadata h2: Metadata Query Language [\\#](\\#metadata-query-language)\n\n| $lte | Matches values that are less than or equal to a specified value |\n| $in | Matches values that are contained by scalar list of specified values |\n| $contains | Matches values where a scalar is contained within an array metadata field |\n\n"
      }
    }
  },
  {
    "chunk_id": "94c6de02-7893-4979-acd1-b32c473b9f57",
    "metadata": {
      "token_count": 131,
      "source_url": "https://supabase.com/docs/guides/ai/python/metadata",
      "page_title": "Metadata | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Metadata",
        "h2": "Metadata Query Language [\\#](\\#metadata-query-language)"
      },
      "text": "Those variants are most consistently able to make use of indexes.\n\n### Examples [\\#](\\#examples)\n\n* * *\n\n`year` equals 2020\n\n`\n_10\n{\"year\": {\"$eq\": 2020}}\n`\n\n* * *\n\n`year` equals 2020 or `gross` greater than or equal to 5000.0\n\n`\n_10\n{\n_10\n    \"$or\": [\\\n_10\\\n        {\"year\": {\"$eq\": 2020}},\\\n_10\\\n        {\"gross\": {\"$gte\": 5000.0}}\\\n_10\\\n    ]\n_10\n}\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "f3409c4f-c190-42dd-b86b-0f496f1b1a23",
        "text": "Content of the previous chunk for context: h1: Metadata h2: Metadata Query Language [\\#](\\#metadata-query-language)\n\n logical OR returns all documents that match the conditions of either clause. |\n\n### Performance [\\#](\\#performance)\n\nFor best performance, use scalar key-value pairs for metadata and prefer `$eq`, `$and` and `$or` filters where possible.\n"
      }
    }
  },
  {
    "chunk_id": "893c4a32-cf8f-4964-961b-e5f69a6ba7ed",
    "metadata": {
      "token_count": 126,
      "source_url": "https://supabase.com/docs/guides/ai/python/metadata",
      "page_title": "Metadata | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Metadata",
        "h2": "Metadata Query Language [\\#](\\#metadata-query-language)"
      },
      "text": "* * *\n\n`last_name` is less than \"Brown\" and `is_priority_customer` is true\n\n`\n_10\n{\n_10\n    \"$and\": [\\\n_10\\\n        {\"last_name\": {\"$lt\": \"Brown\"}},\\\n_10\\\n        {\"is_priority_customer\": {\"$gte\": 5000.00}}\\\n_10\\\n    ]\n_10\n}\n`\n\n* * *\n\n`priority` contained by \\[\"enterprise\", \"pro\"\\]\n\n`\n_10\n{\n_10\n    \"priority\": {\"$in\": [\"enterprise\", \"pro\"]}\n_10\n}\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "94c6de02-7893-4979-acd1-b32c473b9f57",
        "text": "Content of the previous chunk for context: h1: Metadata h2: Metadata Query Language [\\#](\\#metadata-query-language)\n\n    \"$or\": [\\\n_10\\\n        {\"year\": {\"$eq\": 2020}},\\\n_10\\\n        {\"gross\": {\"$gte\": 5000.0}}\\\n_10\\\n    ]\n_10\n}\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "aef1c013-60f5-4e20-9c23-79a3bdb4c953",
    "metadata": {
      "token_count": 36,
      "source_url": "https://supabase.com/docs/guides/ai/python/metadata",
      "page_title": "Metadata | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Metadata",
        "h2": "Metadata Query Language [\\#](\\#metadata-query-language)"
      },
      "text": "`tags`, an array, contains the string \"important\"\n\n`\n_10\n{\n_10\n    \"tags\": {\"$contains\": \"important\"}\n_10\n}\n`\n",
      "overlap_text": {
        "previous_chunk_id": "893c4a32-cf8f-4964-961b-e5f69a6ba7ed",
        "text": "Content of the previous chunk for context: h1: Metadata h2: Metadata Query Language [\\#](\\#metadata-query-language)\n\n    ]\n_10\n}\n`\n\n* * *\n\n`priority` contained by \\[\"enterprise\", \"pro\"\\]\n\n`\n_10\n{\n_10\n    \"priority\": {\"$in\": [\"enterprise\", \"pro\"]}\n_10\n}\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "5b2d6617-3573-45af-9598-38cbf2261b65",
    "metadata": {
      "token_count": 109,
      "source_url": "https://supabase.com/docs/guides/ai/examples/mixpeek-video-search",
      "page_title": "Video Search with Mixpeek Multimodal Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Video Search with Mixpeek Multimodal Embeddings",
        "h2": "Implement video search with the Mixpeek Multimodal Embed API and Supabase Vector."
      },
      "text": "* * *\n\nThe [Mixpeek Embed API](https://docs.mixpeek.com/api-documentation/inference/embed) allows you to generate embeddings for various types of content, including videos and text. You can use these embeddings for:\n\n- Text-to-Video / Video-To-Text / Video-to-Video / Text-to-Text Search\n- Fine-tuning on your own video and text data\n\nThis guide demonstrates how to implement video search using Mixpeek Embed for video processing and embedding, and Supabase Vector for storing and querying embeddings.\n"
    }
  },
  {
    "chunk_id": "6c53a693-191e-475c-b84d-a262c325f8bb",
    "metadata": {
      "token_count": 30,
      "source_url": "https://supabase.com/docs/guides/ai/examples/mixpeek-video-search",
      "page_title": "Video Search with Mixpeek Multimodal Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Video Search with Mixpeek Multimodal Embeddings",
        "h2": "Implement video search with the Mixpeek Multimodal Embed API and Supabase Vector."
      },
      "text": "\nYou can find the full application code as a Python Poetry project on [GitHub](https://github.com/yourusername/your-repo-name).\n",
      "overlap_text": {
        "previous_chunk_id": "5b2d6617-3573-45af-9598-38cbf2261b65",
        "text": "Content of the previous chunk for context: h1: Video Search with Mixpeek Multimodal Embeddings h2: Implement video search with the Mixpeek Multimodal Embed API and Supabase Vector.\n\n-Video / Text-to-Text Search\n- Fine-tuning on your own video and text data\n\nThis guide demonstrates how to implement video search using Mixpeek Embed for video processing and embedding, and Supabase Vector for storing and querying embeddings.\n"
      }
    }
  },
  {
    "chunk_id": "5e61b31d-eee8-45f6-98fa-c1f710f07836",
    "metadata": {
      "token_count": 56,
      "source_url": "https://supabase.com/docs/guides/ai/examples/mixpeek-video-search",
      "page_title": "Video Search with Mixpeek Multimodal Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Video Search with Mixpeek Multimodal Embeddings",
        "h2": "Create a new Python project with Poetry [\\#](\\#create-a-new-python-project-with-poetry)"
      },
      "text": "[Poetry](https://python-poetry.org/) provides packaging and dependency management for Python. If you haven't already, install poetry via pip:\n\n`\n_10\npip install poetry\n`\n\nThen initialize a new project:\n\n`\n_10\npoetry new video-search\n`\n",
      "overlap_text": {
        "previous_chunk_id": "6c53a693-191e-475c-b84d-a262c325f8bb",
        "text": "Content of the previous chunk for context: h1: Video Search with Mixpeek Multimodal Embeddings h2: Implement video search with the Mixpeek Multimodal Embed API and Supabase Vector.\n\n\nYou can find the full application code as a Python Poetry project on [GitHub](https://github.com/yourusername/your-repo-name).\n"
      }
    }
  },
  {
    "chunk_id": "dbe0e043-ec74-4300-8875-942f2e3269b1",
    "metadata": {
      "token_count": 106,
      "source_url": "https://supabase.com/docs/guides/ai/examples/mixpeek-video-search",
      "page_title": "Video Search with Mixpeek Multimodal Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Video Search with Mixpeek Multimodal Embeddings",
        "h2": "Setup Supabase project [\\#](\\#setup-supabase-project)"
      },
      "text": "If you haven't already, [install the Supabase CLI](https://supabase.com/docs/guides/cli), then initialize Supabase in the root of your newly created poetry project:\n\n`\n_10\nsupabase init\n`\n\nNext, start your local Supabase stack:\n\n`\n_10\nsupabase start\n`\n\nThis will start up the Supabase stack locally and print out a bunch of environment details, including your local `DB URL`. Make a note of that for later use.\n",
      "overlap_text": {
        "previous_chunk_id": "5e61b31d-eee8-45f6-98fa-c1f710f07836",
        "text": "Content of the previous chunk for context: h1: Video Search with Mixpeek Multimodal Embeddings h2: Create a new Python project with Poetry [\\#](\\#create-a-new-python-project-with-poetry)\n\npython-poetry.org/) provides packaging and dependency management for Python. If you haven't already, install poetry via pip:\n\n`\n_10\npip install poetry\n`\n\nThen initialize a new project:\n\n`\n_10\npoetry new video-search\n`\n"
      }
    }
  },
  {
    "chunk_id": "f05dce49-04e9-4efa-8b5e-72bea148e668",
    "metadata": {
      "token_count": 73,
      "source_url": "https://supabase.com/docs/guides/ai/examples/mixpeek-video-search",
      "page_title": "Video Search with Mixpeek Multimodal Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Video Search with Mixpeek Multimodal Embeddings",
        "h2": "Install the dependencies [\\#](\\#install-the-dependencies)"
      },
      "text": "Add the following dependencies to your project:\n\n- [`supabase`](https://github.com/supabase-community/supabase-py): Supabase Python Client\n- [`mixpeek`](https://github.com/mixpeek/python-client): Mixpeek Python Client for embedding generation\n\n`\n_10\npoetry add supabase mixpeek\n`\n",
      "overlap_text": {
        "previous_chunk_id": "dbe0e043-ec74-4300-8875-942f2e3269b1",
        "text": "Content of the previous chunk for context: h1: Video Search with Mixpeek Multimodal Embeddings h2: Setup Supabase project [\\#](\\#setup-supabase-project)\n\n Supabase stack:\n\n`\n_10\nsupabase start\n`\n\nThis will start up the Supabase stack locally and print out a bunch of environment details, including your local `DB URL`. Make a note of that for later use.\n"
      }
    }
  },
  {
    "chunk_id": "5b0da188-4a40-411a-b31a-854769600793",
    "metadata": {
      "token_count": 105,
      "source_url": "https://supabase.com/docs/guides/ai/examples/mixpeek-video-search",
      "page_title": "Video Search with Mixpeek Multimodal Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Video Search with Mixpeek Multimodal Embeddings",
        "h2": "Import the necessary dependencies [\\#](\\#import-the-necessary-dependencies)"
      },
      "text": "At the top of your main Python script, import the dependencies and store your environment variables:\n\n`\n_10\nfrom supabase import create_client, Client\n_10\nfrom mixpeek import Mixpeek\n_10\nimport os\n_10\n_10\nSUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n_10\nSUPABASE_KEY = os.getenv(\"SUPABASE_API_KEY\")\n_10\nMIXPEEK_API_KEY = os.getenv(\"MIXPEEK_API_KEY\")\n`\n",
      "overlap_text": {
        "previous_chunk_id": "f05dce49-04e9-4efa-8b5e-72bea148e668",
        "text": "Content of the previous chunk for context: h1: Video Search with Mixpeek Multimodal Embeddings h2: Install the dependencies [\\#](\\#install-the-dependencies)\n\n/supabase-py): Supabase Python Client\n- [`mixpeek`](https://github.com/mixpeek/python-client): Mixpeek Python Client for embedding generation\n\n`\n_10\npoetry add supabase mixpeek\n`\n"
      }
    }
  },
  {
    "chunk_id": "5ce62362-0c6c-4979-be30-1600038981a1",
    "metadata": {
      "token_count": 287,
      "source_url": "https://supabase.com/docs/guides/ai/examples/mixpeek-video-search",
      "page_title": "Video Search with Mixpeek Multimodal Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Video Search with Mixpeek Multimodal Embeddings",
        "h2": "Create embeddings for your videos [\\#](\\#create-embeddings-for-your-videos)"
      },
      "text": "Next, create a `seed` method, which will create a new Supabase table, generate embeddings for your video chunks, and insert the embeddings into your database:\n\n`\n_46\ndef seed():\n_46\n    # Initialize Supabase and Mixpeek clients\n_46\n    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n_46\n    mixpeek = Mixpeek(MIXPEEK_API_KEY)\n_46\n_46\n    # Create a table for storing video chunk embeddings\n_46\n    supabase.table(\"video_chunks\").create({\n_46\n        \"id\": \"text\",\n_46\n        \"start_time\": \"float8\",\n_46\n        \"end_time\": \"float8\",\n_46\n        \"embedding\": \"vector(768)\",\n_46\n        \"metadata\": \"jsonb\"\n_46\n    })\n_46\n_46\n    # Process and embed video\n_46\n    video_url = \"https://example.com/your_video.mp4\"\n_46\n    processed_chunks = mixpeek.tools.video.process(\n_46\n        video_source=video_url,\n_46\n        chunk_interval=1,  # 1 second intervals\n_46\n        resolution=[720, 1280]\n_46\n    )\n_46\n_46\n    for chunk in processed_chunks:\n",
      "overlap_text": {
        "previous_chunk_id": "5b0da188-4a40-411a-b31a-854769600793",
        "text": "Content of the previous chunk for context: h1: Video Search with Mixpeek Multimodal Embeddings h2: Import the necessary dependencies [\\#](\\#import-the-necessary-dependencies)\n\nABASE_URL = os.getenv(\"SUPABASE_URL\")\n_10\nSUPABASE_KEY = os.getenv(\"SUPABASE_API_KEY\")\n_10\nMIXPEEK_API_KEY = os.getenv(\"MIXPEEK_API_KEY\")\n`\n"
      }
    }
  },
  {
    "chunk_id": "aa3f5178-b1ef-4309-a682-dc4404ff2c42",
    "metadata": {
      "token_count": 262,
      "source_url": "https://supabase.com/docs/guides/ai/examples/mixpeek-video-search",
      "page_title": "Video Search with Mixpeek Multimodal Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Video Search with Mixpeek Multimodal Embeddings",
        "h2": "Create embeddings for your videos [\\#](\\#create-embeddings-for-your-videos)"
      },
      "text": "_46\n        print(f\"Processing video chunk: {chunk['start_time']}\")\n_46\n_46\n        # Generate embedding using Mixpeek\n_46\n        embed_response = mixpeek.embed.video(\n_46\n            model_id=\"vuse-generic-v1\",\n_46\n            input=chunk['base64_chunk'],\n_46\n            input_type=\"base64\"\n_46\n        )\n_46\n_46\n        # Insert into Supabase\n_46\n        supabase.table(\"video_chunks\").insert({\n_46\n            \"id\": f\"chunk_{chunk['start_time']}\",\n_46\n            \"start_time\": chunk[\"start_time\"],\n_46\n            \"end_time\": chunk[\"end_time\"],\n_46\n            \"embedding\": embed_response['embedding'],\n_46\n            \"metadata\": {\"video_url\": video_url}\n_46\n        }).execute()\n_46\n_46\n    print(\"Video processed and embeddings inserted\")\n_46\n_46\n    # Create index for fast search performance\n_46\n    supabase.query(\"CREATE INDEX ON video_chunks USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100)\").execute()\n_46\n    print(\"Created index\")\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "5ce62362-0c6c-4979-be30-1600038981a1",
        "text": "Content of the previous chunk for context: h1: Video Search with Mixpeek Multimodal Embeddings h2: Create embeddings for your videos [\\#](\\#create-embeddings-for-your-videos)\n\n=video_url,\n_46\n        chunk_interval=1,  # 1 second intervals\n_46\n        resolution=[720, 1280]\n_46\n    )\n_46\n_46\n    for chunk in processed_chunks:\n"
      }
    }
  },
  {
    "chunk_id": "c7c81ec5-43ea-40af-87c5-bb9ddca0b308",
    "metadata": {
      "token_count": 112,
      "source_url": "https://supabase.com/docs/guides/ai/examples/mixpeek-video-search",
      "page_title": "Video Search with Mixpeek Multimodal Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Video Search with Mixpeek Multimodal Embeddings",
        "h2": "Create embeddings for your videos [\\#](\\#create-embeddings-for-your-videos)"
      },
      "text": "Add this method as a script in your `pyproject.toml` file:\n\n`\n_10\n[tool.poetry.scripts]\n_10\nseed = \"video_search.main:seed\"\n_10\nsearch = \"video_search.main:search\"\n`\n\nAfter activating the virtual environment with `poetry shell`, you can now run your seed script via `poetry run seed`. You can inspect the generated embeddings in your local database by visiting the local Supabase dashboard at [localhost:54323](http://localhost:54323/project/default/editor).\n",
      "overlap_text": {
        "previous_chunk_id": "aa3f5178-b1ef-4309-a682-dc4404ff2c42",
        "text": "Content of the previous chunk for context: h1: Video Search with Mixpeek Multimodal Embeddings h2: Create embeddings for your videos [\\#](\\#create-embeddings-for-your-videos)\n\n index for fast search performance\n_46\n    supabase.query(\"CREATE INDEX ON video_chunks USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100)\").execute()\n_46\n    print(\"Created index\")\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "c9893ee2-0b8e-435d-88af-40f203bf2723",
    "metadata": {
      "token_count": 282,
      "source_url": "https://supabase.com/docs/guides/ai/examples/mixpeek-video-search",
      "page_title": "Video Search with Mixpeek Multimodal Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Video Search with Mixpeek Multimodal Embeddings",
        "h2": "Perform a video search from a text query [\\#](\\#perform-a-video-search-from-a-text-query)"
      },
      "text": "With Supabase Vector, you can query your embeddings. You can use either a video clip as search input or alternatively, you can generate an embedding from a string input and use that as the query input:\n\n`\n_32\ndef search():\n_32\n    # Initialize Supabase and Mixpeek clients\n_32\n    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n_32\n    mixpeek = Mixpeek(MIXPEEK_API_KEY)\n_32\n_32\n    # Generate embedding for text query\n_32\n    query_string = \"a car chase scene\"\n_32\n    text_emb = mixpeek.embed.video(\n_32\n        model_id=\"vuse-generic-v1\",\n_32\n        input=query_string,\n_32\n        input_type=\"text\"\n_32\n    )\n_32\n_32\n    # Query the collection\n_32\n    results = supabase.rpc(\n_32\n        'match_video_chunks',\n_32\n        {\n_32\n            'query_embedding': text_emb['embedding'],\n_32\n            'match_threshold': 0.8,\n_32\n            'match_count': 5\n_32\n        }\n_32\n    ).execute()\n_32\n_32\n    # Display the results\n_32\n    if results.data:\n",
      "overlap_text": {
        "previous_chunk_id": "c7c81ec5-43ea-40af-87c5-bb9ddca0b308",
        "text": "Content of the previous chunk for context: h1: Video Search with Mixpeek Multimodal Embeddings h2: Create embeddings for your videos [\\#](\\#create-embeddings-for-your-videos)\n\n`, you can now run your seed script via `poetry run seed`. You can inspect the generated embeddings in your local database by visiting the local Supabase dashboard at [localhost:54323](http://localhost:54323/project/default/editor).\n"
      }
    }
  },
  {
    "chunk_id": "20c4d764-4192-4c7d-ba07-ccc32835a135",
    "metadata": {
      "token_count": 114,
      "source_url": "https://supabase.com/docs/guides/ai/examples/mixpeek-video-search",
      "page_title": "Video Search with Mixpeek Multimodal Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Video Search with Mixpeek Multimodal Embeddings",
        "h2": "Perform a video search from a text query [\\#](\\#perform-a-video-search-from-a-text-query)"
      },
      "text": "_32\n        for result in results.data:\n_32\n            print(f\"Matched chunk from {result['start_time']} to {result['end_time']} seconds\")\n_32\n            print(f\"Video URL: {result['metadata']['video_url']}\")\n_32\n            print(f\"Similarity: {result['similarity']}\")\n_32\n            print(\"---\")\n_32\n    else:\n_32\n        print(\"No matching video chunks found\")\n`\n\nThis query will return the top 5 most similar video chunks from your database.\n",
      "overlap_text": {
        "previous_chunk_id": "c9893ee2-0b8e-435d-88af-40f203bf2723",
        "text": "Content of the previous chunk for context: h1: Video Search with Mixpeek Multimodal Embeddings h2: Perform a video search from a text query [\\#](\\#perform-a-video-search-from-a-text-query)\n\n_threshold': 0.8,\n_32\n            'match_count': 5\n_32\n        }\n_32\n    ).execute()\n_32\n_32\n    # Display the results\n_32\n    if results.data:\n"
      }
    }
  },
  {
    "chunk_id": "0f73f552-1f71-4251-be82-eeeadaf45020",
    "metadata": {
      "token_count": 35,
      "source_url": "https://supabase.com/docs/guides/ai/examples/mixpeek-video-search",
      "page_title": "Video Search with Mixpeek Multimodal Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Video Search with Mixpeek Multimodal Embeddings",
        "h2": "Perform a video search from a text query [\\#](\\#perform-a-video-search-from-a-text-query)"
      },
      "text": "\nYou can now test it out by running `poetry run search`, and you will be presented with the most relevant video chunks to the query \"a car chase scene\".\n",
      "overlap_text": {
        "previous_chunk_id": "20c4d764-4192-4c7d-ba07-ccc32835a135",
        "text": "Content of the previous chunk for context: h1: Video Search with Mixpeek Multimodal Embeddings h2: Perform a video search from a text query [\\#](\\#perform-a-video-search-from-a-text-query)\n\n: {result['similarity']}\")\n_32\n            print(\"---\")\n_32\n    else:\n_32\n        print(\"No matching video chunks found\")\n`\n\nThis query will return the top 5 most similar video chunks from your database.\n"
      }
    }
  },
  {
    "chunk_id": "81c7bf0d-6816-49f8-a879-8dd5b9cf2742",
    "metadata": {
      "token_count": 61,
      "source_url": "https://supabase.com/docs/guides/ai/examples/mixpeek-video-search",
      "page_title": "Video Search with Mixpeek Multimodal Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Video Search with Mixpeek Multimodal Embeddings",
        "h2": "Conclusion [\\#](\\#conclusion)"
      },
      "text": "With just a couple of Python scripts, you are able to implement video search as well as reverse video search using Mixpeek Embed and Supabase Vector. This approach allows for powerful semantic search capabilities that can be integrated into various applications, enabling you to search through video content using both text and video queries.\n",
      "overlap_text": {
        "previous_chunk_id": "0f73f552-1f71-4251-be82-eeeadaf45020",
        "text": "Content of the previous chunk for context: h1: Video Search with Mixpeek Multimodal Embeddings h2: Perform a video search from a text query [\\#](\\#perform-a-video-search-from-a-text-query)\n\n\nYou can now test it out by running `poetry run search`, and you will be presented with the most relevant video chunks to the query \"a car chase scene\".\n"
      }
    }
  },
  {
    "chunk_id": "14801cc5-87fd-4799-945d-6fc3f752ddb8",
    "metadata": {
      "token_count": 37,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes",
      "page_title": "HNSW indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "HNSW indexes"
      },
      "text": "* * *\n\nHNSW is an algorithm for approximate nearest neighbor search. It is a frequently used index type that can improve performance when querying highly-dimensional vectors, like those representing embeddings.\n"
    }
  },
  {
    "chunk_id": "0e240364-2927-43cf-85f1-8b0924ff1acc",
    "metadata": {
      "token_count": 107,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes",
      "page_title": "HNSW indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "HNSW indexes",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "The way you create an HNSW index depends on the distance operator you are using. `pgvector` includes 3 distance operators:\n\n| Operator | Description | [**Operator class**](https://www.postgresql.org/docs/current/sql-createopclass.html) |\n| --- | --- | --- |\n| `<->` | Euclidean distance | `vector_l2_ops` |\n| `<#>` | negative inner product | `vector_ip_ops` |\n| `<=>` | cosine distance | `vector_cosine_ops` |\n\n",
      "overlap_text": {
        "previous_chunk_id": "14801cc5-87fd-4799-945d-6fc3f752ddb8",
        "text": "Content of the previous chunk for context: h1: HNSW indexes\n\n* * *\n\nHNSW is an algorithm for approximate nearest neighbor search. It is a frequently used index type that can improve performance when querying highly-dimensional vectors, like those representing embeddings.\n"
      }
    }
  },
  {
    "chunk_id": "9d8d3247-806c-417d-8534-07108043bd3f",
    "metadata": {
      "token_count": 113,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes",
      "page_title": "HNSW indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "HNSW indexes",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "Use the following SQL commands to create an HNSW index for the operator(s) used in your queries.\n\n### Euclidean L2 distance ( `vector_l2_ops`) [\\#](\\#euclidean-l2-distance--vectorl2ops-)\n\n`\n_10\ncreate index on items using hnsw (column_name vector_l2_ops);\n`\n\n### Inner product ( `vector_ip_ops`) [\\#](\\#inner-product--vectoripops-)\n\n`\n_10\ncreate index on items using hnsw (column_name vector_ip_ops);\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "0e240364-2927-43cf-85f1-8b0924ff1acc",
        "text": "Content of the previous chunk for context: h1: HNSW indexes h2: Usage [\\#](\\#usage)\n\n --- | --- |\n| `<->` | Euclidean distance | `vector_l2_ops` |\n| `<#>` | negative inner product | `vector_ip_ops` |\n| `<=>` | cosine distance | `vector_cosine_ops` |\n\n"
      }
    }
  },
  {
    "chunk_id": "e443452b-7c7d-4872-adf3-88d1d66695b9",
    "metadata": {
      "token_count": 60,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes",
      "page_title": "HNSW indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "HNSW indexes",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "### Cosine distance ( `vector_cosine_ops`) [\\#](\\#cosine-distance--vectorcosineops-)\n\n`\n_10\ncreate index on items using hnsw (column_name vector_cosine_ops);\n`\n\nCurrently vectors with up to 2,000 dimensions can be indexed.\n",
      "overlap_text": {
        "previous_chunk_id": "9d8d3247-806c-417d-8534-07108043bd3f",
        "text": "Content of the previous chunk for context: h1: HNSW indexes h2: Usage [\\#](\\#usage)\n\n (column_name vector_l2_ops);\n`\n\n### Inner product ( `vector_ip_ops`) [\\#](\\#inner-product--vectoripops-)\n\n`\n_10\ncreate index on items using hnsw (column_name vector_ip_ops);\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "7df01c01-569d-452d-86b2-6918d80bd3de",
    "metadata": {
      "token_count": 108,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes",
      "page_title": "HNSW indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "HNSW indexes",
        "h2": "How does HNSW work? [\\#](\\#how-does-hnsw-work)"
      },
      "text": "HNSW uses proximity graphs (graphs connecting nodes based on distance between them) to approximate nearest-neighbor search. To understand HNSW, we can break it down into 2 parts:\n\n- **Hierarchical (H):** The algorithm operates over multiple layers\n- **Navigable Small World (NSW):** Each vector is a node within a graph and is connected to several other nodes\n\n### Hierarchical [\\#](\\#hierarchical)\n\nThe hierarchical aspect of HNSW builds off of the idea of skip lists.\n",
      "overlap_text": {
        "previous_chunk_id": "e443452b-7c7d-4872-adf3-88d1d66695b9",
        "text": "Content of the previous chunk for context: h1: HNSW indexes h2: Usage [\\#](\\#usage)\n\n`) [\\#](\\#cosine-distance--vectorcosineops-)\n\n`\n_10\ncreate index on items using hnsw (column_name vector_cosine_ops);\n`\n\nCurrently vectors with up to 2,000 dimensions can be indexed.\n"
      }
    }
  },
  {
    "chunk_id": "07d93042-7b0a-4292-88ca-d35345704c14",
    "metadata": {
      "token_count": 164,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes",
      "page_title": "HNSW indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "HNSW indexes",
        "h2": "How does HNSW work? [\\#](\\#how-does-hnsw-work)"
      },
      "text": "\nSkip lists are multi-layer linked lists. The bottom layer is a regular linked list connecting an ordered sequence of elements. Each new layer above removes some elements from the underlying layer (based on a fixed probability), producing a sparser subsequence that \u201cskips\u201d over elements.\n\nWhen searching for an element, the algorithm begins at the top layer and traverses its linked list horizontally. If the target element is found, the algorithm stops and returns it. Otherwise if the next element in the list is greater than the target (or `NULL`), the algorithm drops down to the next layer below. Since each layer below is less sparse than the layer above (with the bottom layer connecting all elements), the target will eventually be found. Skip lists offer O(log n) average complexity for both search and insertion/deletion.\n",
      "overlap_text": {
        "previous_chunk_id": "7df01c01-569d-452d-86b2-6918d80bd3de",
        "text": "Content of the previous chunk for context: h1: HNSW indexes h2: How does HNSW work? [\\#](\\#how-does-hnsw-work)\n\n Small World (NSW):** Each vector is a node within a graph and is connected to several other nodes\n\n### Hierarchical [\\#](\\#hierarchical)\n\nThe hierarchical aspect of HNSW builds off of the idea of skip lists.\n"
      }
    }
  },
  {
    "chunk_id": "82475636-6a62-461f-b7e0-1621c0144ac0",
    "metadata": {
      "token_count": 184,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes",
      "page_title": "HNSW indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "HNSW indexes",
        "h2": "How does HNSW work? [\\#](\\#how-does-hnsw-work)"
      },
      "text": "\n### Navigable Small World [\\#](\\#navigable-small-world)\n\nA navigable small world (NSW) is a special type of proximity graph that also includes long-range connections between nodes. These long-range connections support the \u201csmall world\u201d property of the graph, meaning almost every node can be reached from any other node within a few hops. Without these additional long-range connections, many hops would be required to reach a far-away node.\n\nThe \u201cnavigable\u201d part of NSW specifically refers to the ability to logarithmically scale the greedy search algorithm on the graph, an algorithm that attempts to make only the locally optimal choice at each hop. Without this property, the graph may still be considered a small world with short paths between far-away nodes, but the greedy algorithm tends to miss them. Greedy search is ideal for NSW because it is quick to navigate and has low computational costs.\n",
      "overlap_text": {
        "previous_chunk_id": "07d93042-7b0a-4292-88ca-d35345704c14",
        "text": "Content of the previous chunk for context: h1: HNSW indexes h2: How does HNSW work? [\\#](\\#how-does-hnsw-work)\n\n to the next layer below. Since each layer below is less sparse than the layer above (with the bottom layer connecting all elements), the target will eventually be found. Skip lists offer O(log n) average complexity for both search and insertion/deletion.\n"
      }
    }
  },
  {
    "chunk_id": "d5207f81-af7e-4063-9999-321c5f6cdfc9",
    "metadata": {
      "token_count": 135,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes",
      "page_title": "HNSW indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "HNSW indexes",
        "h2": "How does HNSW work? [\\#](\\#how-does-hnsw-work)"
      },
      "text": "\n### **Hierarchical +** Navigable Small World [\\#](\\#hierarchical--navigable-small-world)\n\nHNSW combines these two concepts. From the hierarchical perspective, the bottom layer consists of a NSW made up of short links between nodes. Each layer above \u201cskips\u201d elements and creates longer links between nodes further away from each other.\n\nJust like skip lists, search starts at the top layer and works its way down until it finds the target element. However, instead of comparing a scalar value at each layer to determine whether or not to descend to the layer below, a multi-dimensional distance measure (such as Euclidean distance) is used.\n",
      "overlap_text": {
        "previous_chunk_id": "82475636-6a62-461f-b7e0-1621c0144ac0",
        "text": "Content of the previous chunk for context: h1: HNSW indexes h2: How does HNSW work? [\\#](\\#how-does-hnsw-work)\n\n. Without this property, the graph may still be considered a small world with short paths between far-away nodes, but the greedy algorithm tends to miss them. Greedy search is ideal for NSW because it is quick to navigate and has low computational costs.\n"
      }
    }
  },
  {
    "chunk_id": "aeb10263-06b3-4cef-a674-43f154a20785",
    "metadata": {
      "token_count": 110,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes",
      "page_title": "HNSW indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "HNSW indexes",
        "h2": "When should you create HNSW indexes? [\\#](\\#when-should-you-create-hnsw-indexes)"
      },
      "text": "HNSW should be your default choice when creating a vector index. Add the index when you don't need 100% accuracy and are willing to trade a small amount of accuracy for a lot of throughput.\n\nUnlike IVFFlat indexes, you are safe to build an HNSW index immediately after the table is created. HNSW indexes are based on graphs which inherently are not affected by the same limitations as IVFFlat. As new data is added to the table, the index will be filled automatically and the index structure will remain optimal.\n",
      "overlap_text": {
        "previous_chunk_id": "d5207f81-af7e-4063-9999-321c5f6cdfc9",
        "text": "Content of the previous chunk for context: h1: HNSW indexes h2: How does HNSW work? [\\#](\\#how-does-hnsw-work)\n\n and works its way down until it finds the target element. However, instead of comparing a scalar value at each layer to determine whether or not to descend to the layer below, a multi-dimensional distance measure (such as Euclidean distance) is used.\n"
      }
    }
  },
  {
    "chunk_id": "b8d815cf-a4a8-4db4-971b-b2c19d11489c",
    "metadata": {
      "token_count": 26,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes",
      "page_title": "HNSW indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "HNSW indexes",
        "h2": "Resources [\\#](\\#resources)"
      },
      "text": "Read more about indexing on `pgvector`'s [GitHub page](https://github.com/pgvector/pgvector#indexing).\n",
      "overlap_text": {
        "previous_chunk_id": "aeb10263-06b3-4cef-a674-43f154a20785",
        "text": "Content of the previous chunk for context: h1: HNSW indexes h2: When should you create HNSW indexes? [\\#](\\#when-should-you-create-hnsw-indexes)\n\n the table is created. HNSW indexes are based on graphs which inherently are not affected by the same limitations as IVFFlat. As new data is added to the table, the index will be filled automatically and the index structure will remain optimal.\n"
      }
    }
  },
  {
    "chunk_id": "32357012-beb1-4588-98ee-547b0737766a",
    "metadata": {
      "token_count": 146,
      "source_url": "https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan",
      "page_title": "Semantic Image Search with Amazon Titan | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Image Search with Amazon Titan",
        "h2": "Implement semantic image search with Amazon Titan and Supabase Vector in Python."
      },
      "text": "* * *\n\n[Amazon Bedrock](https://aws.amazon.com/bedrock) is a fully managed service that offers a choice of high-performing foundation models (FMs) from leading AI companies like AI21 Labs, Anthropic, Cohere, Meta, Mistral AI, Stability AI, and Amazon. Each model is accessible through a common API which implements a broad set of features to help build generative AI applications with security, privacy, and responsible AI in mind.\n\n[Amazon Titan](https://aws.amazon.com/bedrock/titan/) is a family of foundation models (FMs) for text and image generation, summarization, classification, open-ended Q&A, information extraction, and text or image search.\n"
    }
  },
  {
    "chunk_id": "8c46bf7a-195f-4e29-a1f7-61a5e0a62c88",
    "metadata": {
      "token_count": 88,
      "source_url": "https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan",
      "page_title": "Semantic Image Search with Amazon Titan | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Image Search with Amazon Titan",
        "h2": "Implement semantic image search with Amazon Titan and Supabase Vector in Python."
      },
      "text": "\nIn this guide we'll look at how we can get started with Amazon Bedrock and Supabase Vector in Python using the Amazon Titan multimodal model and the [vecs client](/docs/guides/ai/vecs-python-client).\n\nYou can find the full application code as a Python Poetry project on [GitHub](https://github.com/supabase/supabase/tree/master/examples/ai/aws_bedrock_image_search).\n",
      "overlap_text": {
        "previous_chunk_id": "32357012-beb1-4588-98ee-547b0737766a",
        "text": "Content of the previous chunk for context: h1: Semantic Image Search with Amazon Titan h2: Implement semantic image search with Amazon Titan and Supabase Vector in Python.\n\n[Amazon Titan](https://aws.amazon.com/bedrock/titan/) is a family of foundation models (FMs) for text and image generation, summarization, classification, open-ended Q&A, information extraction, and text or image search.\n"
      }
    }
  },
  {
    "chunk_id": "bfec3378-6ed2-45e7-b36e-a7c004c08ddb",
    "metadata": {
      "token_count": 59,
      "source_url": "https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan",
      "page_title": "Semantic Image Search with Amazon Titan | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Image Search with Amazon Titan",
        "h2": "Create a new Python project with Poetry [\\#](\\#create-a-new-python-project-with-poetry)"
      },
      "text": "[Poetry](https://python-poetry.org/) provides packaging and dependency management for Python. If you haven't already, install poetry via pip:\n\n`\n_10\npip install poetry\n`\n\nThen initialize a new project:\n\n`\n_10\npoetry new aws_bedrock_image_search\n`\n",
      "overlap_text": {
        "previous_chunk_id": "8c46bf7a-195f-4e29-a1f7-61a5e0a62c88",
        "text": "Content of the previous chunk for context: h1: Semantic Image Search with Amazon Titan h2: Implement semantic image search with Amazon Titan and Supabase Vector in Python.\n\ndocs/guides/ai/vecs-python-client).\n\nYou can find the full application code as a Python Poetry project on [GitHub](https://github.com/supabase/supabase/tree/master/examples/ai/aws_bedrock_image_search).\n"
      }
    }
  },
  {
    "chunk_id": "f249f2fa-1671-43ce-91d1-7ae255793188",
    "metadata": {
      "token_count": 145,
      "source_url": "https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan",
      "page_title": "Semantic Image Search with Amazon Titan | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Image Search with Amazon Titan",
        "h2": "Spin up a Postgres Database with pgvector [\\#](\\#spin-up-a-postgres-database-with-pgvector)"
      },
      "text": "If you haven't already, head over to [database.new](https://database.new) and create a new project. Every Supabase project comes with a full Postgres database and the [pgvector extension](/docs/guides/database/extensions/pgvector) preconfigured.\n\nWhen creating your project, make sure to note down your database password as you will need it to construct the `DB_URL` in the next step.\n\nYou can find the database connection string in your Supabase Dashboard [database settings](https://supabase.com/dashboard/project/_/settings/database). Select \"Use connection pooling\" with `Mode: Session` for a direct connection to your Postgres database. It will look something like this:\n",
      "overlap_text": {
        "previous_chunk_id": "bfec3378-6ed2-45e7-b36e-a7c004c08ddb",
        "text": "Content of the previous chunk for context: h1: Semantic Image Search with Amazon Titan h2: Create a new Python project with Poetry [\\#](\\#create-a-new-python-project-with-poetry)\n\n.org/) provides packaging and dependency management for Python. If you haven't already, install poetry via pip:\n\n`\n_10\npip install poetry\n`\n\nThen initialize a new project:\n\n`\n_10\npoetry new aws_bedrock_image_search\n`\n"
      }
    }
  },
  {
    "chunk_id": "c28017dc-302b-4085-9346-b7c7d2bef0ec",
    "metadata": {
      "token_count": 38,
      "source_url": "https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan",
      "page_title": "Semantic Image Search with Amazon Titan | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Image Search with Amazon Titan",
        "h2": "Spin up a Postgres Database with pgvector [\\#](\\#spin-up-a-postgres-database-with-pgvector)"
      },
      "text": "\n`\n_10\npostgresql://postgres.[PROJECT-REF]:[YOUR-PASSWORD]@aws-0-[REGION].pooler.supabase.com:5432/postgres\n`\n",
      "overlap_text": {
        "previous_chunk_id": "f249f2fa-1671-43ce-91d1-7ae255793188",
        "text": "Content of the previous chunk for context: h1: Semantic Image Search with Amazon Titan h2: Spin up a Postgres Database with pgvector [\\#](\\#spin-up-a-postgres-database-with-pgvector)\n\n Supabase Dashboard [database settings](https://supabase.com/dashboard/project/_/settings/database). Select \"Use connection pooling\" with `Mode: Session` for a direct connection to your Postgres database. It will look something like this:\n"
      }
    }
  },
  {
    "chunk_id": "684eb8ec-3d04-49af-a3d0-5d7877a9cff0",
    "metadata": {
      "token_count": 92,
      "source_url": "https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan",
      "page_title": "Semantic Image Search with Amazon Titan | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Image Search with Amazon Titan",
        "h2": "Install the dependencies [\\#](\\#install-the-dependencies)"
      },
      "text": "We will need to add the following dependencies to our project:\n\n- [`vecs`](https://github.com/supabase/vecs#vecs): Supabase Vector Python Client.\n- [`boto3`](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html): AWS SDK for Python.\n- [`matplotlib`](https://matplotlib.org/): for displaying our image result.\n\n`\n_10\npoetry add vecs boto3 matplotlib\n`\n",
      "overlap_text": {
        "previous_chunk_id": "c28017dc-302b-4085-9346-b7c7d2bef0ec",
        "text": "Content of the previous chunk for context: h1: Semantic Image Search with Amazon Titan h2: Spin up a Postgres Database with pgvector [\\#](\\#spin-up-a-postgres-database-with-pgvector)\n\n\n`\n_10\npostgresql://postgres.[PROJECT-REF]:[YOUR-PASSWORD]@aws-0-[REGION].pooler.supabase.com:5432/postgres\n`\n"
      }
    }
  },
  {
    "chunk_id": "245a912a-7f25-4867-a5a8-b9abe9d1f419",
    "metadata": {
      "token_count": 131,
      "source_url": "https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan",
      "page_title": "Semantic Image Search with Amazon Titan | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Image Search with Amazon Titan",
        "h2": "Import the necessary dependencies [\\#](\\#import-the-necessary-dependencies)"
      },
      "text": "At the top of your main python script, import the dependencies and store your `DB URL` from above in a variable:\n\n`\n_10\nimport sys\n_10\nimport boto3\n_10\nimport vecs\n_10\nimport json\n_10\nimport base64\n_10\nfrom matplotlib import pyplot as plt\n_10\nfrom matplotlib import image as mpimg\n_10\nfrom typing import Optional\n_10\n_10\nDB_CONNECTION = \"postgresql://postgres.[PROJECT-REF]:[YOUR-PASSWORD]@aws-0-[REGION].pooler.supabase.com:5432/postgres\"\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "684eb8ec-3d04-49af-a3d0-5d7877a9cff0",
        "text": "Content of the previous chunk for context: h1: Semantic Image Search with Amazon Titan h2: Install the dependencies [\\#](\\#install-the-dependencies)\n\nhttps://boto3.amazonaws.com/v1/documentation/api/latest/index.html): AWS SDK for Python.\n- [`matplotlib`](https://matplotlib.org/): for displaying our image result.\n\n`\n_10\npoetry add vecs boto3 matplotlib\n`\n"
      }
    }
  },
  {
    "chunk_id": "1fd34673-2c25-415a-a707-5e401a562d87",
    "metadata": {
      "token_count": 132,
      "source_url": "https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan",
      "page_title": "Semantic Image Search with Amazon Titan | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Image Search with Amazon Titan",
        "h2": "Import the necessary dependencies [\\#](\\#import-the-necessary-dependencies)"
      },
      "text": "Next, get the [credentials to your AWS account](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html) and instantiate the `boto3` client:\n\n`\n_10\nbedrock_client = boto3.client(\n_10\n    'bedrock-runtime',\n_10\n    region_name='us-west-2',\n_10\n    # Credentials from your AWS account\n_10\n    aws_access_key_id='<replace_your_own_credentials>',\n_10\n    aws_secret_access_key='<replace_your_own_credentials>',\n_10\n    aws_session_token='<replace_your_own_credentials>',\n_10\n)\n`\n",
      "overlap_text": {
        "previous_chunk_id": "245a912a-7f25-4867-a5a8-b9abe9d1f419",
        "text": "Content of the previous chunk for context: h1: Semantic Image Search with Amazon Titan h2: Import the necessary dependencies [\\#](\\#import-the-necessary-dependencies)\n\n10\nfrom typing import Optional\n_10\n_10\nDB_CONNECTION = \"postgresql://postgres.[PROJECT-REF]:[YOUR-PASSWORD]@aws-0-[REGION].pooler.supabase.com:5432/postgres\"\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "09fba3be-6aa8-42f5-881f-a22dbdf7350a",
    "metadata": {
      "token_count": 104,
      "source_url": "https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan",
      "page_title": "Semantic Image Search with Amazon Titan | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Image Search with Amazon Titan",
        "h2": "Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)"
      },
      "text": "In the root of your project, create a new folder called `images` and add some images. You can use the images from the example project on [GitHub](https://github.com/supabase/supabase/tree/master/examples/ai/aws_bedrock_image_search/images) or you can find license free images on [unsplash](https://unsplash.com).\n\nTo send images to the Amazon Bedrock API we need to need to encode them as `base64` strings. Create the following helper methods:\n",
      "overlap_text": {
        "previous_chunk_id": "1fd34673-2c25-415a-a707-5e401a562d87",
        "text": "Content of the previous chunk for context: h1: Semantic Image Search with Amazon Titan h2: Import the necessary dependencies [\\#](\\#import-the-necessary-dependencies)\n\n\n_10\n    aws_access_key_id='<replace_your_own_credentials>',\n_10\n    aws_secret_access_key='<replace_your_own_credentials>',\n_10\n    aws_session_token='<replace_your_own_credentials>',\n_10\n)\n`\n"
      }
    }
  },
  {
    "chunk_id": "3eed3f3f-71bb-4b12-a234-9160898ce571",
    "metadata": {
      "token_count": 120,
      "source_url": "https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan",
      "page_title": "Semantic Image Search with Amazon Titan | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Image Search with Amazon Titan",
        "h2": "Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)"
      },
      "text": "\n`\n_44\ndef readFileAsBase64(file_path):\n_44\n    \"\"\"Encode image as base64 string.\"\"\"\n_44\n    try:\n_44\n        with open(file_path, \"rb\") as image_file:\n_44\n            input_image = base64.b64encode(image_file.read()).decode(\"utf8\")\n_44\n        return input_image\n_44\n    except:\n_44\n        print(\"bad file name\")\n_44\n        sys.exit(0)\n_44\n_44\n_44\ndef construct_bedrock_image_body(base64_string):\n",
      "overlap_text": {
        "previous_chunk_id": "09fba3be-6aa8-42f5-881f-a22dbdf7350a",
        "text": "Content of the previous chunk for context: h1: Semantic Image Search with Amazon Titan h2: Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)\n\n_search/images) or you can find license free images on [unsplash](https://unsplash.com).\n\nTo send images to the Amazon Bedrock API we need to need to encode them as `base64` strings. Create the following helper methods:\n"
      }
    }
  },
  {
    "chunk_id": "d47f536a-a776-4e33-ae72-7120ef25545f",
    "metadata": {
      "token_count": 117,
      "source_url": "https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan",
      "page_title": "Semantic Image Search with Amazon Titan | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Image Search with Amazon Titan",
        "h2": "Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)"
      },
      "text": "_44\n    \"\"\"Construct the request body.\n_44\n_44\n    https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-embed-mm.html\n_44\n    \"\"\"\n_44\n    return json.dumps(\n_44\n        {\n_44\n            \"inputImage\": base64_string,\n_44\n            \"embeddingConfig\": {\"outputEmbeddingLength\": 1024},\n_44\n        }\n_44\n    )\n_44\n_44\n_44\ndef get_embedding_from_titan_multimodal(body):\n",
      "overlap_text": {
        "previous_chunk_id": "3eed3f3f-71bb-4b12-a234-9160898ce571",
        "text": "Content of the previous chunk for context: h1: Semantic Image Search with Amazon Titan h2: Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)\n\n\n        return input_image\n_44\n    except:\n_44\n        print(\"bad file name\")\n_44\n        sys.exit(0)\n_44\n_44\n_44\ndef construct_bedrock_image_body(base64_string):\n"
      }
    }
  },
  {
    "chunk_id": "b871cdcb-8da6-4036-a0f9-393b73cef813",
    "metadata": {
      "token_count": 125,
      "source_url": "https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan",
      "page_title": "Semantic Image Search with Amazon Titan | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Image Search with Amazon Titan",
        "h2": "Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)"
      },
      "text": "_44\n    \"\"\"Invoke the Amazon Titan Model via API request.\"\"\"\n_44\n    response = bedrock_client.invoke_model(\n_44\n        body=body,\n_44\n        modelId=\"amazon.titan-embed-image-v1\",\n_44\n        accept=\"application/json\",\n_44\n        contentType=\"application/json\",\n_44\n    )\n_44\n_44\n    response_body = json.loads(response.get(\"body\").read())\n_44\n    print(response_body)\n_44\n    return response_body[\"embedding\"]\n_44\n_44\n_44\ndef encode_image(file_path):\n",
      "overlap_text": {
        "previous_chunk_id": "d47f536a-a776-4e33-ae72-7120ef25545f",
        "text": "Content of the previous chunk for context: h1: Semantic Image Search with Amazon Titan h2: Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)\n\n_string,\n_44\n            \"embeddingConfig\": {\"outputEmbeddingLength\": 1024},\n_44\n        }\n_44\n    )\n_44\n_44\n_44\ndef get_embedding_from_titan_multimodal(body):\n"
      }
    }
  },
  {
    "chunk_id": "6d37ef6f-e661-43b1-886e-75b80c4f8242",
    "metadata": {
      "token_count": 103,
      "source_url": "https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan",
      "page_title": "Semantic Image Search with Amazon Titan | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Image Search with Amazon Titan",
        "h2": "Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)"
      },
      "text": "_44\n    \"\"\"Generate embedding for the image at file_path.\"\"\"\n_44\n    base64_string = readFileAsBase64(file_path)\n_44\n    body = construct_bedrock_image_body(base64_string)\n_44\n    emb = get_embedding_from_titan_multimodal(body)\n_44\n    return emb\n`\n\nNext, create a `seed` method, which will create a new Supabase Vector Collection, generate embeddings for your images, and upsert the embeddings into your database:\n",
      "overlap_text": {
        "previous_chunk_id": "b871cdcb-8da6-4036-a0f9-393b73cef813",
        "text": "Content of the previous chunk for context: h1: Semantic Image Search with Amazon Titan h2: Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)\n\n\n_44\n    response_body = json.loads(response.get(\"body\").read())\n_44\n    print(response_body)\n_44\n    return response_body[\"embedding\"]\n_44\n_44\n_44\ndef encode_image(file_path):\n"
      }
    }
  },
  {
    "chunk_id": "eb994cd1-7c4f-4302-97bc-d89ad8fd71f3",
    "metadata": {
      "token_count": 404,
      "source_url": "https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan",
      "page_title": "Semantic Image Search with Amazon Titan | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Image Search with Amazon Titan",
        "h2": "Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)"
      },
      "text": "\n`\n_40\ndef seed():\n_40\n    # create vector store client\n_40\n    vx = vecs.create_client(DB_CONNECTION)\n_40\n_40\n    # get or create a collection of vectors with 1024 dimensions\n_40\n    images = vx.get_or_create_collection(name=\"image_vectors\", dimension=1024)\n_40\n_40\n    # Generate image embeddings with Amazon Titan Model\n_40\n    img_emb1 = encode_image('./images/one.jpg')\n_40\n    img_emb2 = encode_image('./images/two.jpg')\n_40\n    img_emb3 = encode_image('./images/three.jpg')\n_40\n    img_emb4 = encode_image('./images/four.jpg')\n_40\n_40\n    # add records to the *images* collection\n_40\n    images.upsert(\n_40\n        records=[\\\n_40\\\n            (\\\n_40\\\n                \"one.jpg\",       # the vector's identifier\\\n_40\\\n                img_emb1,        # the vector. list or np.array\\\n_40\\\n                {\"type\": \"jpg\"}  # associated  metadata\\\n_40\\\n            ), (\\\n_40\\\n                \"two.jpg\",\\\n_40\\\n                img_emb2,\\\n_40\\\n                {\"type\": \"jpg\"}\\\n_40\\\n            ), (\\\n_40\\\n                \"three.jpg\",\\\n_40\\\n                img_emb3,\\\n_40\\\n                {\"type\": \"jpg\"}\\\n_40\\\n            ), (\\\n_40\\\n                \"four.jpg\",\\\n_40\\\n                img_emb4,\\\n_40\\\n                {\"type\": \"jpg\"}\\\n_40\\\n            )\\\n_40\\\n        ]\n_40\n    )\n_40\n    print(\"Inserted images\")\n_40\n_40\n    # index the collection for fast search performance\n_40\n    images.create_index()\n_40\n    print(\"Created index\")\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "6d37ef6f-e661-43b1-886e-75b80c4f8242",
        "text": "Content of the previous chunk for context: h1: Semantic Image Search with Amazon Titan h2: Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)\n\n_titan_multimodal(body)\n_44\n    return emb\n`\n\nNext, create a `seed` method, which will create a new Supabase Vector Collection, generate embeddings for your images, and upsert the embeddings into your database:\n"
      }
    }
  },
  {
    "chunk_id": "163cc2b0-f080-4995-be6b-96ad4f19d1e0",
    "metadata": {
      "token_count": 126,
      "source_url": "https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan",
      "page_title": "Semantic Image Search with Amazon Titan | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Image Search with Amazon Titan",
        "h2": "Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)"
      },
      "text": "Add this method as a script in your `pyproject.toml` file:\n\n`\n_10\n[tool.poetry.scripts]\n_10\nseed = \"image_search.main:seed\"\n_10\nsearch = \"image_search.main:search\"\n`\n\nAfter activating the virtual environtment with `poetry shell` you can now run your seed script via `poetry run seed`. You can inspect the generated embeddings in your Supabase Dashboard by visiting the [Table Editor](https://supabase.com/dashboard/project/_/editor), selecting the `vecs` schema, and the `image_vectors` table.\n",
      "overlap_text": {
        "previous_chunk_id": "eb994cd1-7c4f-4302-97bc-d89ad8fd71f3",
        "text": "Content of the previous chunk for context: h1: Semantic Image Search with Amazon Titan h2: Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)\n\n        ]\n_40\n    )\n_40\n    print(\"Inserted images\")\n_40\n_40\n    # index the collection for fast search performance\n_40\n    images.create_index()\n_40\n    print(\"Created index\")\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "046367b5-55c4-40a9-a840-79db8530aeb1",
    "metadata": {
      "token_count": 339,
      "source_url": "https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan",
      "page_title": "Semantic Image Search with Amazon Titan | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Image Search with Amazon Titan",
        "h2": "Perform an image search from a text query [\\#](\\#perform-an-image-search-from-a-text-query)"
      },
      "text": "With Supabase Vector we can easily query our embeddings. We can use either an image as the search input or alternatively we can generate an embedding from a string input and use that as the query input:\n\n`\n_28\ndef search(query_term: Optional[str] = None):\n_28\n    if query_term is None:\n_28\n        query_term = sys.argv[1]\n_28\n_28\n    # create vector store client\n_28\n    vx = vecs.create_client(DB_CONNECTION)\n_28\n    images = vx.get_or_create_collection(name=\"image_vectors\", dimension=1024)\n_28\n_28\n    # Encode text query\n_28\n    text_emb = get_embedding_from_titan_multimodal(json.dumps(\n_28\n        {\n_28\n            \"inputText\": query_term,\n_28\n            \"embeddingConfig\": {\"outputEmbeddingLength\": 1024},\n_28\n        }\n_28\n    ))\n_28\n_28\n    # query the collection filtering metadata for \"type\" = \"jpg\"\n_28\n    results = images.query(\n_28\n        data=text_emb,                      # required\n_28\n        limit=1,                            # number of records to return\n_28\n        filters={\"type\": {\"$eq\": \"jpg\"}},   # metadata filters\n_28\n    )\n_28\n    result = results[0]\n_28\n    print(result)\n_28\n    plt.title(result)\n_28\n    image = mpimg.imread('./images/' + result)\n_28\n    plt.imshow(image)\n_28\n    plt.show()\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "163cc2b0-f080-4995-be6b-96ad4f19d1e0",
        "text": "Content of the previous chunk for context: h1: Semantic Image Search with Amazon Titan h2: Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)\n\netry run seed`. You can inspect the generated embeddings in your Supabase Dashboard by visiting the [Table Editor](https://supabase.com/dashboard/project/_/editor), selecting the `vecs` schema, and the `image_vectors` table.\n"
      }
    }
  },
  {
    "chunk_id": "8896a550-1cd6-4810-a69b-cfc9b294afcf",
    "metadata": {
      "token_count": 72,
      "source_url": "https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan",
      "page_title": "Semantic Image Search with Amazon Titan | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Image Search with Amazon Titan",
        "h2": "Perform an image search from a text query [\\#](\\#perform-an-image-search-from-a-text-query)"
      },
      "text": "By limiting the query to one result, we can show the most relevant image to the user. Finally we use `matplotlib` to show the image result to the user.\n\nThat's it, go ahead and test it out by running `poetry run search` and you will be presented with an image of a \"bike in front of a red brick wall\".\n",
      "overlap_text": {
        "previous_chunk_id": "046367b5-55c4-40a9-a840-79db8530aeb1",
        "text": "Content of the previous chunk for context: h1: Semantic Image Search with Amazon Titan h2: Perform an image search from a text query [\\#](\\#perform-an-image-search-from-a-text-query)\n\n results[0]\n_28\n    print(result)\n_28\n    plt.title(result)\n_28\n    image = mpimg.imread('./images/' + result)\n_28\n    plt.imshow(image)\n_28\n    plt.show()\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "c2e226a0-85d7-46e8-9ced-ac1c3246e1f1",
    "metadata": {
      "token_count": 34,
      "source_url": "https://supabase.com/docs/guides/ai/examples/semantic-image-search-amazon-titan",
      "page_title": "Semantic Image Search with Amazon Titan | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Image Search with Amazon Titan",
        "h2": "Conclusion [\\#](\\#conclusion)"
      },
      "text": "With just a couple of lines of Python you are able to implement image search as well as reverse image search using the Amazon Titan multimodal model and Supabase Vector.\n",
      "overlap_text": {
        "previous_chunk_id": "8896a550-1cd6-4810-a69b-cfc9b294afcf",
        "text": "Content of the previous chunk for context: h1: Semantic Image Search with Amazon Titan h2: Perform an image search from a text query [\\#](\\#perform-an-image-search-from-a-text-query)\n\n `matplotlib` to show the image result to the user.\n\nThat's it, go ahead and test it out by running `poetry run search` and you will be presented with an image of a \"bike in front of a red brick wall\".\n"
      }
    }
  },
  {
    "chunk_id": "adf207a1-b693-4094-92b1-732af245fbc2",
    "metadata": {
      "token_count": 171,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/amazon-bedrock",
      "page_title": "Amazon Bedrock | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Amazon Bedrock"
      },
      "text": "* * *\n\n[Amazon Bedrock](https://aws.amazon.com/bedrock) is a fully managed service that offers a choice of high-performing foundation models (FMs) from leading AI companies like AI21 Labs, Anthropic, Cohere, Meta, Mistral AI, Stability AI, and Amazon. Each model is accessible through a common API which implements a broad set of features to help build generative AI applications with security, privacy, and responsible AI in mind.\n\nThis guide will walk you through an example using Amazon Bedrock SDK with `vecs`. We will create embeddings using the Amazon Titan Embeddings G1 \u2013 Text v1.2 (amazon.titan-embed-text-v1) model, insert these embeddings into a PostgreSQL database using vecs, and then query the collection to find the most similar sentences to a given query sentence.\n"
    }
  },
  {
    "chunk_id": "f795b6b1-5125-4d3a-a32d-827fd6431698",
    "metadata": {
      "token_count": 102,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/amazon-bedrock",
      "page_title": "Amazon Bedrock | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Amazon Bedrock",
        "h2": "Create an Environment [\\#](\\#create-an-environment)"
      },
      "text": "First, you need to set up your environment. You will need Python 3.7+ with the `vecs` and `boto3` libraries installed.\n\nYou can install the necessary Python libraries using pip:\n\n`\n_10\npip install vecs boto3\n`\n\nYou'll also need:\n\n- [Credentials to your AWS account](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html)\n- [A Postgres Database with the pgvector extension](hosting.md)\n",
      "overlap_text": {
        "previous_chunk_id": "adf207a1-b693-4094-92b1-732af245fbc2",
        "text": "Content of the previous chunk for context: h1: Amazon Bedrock\n\n Embeddings G1 \u2013 Text v1.2 (amazon.titan-embed-text-v1) model, insert these embeddings into a PostgreSQL database using vecs, and then query the collection to find the most similar sentences to a given query sentence.\n"
      }
    }
  },
  {
    "chunk_id": "e2220c91-c1b1-4c14-bdae-2c2ddb765ef3",
    "metadata": {
      "token_count": 241,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/amazon-bedrock",
      "page_title": "Amazon Bedrock | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Amazon Bedrock",
        "h2": "Create Embeddings [\\#](\\#create-embeddings)"
      },
      "text": "Next, we will use Amazon\u2019s Titan Embedding G1 - Text v1.2 model to create embeddings for a set of sentences.\n\n`\n_34\nimport boto3\n_34\nimport vecs\n_34\nimport json\n_34\n_34\nclient = boto3.client(\n_34\n    'bedrock-runtime',\n_34\n    region_name='us-east-1',\n_34\n\t# Credentials from your AWS account\n_34\n    aws_access_key_id='<replace_your_own_credentials>',\n_34\n    aws_secret_access_key='<replace_your_own_credentials>',\n_34\n    aws_session_token='<replace_your_own_credentials>',\n_34\n)\n_34\n_34\ndataset = [\\\n_34\\\n    \"The cat sat on the mat.\",\\\n_34\\\n    \"The quick brown fox jumps over the lazy dog.\",\\\n_34\\\n    \"Friends, Romans, countrymen, lend me your ears\",\\\n_34\\\n    \"To be or not to be, that is the question.\",\\\n_34\\\n]\n_34\n_34\nembeddings = []\n_34\n_34\nfor sentence in dataset:\n",
      "overlap_text": {
        "previous_chunk_id": "f795b6b1-5125-4d3a-a32d-827fd6431698",
        "text": "Content of the previous chunk for context: h1: Amazon Bedrock h2: Create an Environment [\\#](\\#create-an-environment)\n\n3\n`\n\nYou'll also need:\n\n- [Credentials to your AWS account](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html)\n- [A Postgres Database with the pgvector extension](hosting.md)\n"
      }
    }
  },
  {
    "chunk_id": "e8570489-ee01-4cb2-8212-7db3c1f1dafa",
    "metadata": {
      "token_count": 137,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/amazon-bedrock",
      "page_title": "Amazon Bedrock | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Amazon Bedrock",
        "h2": "Create Embeddings [\\#](\\#create-embeddings)"
      },
      "text": "_34\n    # invoke the embeddings model for each sentence\n_34\n    response = client.invoke_model(\n_34\n        body= json.dumps({\"inputText\": sentence}),\n_34\n        modelId= \"amazon.titan-embed-text-v1\",\n_34\n        accept = \"application/json\",\n_34\n        contentType = \"application/json\"\n_34\n    )\n_34\n    # collect the embedding from the response\n_34\n    response_body = json.loads(response[\"body\"].read())\n_34\n    # add the embedding to the embedding list\n_34\n    embeddings.append((sentence, response_body.get(\"embedding\"), {}))\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "e2220c91-c1b1-4c14-bdae-2c2ddb765ef3",
        "text": "Content of the previous chunk for context: h1: Amazon Bedrock h2: Create Embeddings [\\#](\\#create-embeddings)\n\n, lend me your ears\",\\\n_34\\\n    \"To be or not to be, that is the question.\",\\\n_34\\\n]\n_34\n_34\nembeddings = []\n_34\n_34\nfor sentence in dataset:\n"
      }
    }
  },
  {
    "chunk_id": "17e9b6bc-9bb1-4ace-a0f1-b3aa11f2517d",
    "metadata": {
      "token_count": 220,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/amazon-bedrock",
      "page_title": "Amazon Bedrock | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Amazon Bedrock",
        "h2": "Create Embeddings [\\#](\\#create-embeddings)"
      },
      "text": "### Store the Embeddings with vecs [\\#](\\#store-the-embeddings-with-vecs)\n\nNow that we have our embeddings, we can insert them into a PostgreSQL database using vecs.\n\n`\n_16\nimport vecs\n_16\n_16\nDB_CONNECTION = \"postgresql://<user>:<password>@<host>:<port>/<db_name>\"\n_16\n_16\n# create vector store client\n_16\nvx = vecs.Client(DB_CONNECTION)\n_16\n_16\n# create a collection named 'sentences' with 1536 dimensional vectors\n_16\n# to match the default dimension of the Titan Embeddings G1 - Text model\n_16\nsentences = vx.get_or_create_collection(name=\"sentences\", dimension=1536)\n_16\n_16\n# upsert the embeddings into the 'sentences' collection\n_16\nsentences.upsert(records=embeddings)\n_16\n_16\n# create an index for the 'sentences' collection\n_16\nsentences.create_index()\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "e8570489-ee01-4cb2-8212-7db3c1f1dafa",
        "text": "Content of the previous chunk for context: h1: Amazon Bedrock h2: Create Embeddings [\\#](\\#create-embeddings)\n\n from the response\n_34\n    response_body = json.loads(response[\"body\"].read())\n_34\n    # add the embedding to the embedding list\n_34\n    embeddings.append((sentence, response_body.get(\"embedding\"), {}))\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "6f5b7689-7b08-446e-9113-d166df3ea410",
    "metadata": {
      "token_count": 301,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/amazon-bedrock",
      "page_title": "Amazon Bedrock | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Amazon Bedrock",
        "h2": "Create Embeddings [\\#](\\#create-embeddings)"
      },
      "text": "### Querying for Most Similar Sentences [\\#](\\#querying-for-most-similar-sentences)\n\nNow, we query the `sentences` collection to find the most similar sentences to a sample query sentence. First need to create an embedding for the query sentence. Next, we query the collection we created earlier to find the most similar sentences.\n\n`\n_27\nquery_sentence = \"A quick animal jumps over a lazy one.\"\n_27\n_27\n# create vector store client\n_27\nvx = vecs.Client(DB_CONNECTION)\n_27\n_27\n# create an embedding for the query sentence\n_27\nresponse = client.invoke_model(\n_27\n        body= json.dumps({\"inputText\": query_sentence}),\n_27\n        modelId= \"amazon.titan-embed-text-v1\",\n_27\n        accept = \"application/json\",\n_27\n        contentType = \"application/json\"\n_27\n    )\n_27\n_27\nresponse_body = json.loads(response[\"body\"].read())\n_27\n_27\nquery_embedding = response_body.get(\"embedding\")\n_27\n_27\n# query the 'sentences' collection for the most similar sentences\n_27\nresults = sentences.query(\n_27\n    data=query_embedding,\n_27\n    limit=3,\n_27\n    include_value = True\n_27\n)\n_27\n_27\n# print the results\n_27\nfor result in results:\n",
      "overlap_text": {
        "previous_chunk_id": "17e9b6bc-9bb1-4ace-a0f1-b3aa11f2517d",
        "text": "Content of the previous chunk for context: h1: Amazon Bedrock h2: Create Embeddings [\\#](\\#create-embeddings)\n\nsert the embeddings into the 'sentences' collection\n_16\nsentences.upsert(records=embeddings)\n_16\n_16\n# create an index for the 'sentences' collection\n_16\nsentences.create_index()\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "55d577b2-e992-460d-8c42-669340e399a5",
    "metadata": {
      "token_count": 94,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/amazon-bedrock",
      "page_title": "Amazon Bedrock | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Amazon Bedrock",
        "h2": "Create Embeddings [\\#](\\#create-embeddings)"
      },
      "text": "_27\n    print(result)\n`\n\nThis returns the most similar 3 records and their distance to the query vector.\n\n`\n_10\n('The quick brown fox jumps over the lazy dog.', 0.27600620558852)\n_10\n('The cat sat on the mat.', 0.609986272479202)\n_10\n('To be or not to be, that is the question.', 0.744849503688346)\n`\n",
      "overlap_text": {
        "previous_chunk_id": "6f5b7689-7b08-446e-9113-d166df3ea410",
        "text": "Content of the previous chunk for context: h1: Amazon Bedrock h2: Create Embeddings [\\#](\\#create-embeddings)\n\n.query(\n_27\n    data=query_embedding,\n_27\n    limit=3,\n_27\n    include_value = True\n_27\n)\n_27\n_27\n# print the results\n_27\nfor result in results:\n"
      }
    }
  },
  {
    "chunk_id": "82109c05-8f56-4968-8f15-b56f06ce55a2",
    "metadata": {
      "token_count": 57,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/amazon-bedrock",
      "page_title": "Amazon Bedrock | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Amazon Bedrock",
        "h2": "Resources [\\#](\\#resources)"
      },
      "text": "- [Amazon Bedrock](https://aws.amazon.com/bedrock)\n- [Amazon Titan](https://aws.amazon.com/bedrock/titan)\n- [Semantic Image Search with Amazon Titan](/docs/guides/ai/examples/semantic-image-search-amazon-titan)\n",
      "overlap_text": {
        "previous_chunk_id": "55d577b2-e992-460d-8c42-669340e399a5",
        "text": "Content of the previous chunk for context: h1: Amazon Bedrock h2: Create Embeddings [\\#](\\#create-embeddings)\n\n20558852)\n_10\n('The cat sat on the mat.', 0.609986272479202)\n_10\n('To be or not to be, that is the question.', 0.744849503688346)\n`\n"
      }
    }
  },
  {
    "chunk_id": "c91666e7-bcc9-488d-b96e-fc40556ec59e",
    "metadata": {
      "token_count": 120,
      "source_url": "https://supabase.com/docs/guides/ai/google-colab",
      "page_title": "Google Colab | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Google Colab",
        "h2": "Use Google Colab to manage your Supabase Vector store."
      },
      "text": "* * *\n\n[![](https://supabase.com/docs/img/ai/colab-badge.svg)](https://colab.research.google.com/github/supabase/supabase/blob/master/examples/ai/vector_hello_world.ipynb)\n\nGoogle Colab is a hosted Jupyter Notebook service. It provides free access to computing resources, including GPUs and TPUs, and is well-suited to machine learning, data science, and education. We can use Colab to manage collections using [Supabase Vecs](/docs/guides/ai/vecs-python-client).\n"
    }
  },
  {
    "chunk_id": "ff4e752f-6983-409f-854e-7a11287fe80e",
    "metadata": {
      "token_count": 52,
      "source_url": "https://supabase.com/docs/guides/ai/google-colab",
      "page_title": "Google Colab | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Google Colab",
        "h2": "Use Google Colab to manage your Supabase Vector store."
      },
      "text": "\nIn this tutorial we'll connect to a database running on the Supabase [platform](https://supabase.com/dashboard/). If you don't already have a database, you can create one here: [database.new](https://database.new).\n",
      "overlap_text": {
        "previous_chunk_id": "c91666e7-bcc9-488d-b96e-fc40556ec59e",
        "text": "Content of the previous chunk for context: h1: Google Colab h2: Use Google Colab to manage your Supabase Vector store.\n\n, including GPUs and TPUs, and is well-suited to machine learning, data science, and education. We can use Colab to manage collections using [Supabase Vecs](/docs/guides/ai/vecs-python-client).\n"
      }
    }
  },
  {
    "chunk_id": "22922959-f0e7-477e-8ed4-212337387e60",
    "metadata": {
      "token_count": 55,
      "source_url": "https://supabase.com/docs/guides/ai/google-colab",
      "page_title": "Google Colab | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Google Colab",
        "h2": "Create a new notebook [\\#](\\#create-a-new-notebook)"
      },
      "text": "Start by visiting [colab.research.google.com](https://colab.research.google.com/). There you can create a new notebook.\n\n![Google Colab new notebook](https://supabase.com/docs/img/ai/google-colab/colab-new.png)\n",
      "overlap_text": {
        "previous_chunk_id": "ff4e752f-6983-409f-854e-7a11287fe80e",
        "text": "Content of the previous chunk for context: h1: Google Colab h2: Use Google Colab to manage your Supabase Vector store.\n\n this tutorial we'll connect to a database running on the Supabase [platform](https://supabase.com/dashboard/). If you don't already have a database, you can create one here: [database.new](https://database.new).\n"
      }
    }
  },
  {
    "chunk_id": "fec775d2-c12c-4501-83d0-71b8809e380a",
    "metadata": {
      "token_count": 91,
      "source_url": "https://supabase.com/docs/guides/ai/google-colab",
      "page_title": "Google Colab | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Google Colab",
        "h2": "Install Vecs [\\#](\\#install-vecs)"
      },
      "text": "We'll use the Supabase Vector client, [Vecs](/docs/guides/ai/vecs-python-client), to manage our collections.\n\nAt the top of the notebook add the notebook paste the following code and hit the \"execute\" button ( `ctrl+enter`):\n\n`\n_10\npip install vecs\n`\n\n![Install vecs](https://supabase.com/docs/img/ai/google-colab/install-vecs.png)\n",
      "overlap_text": {
        "previous_chunk_id": "22922959-f0e7-477e-8ed4-212337387e60",
        "text": "Content of the previous chunk for context: h1: Google Colab h2: Create a new notebook [\\#](\\#create-a-new-notebook)\n\nab.research.google.com](https://colab.research.google.com/). There you can create a new notebook.\n\n![Google Colab new notebook](https://supabase.com/docs/img/ai/google-colab/colab-new.png)\n"
      }
    }
  },
  {
    "chunk_id": "65cb0c4f-bf44-4a09-9c35-880f3c1596ea",
    "metadata": {
      "token_count": 100,
      "source_url": "https://supabase.com/docs/guides/ai/google-colab",
      "page_title": "Google Colab | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Google Colab",
        "h2": "Connect to your database [\\#](\\#connect-to-your-database)"
      },
      "text": "Find the Postgres pooler connection string for your Supabase project in the [database settings](https://supabase.com/dashboard/project/_/settings/database) of the dashboard. Copy the \"URI\" format, which should look something like `postgres://postgres.xxxx:password@xxxx.pooler.supabase.com:6543/postgres`\n\nCreate a new code block below the install block ( `ctrl+m b`) and add the following code using the Postgres URI you copied above:\n",
      "overlap_text": {
        "previous_chunk_id": "fec775d2-c12c-4501-83d0-71b8809e380a",
        "text": "Content of the previous chunk for context: h1: Google Colab h2: Install Vecs [\\#](\\#install-vecs)\n\n the following code and hit the \"execute\" button ( `ctrl+enter`):\n\n`\n_10\npip install vecs\n`\n\n![Install vecs](https://supabase.com/docs/img/ai/google-colab/install-vecs.png)\n"
      }
    }
  },
  {
    "chunk_id": "f7659411-10e4-4e08-b9c6-aa5ad18c172b",
    "metadata": {
      "token_count": 86,
      "source_url": "https://supabase.com/docs/guides/ai/google-colab",
      "page_title": "Google Colab | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Google Colab",
        "h2": "Connect to your database [\\#](\\#connect-to-your-database)"
      },
      "text": "\n`\n_10\nimport vecs\n_10\n_10\nDB_CONNECTION = \"postgres://postgres.xxxx:password@xxxx.pooler.supabase.com:6543/postgres\"\n_10\n_10\n# create vector store client\n_10\nvx = vecs.create_client(DB_CONNECTION)\n`\n\nExecute the code block ( `ctrl+enter`). If no errors were returned then your connection was successful.\n",
      "overlap_text": {
        "previous_chunk_id": "65cb0c4f-bf44-4a09-9c35-880f3c1596ea",
        "text": "Content of the previous chunk for context: h1: Google Colab h2: Connect to your database [\\#](\\#connect-to-your-database)\n\npostgres://postgres.xxxx:password@xxxx.pooler.supabase.com:6543/postgres`\n\nCreate a new code block below the install block ( `ctrl+m b`) and add the following code using the Postgres URI you copied above:\n"
      }
    }
  },
  {
    "chunk_id": "d141ef7f-87d9-4a3a-b22e-63595284754e",
    "metadata": {
      "token_count": 221,
      "source_url": "https://supabase.com/docs/guides/ai/google-colab",
      "page_title": "Google Colab | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Google Colab",
        "h2": "Create a collection [\\#](\\#create-a-collection)"
      },
      "text": "Now we're going to create a new collection and insert some documents.\n\nCreate a new code block below the install block ( `ctrl+m b`). Add the following code to the code block and execute it ( `ctrl+enter`):\n\n`\n_16\ncollection = vx.get_or_create_collection(name=\"colab_collection\", dimension=3)\n_16\n_16\ncollection.upsert(\n_16\n    vectors=[\\\n_16\\\n        (\\\n_16\\\n         \"vec0\",           # the vector's identifier\\\n_16\\\n         [0.1, 0.2, 0.3],  # the vector. list or np.array\\\n_16\\\n         {\"year\": 1973}    # associated  metadata\\\n_16\\\n        ),\\\n_16\\\n        (\\\n_16\\\n         \"vec1\",\\\n_16\\\n         [0.7, 0.8, 0.9],\\\n_16\\\n         {\"year\": 2012}\\\n_16\\\n        )\\\n_16\\\n    ]\n_16\n)\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "f7659411-10e4-4e08-b9c6-aa5ad18c172b",
        "text": "Content of the previous chunk for context: h1: Google Colab h2: Connect to your database [\\#](\\#connect-to-your-database)\n\n3/postgres\"\n_10\n_10\n# create vector store client\n_10\nvx = vecs.create_client(DB_CONNECTION)\n`\n\nExecute the code block ( `ctrl+enter`). If no errors were returned then your connection was successful.\n"
      }
    }
  },
  {
    "chunk_id": "59e1ceb4-2f77-4849-b40d-515d435ada0f",
    "metadata": {
      "token_count": 83,
      "source_url": "https://supabase.com/docs/guides/ai/google-colab",
      "page_title": "Google Colab | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Google Colab",
        "h2": "Create a collection [\\#](\\#create-a-collection)"
      },
      "text": "This will create a table inside your database within the `vecs` schema, called `colab_collection`. You can view the inserted items in the [Table Editor](https://supabase.com/dashboard/project/_/editor/), by selecting the `vecs` schema from the schema dropdown.\n\n![Colab documents](https://supabase.com/docs/img/ai/google-colab/colab-documents.png)\n",
      "overlap_text": {
        "previous_chunk_id": "d141ef7f-87d9-4a3a-b22e-63595284754e",
        "text": "Content of the previous chunk for context: h1: Google Colab h2: Create a collection [\\#](\\#create-a-collection)\n\n\",\\\n_16\\\n         [0.7, 0.8, 0.9],\\\n_16\\\n         {\"year\": 2012}\\\n_16\\\n        )\\\n_16\\\n    ]\n_16\n)\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "ea48fcd7-6eb9-41e1-a42f-895a765b384c",
    "metadata": {
      "token_count": 134,
      "source_url": "https://supabase.com/docs/guides/ai/google-colab",
      "page_title": "Google Colab | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Google Colab",
        "h2": "Query your documents [\\#](\\#query-your-documents)"
      },
      "text": "Now we can search for documents based on their similarity. Create a new code block and execute the following code:\n\n`\n_10\ncollection.query(\n_10\n    query_vector=[0.4,0.5,0.6],  # required\n_10\n    limit=5,                     # number of records to return\n_10\n    filters={},                  # metadata filters\n_10\n    measure=\"cosine_distance\",   # distance measure to use\n_10\n    include_value=False,         # should distance measure values be returned?\n_10\n    include_metadata=False,      # should record metadata be returned?\n_10\n)\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "59e1ceb4-2f77-4849-b40d-515d435ada0f",
        "text": "Content of the previous chunk for context: h1: Google Colab h2: Create a collection [\\#](\\#create-a-collection)\n\nhttps://supabase.com/dashboard/project/_/editor/), by selecting the `vecs` schema from the schema dropdown.\n\n![Colab documents](https://supabase.com/docs/img/ai/google-colab/colab-documents.png)\n"
      }
    }
  },
  {
    "chunk_id": "61848fc9-c658-425b-b4a1-54ab6d81df07",
    "metadata": {
      "token_count": 97,
      "source_url": "https://supabase.com/docs/guides/ai/google-colab",
      "page_title": "Google Colab | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Google Colab",
        "h2": "Query your documents [\\#](\\#query-your-documents)"
      },
      "text": "You will see that this returns two documents in an array `['vec1', 'vec0']`:\n\n![Colab results](https://supabase.com/docs/img/ai/google-colab/colab-results.png)\n\nIt also returns a warning:\n\n`\n_10\nQuery does not have a covering index for cosine_distance.\n`\n\nYou can lean more about creating indexes in the [Vecs documentation](https://supabase.github.io/vecs/api/#create-an-index).\n",
      "overlap_text": {
        "previous_chunk_id": "ea48fcd7-6eb9-41e1-a42f-895a765b384c",
        "text": "Content of the previous chunk for context: h1: Google Colab h2: Query your documents [\\#](\\#query-your-documents)\n\n=\"cosine_distance\",   # distance measure to use\n_10\n    include_value=False,         # should distance measure values be returned?\n_10\n    include_metadata=False,      # should record metadata be returned?\n_10\n)\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "c3cd0adc-6c60-46e8-bfd2-2760e9540631",
    "metadata": {
      "token_count": 26,
      "source_url": "https://supabase.com/docs/guides/ai/google-colab",
      "page_title": "Google Colab | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Google Colab",
        "h2": "Resources [\\#](\\#resources)"
      },
      "text": "- Vecs API: [supabase.github.io/vecs/api](https://supabase.github.io/vecs/api)\n",
      "overlap_text": {
        "previous_chunk_id": "61848fc9-c658-425b-b4a1-54ab6d81df07",
        "text": "Content of the previous chunk for context: h1: Google Colab h2: Query your documents [\\#](\\#query-your-documents)\n\n also returns a warning:\n\n`\n_10\nQuery does not have a covering index for cosine_distance.\n`\n\nYou can lean more about creating indexes in the [Vecs documentation](https://supabase.github.io/vecs/api/#create-an-index).\n"
      }
    }
  },
  {
    "chunk_id": "a7fd6256-1acd-4ed9-9500-553c13d87f77",
    "metadata": {
      "token_count": 120,
      "source_url": "https://supabase.com/docs/guides/ai/examples/headless-vector-search",
      "page_title": "Adding generative Q&A for your documentation | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Adding generative Q&A for your documentation",
        "h2": "Learn how to build a ChatGPT-style doc search powered using our headless search toolkit."
      },
      "text": "* * *\n\nSupabase provides a [Headless Search Toolkit](https://github.com/supabase/headless-vector-search) for adding \"Generative Q&A\" to your documentation. The toolkit is \"headless\", so that you can integrate it into your existing website and style it to match your website theme.\n\nYou can see how this works with the Supabase docs. Just hit `cmd+k` and \"ask\" for something like \"what are the features of supabase?\". You will see that the response is streamed back, using the information provided in the docs:\n"
    }
  },
  {
    "chunk_id": "9125e8d8-f312-402b-ac8d-ed0df92a744f",
    "metadata": {
      "token_count": 23,
      "source_url": "https://supabase.com/docs/guides/ai/examples/headless-vector-search",
      "page_title": "Adding generative Q&A for your documentation | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Adding generative Q&A for your documentation",
        "h2": "Learn how to build a ChatGPT-style doc search powered using our headless search toolkit."
      },
      "text": "\n![headless search](https://supabase.com/docs/img/ai/headless-search/headless.png)\n",
      "overlap_text": {
        "previous_chunk_id": "a7fd6256-1acd-4ed9-9500-553c13d87f77",
        "text": "Content of the previous chunk for context: h1: Adding generative Q&A for your documentation h2: Learn how to build a ChatGPT-style doc search powered using our headless search toolkit.\n\n works with the Supabase docs. Just hit `cmd+k` and \"ask\" for something like \"what are the features of supabase?\". You will see that the response is streamed back, using the information provided in the docs:\n"
      }
    }
  },
  {
    "chunk_id": "57926cd8-b4dc-4ae3-b745-a19a34ea2a58",
    "metadata": {
      "token_count": 31,
      "source_url": "https://supabase.com/docs/guides/ai/examples/headless-vector-search",
      "page_title": "Adding generative Q&A for your documentation | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Adding generative Q&A for your documentation",
        "h2": "Tech stack [\\#](\\#tech-stack)"
      },
      "text": "- Supabase: Database & Edge Functions.\n- OpenAI: Embeddings and completions.\n- GitHub Actions: for ingesting your markdown docs.\n",
      "overlap_text": {
        "previous_chunk_id": "9125e8d8-f312-402b-ac8d-ed0df92a744f",
        "text": "Content of the previous chunk for context: h1: Adding generative Q&A for your documentation h2: Learn how to build a ChatGPT-style doc search powered using our headless search toolkit.\n\n\n![headless search](https://supabase.com/docs/img/ai/headless-search/headless.png)\n"
      }
    }
  },
  {
    "chunk_id": "664780fd-6a9d-4eca-97dd-65f54fe4534d",
    "metadata": {
      "token_count": 76,
      "source_url": "https://supabase.com/docs/guides/ai/examples/headless-vector-search",
      "page_title": "Adding generative Q&A for your documentation | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Adding generative Q&A for your documentation",
        "h2": "Toolkit [\\#](\\#toolkit)"
      },
      "text": "This toolkit consists of 2 parts:\n\n- The [Headless Vector Search](https://github.com/supabase/headless-vector-search) template which you can deploy in your own organization.\n- A [GitHub Action](https://github.com/supabase/embeddings-generator) which will ingest your markdown files, convert them to embeddings, and store them in your database.\n",
      "overlap_text": {
        "previous_chunk_id": "57926cd8-b4dc-4ae3-b745-a19a34ea2a58",
        "text": "Content of the previous chunk for context: h1: Adding generative Q&A for your documentation h2: Tech stack [\\#](\\#tech-stack)\n\n- Supabase: Database & Edge Functions.\n- OpenAI: Embeddings and completions.\n- GitHub Actions: for ingesting your markdown docs.\n"
      }
    }
  },
  {
    "chunk_id": "f455a12e-a54a-47c6-836e-7e15cd4f6214",
    "metadata": {
      "token_count": 128,
      "source_url": "https://supabase.com/docs/guides/ai/examples/headless-vector-search",
      "page_title": "Adding generative Q&A for your documentation | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Adding generative Q&A for your documentation",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "There are 3 steps to build similarity search inside your documentation:\n\n1. Prepare your database.\n2. Ingest your documentation.\n3. Add a search interface.\n\n### Prepare your database [\\#](\\#prepare-your-database)\n\nTo prepare, create a [new Supabase project](https://database.new) and store the database and API credentials, which you can find in the project [settings](https://supabase.com/dashboard/project/_/settings).\n\nNow we can use the [Headless Vector Search](https://github.com/supabase/headless-vector-search#set-up) instructions to set up the database:\n",
      "overlap_text": {
        "previous_chunk_id": "664780fd-6a9d-4eca-97dd-65f54fe4534d",
        "text": "Content of the previous chunk for context: h1: Adding generative Q&A for your documentation h2: Toolkit [\\#](\\#toolkit)\n\n-vector-search) template which you can deploy in your own organization.\n- A [GitHub Action](https://github.com/supabase/embeddings-generator) which will ingest your markdown files, convert them to embeddings, and store them in your database.\n"
      }
    }
  },
  {
    "chunk_id": "3ec9f00b-f18c-406a-aff4-9590358ad2b0",
    "metadata": {
      "token_count": 151,
      "source_url": "https://supabase.com/docs/guides/ai/examples/headless-vector-search",
      "page_title": "Adding generative Q&A for your documentation | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Adding generative Q&A for your documentation",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "\n1. Clone the repo to your local machine: `git clone git@github.com:supabase/headless-vector-search.git`\n2. Link the repo to your remote project: `supabase link --project-ref XXX`\n3. Apply the database migrations: `supabase db push`\n4. Set your OpenAI key as a secret: `supabase secrets set OPENAI_API_KEY=sk-xxx`\n5. Deploy the Edge Functions: `supabase functions deploy --no-verify-jwt`\n6. Expose `docs` schema via API in Supabase Dashboard [settings](https://supabase.com/dashboard/project/_/settings/api) \\> `API Settings` \\> `Exposed schemas`\n\n",
      "overlap_text": {
        "previous_chunk_id": "f455a12e-a54a-47c6-836e-7e15cd4f6214",
        "text": "Content of the previous chunk for context: h1: Adding generative Q&A for your documentation h2: Usage [\\#](\\#usage)\n\n project [settings](https://supabase.com/dashboard/project/_/settings).\n\nNow we can use the [Headless Vector Search](https://github.com/supabase/headless-vector-search#set-up) instructions to set up the database:\n"
      }
    }
  },
  {
    "chunk_id": "3e83eed9-2a57-421b-bcc2-e20712f09733",
    "metadata": {
      "token_count": 103,
      "source_url": "https://supabase.com/docs/guides/ai/examples/headless-vector-search",
      "page_title": "Adding generative Q&A for your documentation | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Adding generative Q&A for your documentation",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "### Ingest your documentation [\\#](\\#ingest-your-documentation)\n\nNow we need to push your documentation into the database as embeddings. You can do this manually, but to make it easier we've created a [GitHub Action](https://github.com/marketplace/actions/supabase-embeddings-generator) which can update your database every time there is a Pull Request.\n\nIn your knowledge base repository, create a new action called `.github/workflows/generate_embeddings.yml` with the following content:\n",
      "overlap_text": {
        "previous_chunk_id": "3ec9f00b-f18c-406a-aff4-9590358ad2b0",
        "text": "Content of the previous chunk for context: h1: Adding generative Q&A for your documentation h2: Usage [\\#](\\#usage)\n\n --no-verify-jwt`\n6. Expose `docs` schema via API in Supabase Dashboard [settings](https://supabase.com/dashboard/project/_/settings/api) \\> `API Settings` \\> `Exposed schemas`\n\n"
      }
    }
  },
  {
    "chunk_id": "8e243f95-5969-48b7-bf4a-9f0eb5cf99e2",
    "metadata": {
      "token_count": 112,
      "source_url": "https://supabase.com/docs/guides/ai/examples/headless-vector-search",
      "page_title": "Adding generative Q&A for your documentation | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Adding generative Q&A for your documentation",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "\n`\n_17\nname: 'generate_embeddings'\n_17\non: # run on main branch changes\n_17\npush:\n_17\n    branches:\n_17\n      - main\n_17\n_17\njobs:\n_17\ngenerate:\n_17\n    runs-on: ubuntu-latest\n_17\n    steps:\n_17\n      - uses: actions/checkout@v3\n_17\n      - uses: supabase/embeddings-generator@v0.0.x # Update this to the latest version.\n",
      "overlap_text": {
        "previous_chunk_id": "3e83eed9-2a57-421b-bcc2-e20712f09733",
        "text": "Content of the previous chunk for context: h1: Adding generative Q&A for your documentation h2: Usage [\\#](\\#usage)\n\narketplace/actions/supabase-embeddings-generator) which can update your database every time there is a Pull Request.\n\nIn your knowledge base repository, create a new action called `.github/workflows/generate_embeddings.yml` with the following content:\n"
      }
    }
  },
  {
    "chunk_id": "347b7b60-c147-4556-bb46-3fe2c14a43f1",
    "metadata": {
      "token_count": 137,
      "source_url": "https://supabase.com/docs/guides/ai/examples/headless-vector-search",
      "page_title": "Adding generative Q&A for your documentation | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Adding generative Q&A for your documentation",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "_17\n        with:\n_17\n          supabase-url: 'https://your-project-ref.supabase.co' # Update this to your project URL.\n_17\n          supabase-service-role-key: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}\n_17\n          openai-key: ${{ secrets.OPENAI_API_KEY }}\n_17\n          docs-root-path: 'docs' # the path to the root of your md(x) files\n`\n\nMake sure to choose the latest version, and set your `SUPABASE_SERVICE_ROLE_KEY` and `OPENAI_API_KEY` as repository secrets in your repo settings (settings > secrets > actions).\n",
      "overlap_text": {
        "previous_chunk_id": "8e243f95-5969-48b7-bf4a-9f0eb5cf99e2",
        "text": "Content of the previous chunk for context: h1: Adding generative Q&A for your documentation h2: Usage [\\#](\\#usage)\n\n-latest\n_17\n    steps:\n_17\n      - uses: actions/checkout@v3\n_17\n      - uses: supabase/embeddings-generator@v0.0.x # Update this to the latest version.\n"
      }
    }
  },
  {
    "chunk_id": "573690c6-4881-4925-92ac-6d9217102ff1",
    "metadata": {
      "token_count": 352,
      "source_url": "https://supabase.com/docs/guides/ai/examples/headless-vector-search",
      "page_title": "Adding generative Q&A for your documentation | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Adding generative Q&A for your documentation",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "\n### Add a search interface [\\#](\\#add-a-search-interface)\n\nNow inside your docs, you need to create a search interface. Because this is a headless interface, you can use it with any language. The only requirement is that you send the user query to the `query` Edge Function, which will stream an answer back from OpenAI. It might look something like this:\n\n``\n_31\nconst onSubmit = (e: Event) => {\n_31\ne.preventDefault()\n_31\nanswer.value = \"\"\n_31\nisLoading.value = true\n_31\n_31\nconst query = new URLSearchParams({ query: inputRef.current!.value })\n_31\nconst projectUrl = `https://your-project-ref.supabase.co/functions/v1`\n_31\nconst queryURL = `${projectURL}/${query}`\n_31\nconst eventSource = new EventSource(queryURL)\n_31\n_31\neventSource.addEventListener(\"error\", (err) => {\n_31\n    isLoading.value = false\n_31\n    console.error(err)\n_31\n})\n_31\n_31\neventSource.addEventListener(\"message\", (e: MessageEvent) => {\n_31\n    isLoading.value = false\n_31\n_31\n    if (e.data === \"[DONE]\") {\n_31\n      eventSource.close()\n_31\n      return\n_31\n    }\n_31\n_31\n    const completionResponse: CreateCompletionResponse = JSON.parse(e.data)\n_31\n    const text = completionResponse.choices[0].text\n_31\n_31\n    answer.value += text\n_31\n});\n_31\n_31\nisLoading.value = true\n_31\n}\n``\n",
      "overlap_text": {
        "previous_chunk_id": "347b7b60-c147-4556-bb46-3fe2c14a43f1",
        "text": "Content of the previous chunk for context: h1: Adding generative Q&A for your documentation h2: Usage [\\#](\\#usage)\n\n the root of your md(x) files\n`\n\nMake sure to choose the latest version, and set your `SUPABASE_SERVICE_ROLE_KEY` and `OPENAI_API_KEY` as repository secrets in your repo settings (settings > secrets > actions).\n"
      }
    }
  },
  {
    "chunk_id": "a9a54ef0-a077-484e-8eed-db7d1d357cad",
    "metadata": {
      "token_count": 86,
      "source_url": "https://supabase.com/docs/guides/ai/examples/headless-vector-search",
      "page_title": "Adding generative Q&A for your documentation | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Adding generative Q&A for your documentation",
        "h2": "Resources [\\#](\\#resources)"
      },
      "text": "- Read about how we built [ChatGPT for the Supabase Docs](https://supabase.com/blog/chatgpt-supabase-docs).\n- Read the pgvector Docs for [Embeddings and vector similarity](/docs/guides/database/extensions/pgvector)\n- See how to build something like this from scratch [using Next.js](/docs/guides/ai/examples/nextjs-vector-search).\n",
      "overlap_text": {
        "previous_chunk_id": "573690c6-4881-4925-92ac-6d9217102ff1",
        "text": "Content of the previous chunk for context: h1: Adding generative Q&A for your documentation h2: Usage [\\#](\\#usage)\n\n(e.data)\n_31\n    const text = completionResponse.choices[0].text\n_31\n_31\n    answer.value += text\n_31\n});\n_31\n_31\nisLoading.value = true\n_31\n}\n``\n"
      }
    }
  },
  {
    "chunk_id": "8b110039-0607-49dd-ae19-292b3215a0be",
    "metadata": {
      "token_count": 55,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/llamaindex",
      "page_title": "Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications. | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications.",
        "h2": "Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications."
      },
      "text": "* * *\n\nThis guide will walk you through a basic example using the LlamaIndex [SupabaseVectorStore](https://github.com/supabase/supabase/blob/master/examples/ai/llamaindex/llamaindex.ipynb).\n"
    }
  },
  {
    "chunk_id": "5053006d-a3ef-427a-abef-904c0423c6f2",
    "metadata": {
      "token_count": 102,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/llamaindex",
      "page_title": "Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications. | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications.",
        "h2": "Project setup [\\#](\\#project-setup)"
      },
      "text": "Let's create a new Postgres database. This is as simple as starting a new Project in Supabase:\n\n1. [Create a new project](https://database.new/) in the Supabase dashboard.\n2. Enter your project details. Remember to store your password somewhere safe.\n\nYour database will be available in less than a minute.\n\n**Finding your credentials:**\n\nYou can find your project credentials inside the project [settings](https://supabase.com/dashboard/project/_/settings/), including:\n",
      "overlap_text": {
        "previous_chunk_id": "8b110039-0607-49dd-ae19-292b3215a0be",
        "text": "Content of the previous chunk for context: h1: Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications. h2: Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications.\n\n will walk you through a basic example using the LlamaIndex [SupabaseVectorStore](https://github.com/supabase/supabase/blob/master/examples/ai/llamaindex/llamaindex.ipynb).\n"
      }
    }
  },
  {
    "chunk_id": "550a28e2-f260-4a0a-aaa2-1da1d6a2a256",
    "metadata": {
      "token_count": 61,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/llamaindex",
      "page_title": "Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications. | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications.",
        "h2": "Project setup [\\#](\\#project-setup)"
      },
      "text": "\n- [Database credentials](https://supabase.com/dashboard/project/_/settings/database): connection strings and connection pooler details.\n- [API credentials](https://supabase.com/dashboard/project/_/settings/database): your serverless API URL and `anon` / `service_role` keys.\n",
      "overlap_text": {
        "previous_chunk_id": "5053006d-a3ef-427a-abef-904c0423c6f2",
        "text": "Content of the previous chunk for context: h1: Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications. h2: Project setup [\\#](\\#project-setup)\n\n store your password somewhere safe.\n\nYour database will be available in less than a minute.\n\n**Finding your credentials:**\n\nYou can find your project credentials inside the project [settings](https://supabase.com/dashboard/project/_/settings/), including:\n"
      }
    }
  },
  {
    "chunk_id": "4e416ea5-6d00-4a8b-b4dc-13d73107bac9",
    "metadata": {
      "token_count": 128,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/llamaindex",
      "page_title": "Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications. | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications.",
        "h2": "Launching a notebook [\\#](\\#launching-a-notebook)"
      },
      "text": "Launch our [LlamaIndex](https://github.com/supabase/supabase/blob/master/examples/ai/llamaindex/llamaindex.ipynb) notebook in Colab:\n\n[![](https://supabase.com/docs/img/ai/colab-badge.svg)](https://colab.research.google.com/github/supabase/supabase/blob/master/examples/ai/llamaindex/llamaindex.ipynb)\n\nAt the top of the notebook, you'll see a button `Copy to Drive`. Click this button to copy the notebook to your Google Drive.\n",
      "overlap_text": {
        "previous_chunk_id": "550a28e2-f260-4a0a-aaa2-1da1d6a2a256",
        "text": "Content of the previous chunk for context: h1: Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications. h2: Project setup [\\#](\\#project-setup)\n\n.com/dashboard/project/_/settings/database): connection strings and connection pooler details.\n- [API credentials](https://supabase.com/dashboard/project/_/settings/database): your serverless API URL and `anon` / `service_role` keys.\n"
      }
    }
  },
  {
    "chunk_id": "4354725e-a442-4000-b059-8042fb47e6bb",
    "metadata": {
      "token_count": 49,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/llamaindex",
      "page_title": "Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications. | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications.",
        "h2": "Fill in your OpenAI credentials [\\#](\\#fill-in-your-openai-credentials)"
      },
      "text": "Inside the Notebook, add your `OPENAI_API_KEY` key. Find the cell which contains this code:\n\n`\n_10\nimport os\n_10\nos.environ['OPENAI_API_KEY'] = \"[your_openai_api_key]\"\n`\n",
      "overlap_text": {
        "previous_chunk_id": "4e416ea5-6d00-4a8b-b4dc-13d73107bac9",
        "text": "Content of the previous chunk for context: h1: Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications. h2: Launching a notebook [\\#](\\#launching-a-notebook)\n\nabase/blob/master/examples/ai/llamaindex/llamaindex.ipynb)\n\nAt the top of the notebook, you'll see a button `Copy to Drive`. Click this button to copy the notebook to your Google Drive.\n"
      }
    }
  },
  {
    "chunk_id": "2a3496d4-8d56-4ba4-9b0f-240eefe6e9aa",
    "metadata": {
      "token_count": 121,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/llamaindex",
      "page_title": "Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications. | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications.",
        "h2": "Connecting to your database [\\#](\\#connecting-to-your-database)"
      },
      "text": "Inside the Notebook, find the cell which specifies the `DB_CONNECTION`. It will contain some code like this:\n\n`\n_10\nDB_CONNECTION = \"postgresql://<user>:<password>@<host>:<port>/<db_name>\"\n_10\n_10\n# create vector store client\n_10\nvx = vecs.create_client(DB_CONNECTION)\n`\n\nReplace the `DB_CONNECTION` with your own connection string for your database. You can find the Postgres connection string in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database) of your Supabase project.\n",
      "overlap_text": {
        "previous_chunk_id": "4354725e-a442-4000-b059-8042fb47e6bb",
        "text": "Content of the previous chunk for context: h1: Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications. h2: Fill in your OpenAI credentials [\\#](\\#fill-in-your-openai-credentials)\n\nInside the Notebook, add your `OPENAI_API_KEY` key. Find the cell which contains this code:\n\n`\n_10\nimport os\n_10\nos.environ['OPENAI_API_KEY'] = \"[your_openai_api_key]\"\n`\n"
      }
    }
  },
  {
    "chunk_id": "ec486ed1-2879-4e87-b4bd-f6f4fee1fbb6",
    "metadata": {
      "token_count": 70,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/llamaindex",
      "page_title": "Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications. | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications.",
        "h2": "Connecting to your database [\\#](\\#connecting-to-your-database)"
      },
      "text": "\nSQLAlchemy requires the connection string to start with `postgresql://` (instead of `postgres://`). Don't forget to rename this after copying the string from the dashboard.\n\nYou must use the \"connection pooling\" string (domain ending in `*.pooler.supabase.com`) with Google Colab since Colab does not support IPv6.\n",
      "overlap_text": {
        "previous_chunk_id": "2a3496d4-8d56-4ba4-9b0f-240eefe6e9aa",
        "text": "Content of the previous chunk for context: h1: Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications. h2: Connecting to your database [\\#](\\#connecting-to-your-database)\n\n`\n\nReplace the `DB_CONNECTION` with your own connection string for your database. You can find the Postgres connection string in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database) of your Supabase project.\n"
      }
    }
  },
  {
    "chunk_id": "25a8a702-35c2-419d-8b7e-b9d0aee11b6d",
    "metadata": {
      "token_count": 121,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/llamaindex",
      "page_title": "Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications. | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications.",
        "h2": "Stepping through the notebook [\\#](\\#stepping-through-the-notebook)"
      },
      "text": "Now all that's left is to step through the notebook. You can do this by clicking the \"execute\" button ( `ctrl+enter`) at the top left of each code cell. The notebook guides you through the process of creating a collection, adding data to it, and querying it.\n\nYou can view the inserted items in the [Table Editor](https://supabase.com/dashboard/project/_/editor/), by selecting the `vecs` schema from the schema dropdown.\n\n![Colab documents](https://supabase.com/docs/img/ai/google-colab/colab-documents.png)\n",
      "overlap_text": {
        "previous_chunk_id": "ec486ed1-2879-4e87-b4bd-f6f4fee1fbb6",
        "text": "Content of the previous chunk for context: h1: Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications. h2: Connecting to your database [\\#](\\#connecting-to-your-database)\n\n`). Don't forget to rename this after copying the string from the dashboard.\n\nYou must use the \"connection pooling\" string (domain ending in `*.pooler.supabase.com`) with Google Colab since Colab does not support IPv6.\n"
      }
    }
  },
  {
    "chunk_id": "ab17beb5-1b16-4e8b-97c6-1ef3ec9d73af",
    "metadata": {
      "token_count": 63,
      "source_url": "https://supabase.com/docs/guides/ai/integrations/llamaindex",
      "page_title": "Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications. | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications.",
        "h2": "Resources [\\#](\\#resources)"
      },
      "text": "- Visit the LlamaIndex + SupabaseVectorStore [docs](https://gpt-index.readthedocs.io/en/latest/examples/vector_stores/SupabaseVectorIndexDemo.html)\n- Visit the official LlamaIndex [repo](https://github.com/jerryjliu/llama_index/)\n",
      "overlap_text": {
        "previous_chunk_id": "25a8a702-35c2-419d-8b7e-b9d0aee11b6d",
        "text": "Content of the previous chunk for context: h1: Learn how to integrate Supabase with LlamaIndex, a data framework for your LLM applications. h2: Stepping through the notebook [\\#](\\#stepping-through-the-notebook)\n\nhttps://supabase.com/dashboard/project/_/editor/), by selecting the `vecs` schema from the schema dropdown.\n\n![Colab documents](https://supabase.com/docs/img/ai/google-colab/colab-documents.png)\n"
      }
    }
  },
  {
    "chunk_id": "76c9ea56-1701-43b5-b0d2-b405afc8f8dd",
    "metadata": {
      "token_count": 62,
      "source_url": "https://supabase.com/docs/guides/ai/choosing-compute-addon",
      "page_title": "Choosing your Compute Add-on | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Choosing your Compute Add-on",
        "h2": "Choosing the right Compute Add-on for your vector workload."
      },
      "text": "* * *\n\nYou have two options for scaling your vector workload:\n\n1. Increase the size of your database. This guide will help you choose the right size for your workload.\n2. Spread your workload across multiple databases. You can find more details about this approach in [Engineering for Scale](engineering-for-scale).\n"
    }
  },
  {
    "chunk_id": "f496a9aa-2573-4172-9846-ecef91460563",
    "metadata": {
      "token_count": 126,
      "source_url": "https://supabase.com/docs/guides/ai/choosing-compute-addon",
      "page_title": "Choosing your Compute Add-on | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Choosing your Compute Add-on",
        "h2": "Dimensionality [\\#](\\#dimensionality)"
      },
      "text": "The number of dimensions in your embeddings is the most important factor in choosing the right Compute Add-on. In general, the lower the dimensionality the better the performance. We've provided guidance for some of the more common embedding dimensions below. For each benchmark, we used [Vecs](https://github.com/supabase/vecs) to create a collection, upload the embeddings to a single table, and create both the `IVFFlat` and `HNSW` indexes for `inner-product` distance measure for the embedding column. We then ran a series of queries to measure the performance of different compute add-ons:\n",
      "overlap_text": {
        "previous_chunk_id": "76c9ea56-1701-43b5-b0d2-b405afc8f8dd",
        "text": "Content of the previous chunk for context: h1: Choosing your Compute Add-on h2: Choosing the right Compute Add-on for your vector workload.\n\n:\n\n1. Increase the size of your database. This guide will help you choose the right size for your workload.\n2. Spread your workload across multiple databases. You can find more details about this approach in [Engineering for Scale](engineering-for-scale).\n"
      }
    }
  },
  {
    "chunk_id": "58343d25-76f1-4f43-a367-a6f6da2ff8f4",
    "metadata": {
      "token_count": 564,
      "source_url": "https://supabase.com/docs/guides/ai/choosing-compute-addon",
      "page_title": "Choosing your Compute Add-on | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Choosing your Compute Add-on",
        "h2": "HNSW [\\#](\\#hnsw)"
      },
      "text": "### 384 dimensions [\\#](\\#hnsw-384-dimensions)\n\nThis benchmark uses the dbpedia-entities-openai-1M dataset containing 1,000,000 embeddings of text, regenerated for 384 dimension embeddings. Each embedding is generated using [gte-small](https://huggingface.co/Supabase/gte-small).\n\ngte-small-384\n\n| Compute Size | Vectors | m | ef\\_construction | ef\\_search | QPS | Latency Mean | Latency p95 | RAM Usage | RAM |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| Micro | 100,000 | 16 | 64 | 60 | 580 | 0.017 sec | 0.024 sec | 1.2 (Swap) | 1 GB |\n| Small | 250,000 | 24 | 64 | 60 | 440 | 0.022 sec | 0.033 sec | 2 GB | 2 GB |\n| Medium | 500,000 | 24 | 64 | 80 | 350 | 0.028 sec | 0.045 sec | 4 GB | 4 GB |\n| Large | 1,000,000 | 32 | 80 | 100 | 270 | 0.073 sec | 0.108 sec | 7 GB | 8 GB |\n| XL | 1,000,000 | 32 | 80 | 100 | 525 | 0.038 sec | 0.059 sec | 9 GB | 16 GB |\n| 2XL | 1,000,000 | 32 | 80 | 100 | 790 | 0.025 sec | 0.037 sec | 9 GB | 32 GB |\n| 4XL | 1,000,000 | 32 | 80 | 100 | 1650 | 0.015 sec | 0.018 sec | 11 GB | 64 GB |\n| 8XL | 1,000,000 | 32 | 80 | 100 | 2690 | 0.015 sec | 0.016 sec | 13 GB | 128 GB |\n| 12XL | 1,000,000 | 32 | 80 | 100 | 3900 | 0.014 sec | 0.016 sec | 13 GB | 192 GB |\n| 16XL | 1,000,000 | 32 | 80 | 100 | 4200 | 0.014 sec | 0.016 sec | 20 GB | 256 GB |\n\n",
      "overlap_text": {
        "previous_chunk_id": "f496a9aa-2573-4172-9846-ecef91460563",
        "text": "Content of the previous chunk for context: h1: Choosing your Compute Add-on h2: Dimensionality [\\#](\\#dimensionality)\n\n to a single table, and create both the `IVFFlat` and `HNSW` indexes for `inner-product` distance measure for the embedding column. We then ran a series of queries to measure the performance of different compute add-ons:\n"
      }
    }
  },
  {
    "chunk_id": "c0e28833-360e-4c61-9800-c802f3e6c0aa",
    "metadata": {
      "token_count": 562,
      "source_url": "https://supabase.com/docs/guides/ai/choosing-compute-addon",
      "page_title": "Choosing your Compute Add-on | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Choosing your Compute Add-on",
        "h2": "HNSW [\\#](\\#hnsw)"
      },
      "text": "Accuracy was 0.99 for benchmarks.\n\n### 960 dimensions [\\#](\\#hnsw-960-dimensions)\n\nThis benchmark uses the [gist-960](http://corpus-texmex.irisa.fr/) dataset, which contains 1,000,000 embeddings of images. Each embedding is 960 dimensions.\n\ngist-960\n\n| Compute Size | Vectors | m | ef\\_construction | ef\\_search | QPS | Latency Mean | Latency p95 | RAM Usage | RAM |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| Micro | 30,000 | 16 | 64 | 65 | 430 | 0.024 sec | 0.034 sec | 1.2 GB (Swap) | 1 GB |\n| Small | 100,000 | 32 | 80 | 60 | 260 | 0.040 sec | 0.054 sec | 2.2 GB (Swap) | 2 GB |\n| Medium | 250,000 | 32 | 80 | 90 | 120 | 0.083 sec | 0.106 sec | 4 GB | 4 GB |\n| Large | 500,000 | 32 | 80 | 120 | 160 | 0.063 sec | 0.087 sec | 7 GB | 8 GB |\n| XL | 1,000,000 | 32 | 80 | 200 | 200 | 0.049 sec | 0.072 sec | 13 GB | 16 GB |\n| 2XL | 1,000,000 | 32 | 80 | 200 | 340 | 0.025 sec | 0.029 sec | 17 GB | 32 GB |\n| 4XL | 1,000,000 | 32 | 80 | 200 | 630 | 0.031 sec | 0.050 sec | 18 GB | 64 GB |\n| 8XL | 1,000,000 | 32 | 80 | 200 | 1100 | 0.034 sec | 0.048 sec | 19 GB | 128 GB |\n| 12XL | 1,000,000 | 32 | 80 | 200 | 1420 | 0.041 sec | 0.095 sec | 21 GB | 192 GB |\n| 16XL | 1,000,000 | 32 | 80 | 200 | 1650 | 0.037 sec | 0.081 sec | 23 GB | 256 GB |\n\n",
      "overlap_text": {
        "previous_chunk_id": "58343d25-76f1-4f43-a367-a6f6da2ff8f4",
        "text": "Content of the previous chunk for context: h1: Choosing your Compute Add-on h2: HNSW [\\#](\\#hnsw)\n\n | 192 GB |\n| 16XL | 1,000,000 | 32 | 80 | 100 | 4200 | 0.014 sec | 0.016 sec | 20 GB | 256 GB |\n\n"
      }
    }
  },
  {
    "chunk_id": "822cb567-7160-4ba1-9b71-bca0602880ee",
    "metadata": {
      "token_count": 214,
      "source_url": "https://supabase.com/docs/guides/ai/choosing-compute-addon",
      "page_title": "Choosing your Compute Add-on | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Choosing your Compute Add-on",
        "h2": "HNSW [\\#](\\#hnsw)"
      },
      "text": "Accuracy was 0.99 for benchmarks.\n\nQPS can also be improved by increasing [`m` and `ef_construction`](/docs/guides/ai/going-to-prod#hnsw-understanding-efconstruction--efsearch--and-m). This will allow you to use a smaller value for `ef_search` and increase QPS.\n\n### 1536 dimensions [\\#](\\#hnsw-1536-dimensions)\n\nThis benchmark uses the [dbpedia-entities-openai-1M](https://huggingface.co/datasets/KShivendu/dbpedia-entities-openai-1M) dataset, which contains 1,000,000 embeddings of text. And 224,482 embeddings from [Wikipedia articles](https://huggingface.co/datasets/Supabase/wikipedia-en-embeddings) for compute add-ons `large` and below. Each embedding is 1536 dimensions created with the [OpenAI Embeddings API](https://platform.openai.com/docs/guides/embeddings).\n",
      "overlap_text": {
        "previous_chunk_id": "c0e28833-360e-4c61-9800-c802f3e6c0aa",
        "text": "Content of the previous chunk for context: h1: Choosing your Compute Add-on h2: HNSW [\\#](\\#hnsw)\n\n | 192 GB |\n| 16XL | 1,000,000 | 32 | 80 | 200 | 1650 | 0.037 sec | 0.081 sec | 23 GB | 256 GB |\n\n"
      }
    }
  },
  {
    "chunk_id": "d795306c-0e23-45ba-a869-a3f0c549f92d",
    "metadata": {
      "token_count": 495,
      "source_url": "https://supabase.com/docs/guides/ai/choosing-compute-addon",
      "page_title": "Choosing your Compute Add-on | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Choosing your Compute Add-on",
        "h2": "HNSW [\\#](\\#hnsw)"
      },
      "text": "\nOpenAI-1536\n\n| Compute Size | Vectors | m | ef\\_construction | ef\\_search | QPS | Latency Mean | Latency p95 | RAM Usage | RAM |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| Micro | 15,000 | 16 | 40 | 40 | 480 | 0.011 sec | 0.016 sec | 1.2 GB (Swap) | 1 GB |\n| Small | 50,000 | 32 | 64 | 100 | 175 | 0.031 sec | 0.051 sec | 2.2 GB (Swap) | 2 GB |\n| Medium | 100,000 | 32 | 64 | 100 | 240 | 0.083 sec | 0.126 sec | 4 GB | 4 GB |\n| Large | 224,482 | 32 | 64 | 100 | 280 | 0.017 sec | 0.028 sec | 8 GB | 8 GB |\n| XL | 500,000 | 24 | 56 | 100 | 360 | 0.055 sec | 0.135 sec | 13 GB | 16 GB |\n| 2XL | 1,000,000 | 24 | 56 | 250 | 560 | 0.036 sec | 0.058 sec | 32 GB | 32 GB |\n| 4XL | 1,000,000 | 24 | 56 | 250 | 950 | 0.021 sec | 0.033 sec | 39 GB | 64 GB |\n| 8XL | 1,000,000 | 24 | 56 | 250 | 1650 | 0.016 sec | 0.023 sec | 40 GB | 128 GB |\n| 12XL | 1,000,000 | 24 | 56 | 250 | 1900 | 0.015 sec | 0.021 sec | 38 GB | 192 GB |\n| 16XL | 1,000,000 | 24 | 56 | 250 | 2200 | 0.015 sec | 0.020 sec | 40 GB | 256 GB |\n\n",
      "overlap_text": {
        "previous_chunk_id": "822cb567-7160-4ba1-9b71-bca0602880ee",
        "text": "Content of the previous chunk for context: h1: Choosing your Compute Add-on h2: HNSW [\\#](\\#hnsw)\n\nSupabase/wikipedia-en-embeddings) for compute add-ons `large` and below. Each embedding is 1536 dimensions created with the [OpenAI Embeddings API](https://platform.openai.com/docs/guides/embeddings).\n"
      }
    }
  },
  {
    "chunk_id": "665a7af1-7d3b-4d9c-8f1e-15a3b9c93844",
    "metadata": {
      "token_count": 104,
      "source_url": "https://supabase.com/docs/guides/ai/choosing-compute-addon",
      "page_title": "Choosing your Compute Add-on | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Choosing your Compute Add-on",
        "h2": "HNSW [\\#](\\#hnsw)"
      },
      "text": "Accuracy was 0.99 for benchmarks.\n\nQPS can also be improved by increasing [`m` and `ef_construction`](/docs/guides/ai/going-to-prod#hnsw-understanding-efconstruction--efsearch--and-m). This will allow you to use a smaller value for `ef_search` and increase QPS. For example, increasing `m` to 32 and `ef_construction` to 80 for 4XL will increase QPS to 1280.\n",
      "overlap_text": {
        "previous_chunk_id": "d795306c-0e23-45ba-a869-a3f0c549f92d",
        "text": "Content of the previous chunk for context: h1: Choosing your Compute Add-on h2: HNSW [\\#](\\#hnsw)\n\n | 192 GB |\n| 16XL | 1,000,000 | 24 | 56 | 250 | 2200 | 0.015 sec | 0.020 sec | 40 GB | 256 GB |\n\n"
      }
    }
  },
  {
    "chunk_id": "abf97380-be96-4310-9797-c72b330ed6b2",
    "metadata": {
      "token_count": 81,
      "source_url": "https://supabase.com/docs/guides/ai/choosing-compute-addon",
      "page_title": "Choosing your Compute Add-on | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Choosing your Compute Add-on",
        "h2": "HNSW [\\#](\\#hnsw)"
      },
      "text": "\nIt is possible to upload more vectors to a single table if Memory allows it (for example, 4XL plan and higher for OpenAI embeddings). But it will affect the performance of the queries: QPS will be lower, and latency will be higher. Scaling should be almost linear, but it is recommended to benchmark your workload to find the optimal number of vectors per table and per database instance.\n",
      "overlap_text": {
        "previous_chunk_id": "665a7af1-7d3b-4d9c-8f1e-15a3b9c93844",
        "text": "Content of the previous chunk for context: h1: Choosing your Compute Add-on h2: HNSW [\\#](\\#hnsw)\n\n will allow you to use a smaller value for `ef_search` and increase QPS. For example, increasing `m` to 32 and `ef_construction` to 80 for 4XL will increase QPS to 1280.\n"
      }
    }
  },
  {
    "chunk_id": "9d83a4d0-d2b3-4fb6-a9b7-7290bb105fa8",
    "metadata": {
      "token_count": 553,
      "source_url": "https://supabase.com/docs/guides/ai/choosing-compute-addon",
      "page_title": "Choosing your Compute Add-on | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Choosing your Compute Add-on",
        "h2": "IVFFlat [\\#](\\#ivfflat)"
      },
      "text": "### 384 dimensions [\\#](\\#ivfflat-384-dimensions)\n\nThis benchmark uses the dbpedia-entities-openai-1M dataset containing 1,000,000 embeddings of text, regenerated for 384 dimension embeddings. Each embedding is generated using [gte-small](https://huggingface.co/Supabase/gte-small).\n\ngte-small-384, accuracy=.98gte-small-384, accuracy=.99\n\n| Compute Size | Vectors | Lists | Probes | QPS | Latency Mean | Latency p95 | RAM Usage | RAM |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| Micro | 100,000 | 500 | 50 | 205 | 0.048 sec | 0.066 sec | 1.2 GB (Swap) | 1 GB |\n| Small | 250,000 | 1000 | 60 | 160 | 0.062 sec | 0.079 sec | 2 GB | 2 GB |\n| Medium | 500,000 | 2000 | 80 | 120 | 0.082 sec | 0.104 sec | 3.2 GB | 4 GB |\n| Large | 1,000,000 | 5000 | 150 | 75 | 0.269 sec | 0.375 sec | 6.5 GB | 8 GB |\n| XL | 1,000,000 | 5000 | 150 | 150 | 0.131 sec | 0.178 sec | 9 GB | 16 GB |\n| 2XL | 1,000,000 | 5000 | 150 | 300 | 0.066 sec | 0.099 sec | 10 GB | 32 GB |\n| 4XL | 1,000,000 | 5000 | 150 | 570 | 0.035 sec | 0.046 sec | 10 GB | 64 GB |\n| 8XL | 1,000,000 | 5000 | 150 | 1400 | 0.023 sec | 0.028 sec | 12 GB | 128 GB |\n| 12XL | 1,000,000 | 5000 | 150 | 1550 | 0.030 sec | 0.039 sec | 12 GB | 192 GB |\n| 16XL | 1,000,000 | 5000 | 150 | 1800 | 0.030 sec | 0.039 sec | 16 GB | 256 GB |\n\n",
      "overlap_text": {
        "previous_chunk_id": "abf97380-be96-4310-9797-c72b330ed6b2",
        "text": "Content of the previous chunk for context: h1: Choosing your Compute Add-on h2: HNSW [\\#](\\#hnsw)\n\n But it will affect the performance of the queries: QPS will be lower, and latency will be higher. Scaling should be almost linear, but it is recommended to benchmark your workload to find the optimal number of vectors per table and per database instance.\n"
      }
    }
  },
  {
    "chunk_id": "5bc5a2ad-7d0a-475c-8bac-8de1f7f3e7d2",
    "metadata": {
      "token_count": 495,
      "source_url": "https://supabase.com/docs/guides/ai/choosing-compute-addon",
      "page_title": "Choosing your Compute Add-on | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Choosing your Compute Add-on",
        "h2": "IVFFlat [\\#](\\#ivfflat)"
      },
      "text": "### 960 dimensions [\\#](\\#ivfflat-960-dimensions)\n\nThis benchmark uses the [gist-960](http://corpus-texmex.irisa.fr/) dataset, which contains 1,000,000 embeddings of images. Each embedding is 960 dimensions.\n\ngist-960, probes = 10\n\n| Compute Size | Vectors | Lists | QPS | Latency Mean | Latency p95 | RAM Usage | RAM |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n| Micro | 30,000 | 30 | 75 | 0.065 sec | 0.088 sec | 1.1 GB (Swap) | 1 GB |\n| Small | 100,000 | 100 | 78 | 0.064 sec | 0.092 sec | 1.8 GB | 2 GB |\n| Medium | 250,000 | 250 | 58 | 0.085 sec | 0.129 sec | 3.2 GB | 4 GB |\n| Large | 500,000 | 500 | 55 | 0.088 sec | 0.140 sec | 5 GB | 8 GB |\n| XL | 1,000,000 | 1000 | 110 | 0.046 sec | 0.070 sec | 14 GB | 16 GB |\n| 2XL | 1,000,000 | 1000 | 235 | 0.083 sec | 0.136 sec | 10 GB | 32 GB |\n| 4XL | 1,000,000 | 1000 | 420 | 0.071 sec | 0.106 sec | 11 GB | 64 GB |\n| 8XL | 1,000,000 | 1000 | 815 | 0.072 sec | 0.106 sec | 13 GB | 128 GB |\n| 12XL | 1,000,000 | 1000 | 1150 | 0.052 sec | 0.078 sec | 15.5 GB | 192 GB |\n| 16XL | 1,000,000 | 1000 | 1345 | 0.072 sec | 0.106 sec | 17.5 GB | 256 GB |\n\n",
      "overlap_text": {
        "previous_chunk_id": "9d83a4d0-d2b3-4fb6-a9b7-7290bb105fa8",
        "text": "Content of the previous chunk for context: h1: Choosing your Compute Add-on h2: IVFFlat [\\#](\\#ivfflat)\n\n12 GB | 192 GB |\n| 16XL | 1,000,000 | 5000 | 150 | 1800 | 0.030 sec | 0.039 sec | 16 GB | 256 GB |\n\n"
      }
    }
  },
  {
    "chunk_id": "42afe8dc-091a-444d-905c-800f813c70b5",
    "metadata": {
      "token_count": 102,
      "source_url": "https://supabase.com/docs/guides/ai/choosing-compute-addon",
      "page_title": "Choosing your Compute Add-on | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Choosing your Compute Add-on",
        "h2": "IVFFlat [\\#](\\#ivfflat)"
      },
      "text": "### 1536 dimensions [\\#](\\#ivfflat-1536-dimensions)\n\nThis benchmark uses the [dbpedia-entities-openai-1M](https://huggingface.co/datasets/KShivendu/dbpedia-entities-openai-1M) dataset, which contains 1,000,000 embeddings of text. Each embedding is 1536 dimensions created with the [OpenAI Embeddings API](https://platform.openai.com/docs/guides/embeddings).\n",
      "overlap_text": {
        "previous_chunk_id": "5bc5a2ad-7d0a-475c-8bac-8de1f7f3e7d2",
        "text": "Content of the previous chunk for context: h1: Choosing your Compute Add-on h2: IVFFlat [\\#](\\#ivfflat)\n\n.5 GB | 192 GB |\n| 16XL | 1,000,000 | 1000 | 1345 | 0.072 sec | 0.106 sec | 17.5 GB | 256 GB |\n\n"
      }
    }
  },
  {
    "chunk_id": "54831934-cbdd-40ce-b4f4-3f83e85e7a5b",
    "metadata": {
      "token_count": 445,
      "source_url": "https://supabase.com/docs/guides/ai/choosing-compute-addon",
      "page_title": "Choosing your Compute Add-on | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Choosing your Compute Add-on",
        "h2": "IVFFlat [\\#](\\#ivfflat)"
      },
      "text": "\nOpenAI-1536, probes = 10OpenAI-1536, probes = 40\n\n| Compute Size | Vectors | Lists | QPS | Latency Mean | Latency p95 | RAM Usage | RAM |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n| Micro | 20,000 | 40 | 135 | 0.372 sec | 0.412 sec | 1.2 GB (Swap) | 1 GB |\n| Small | 50,000 | 100 | 140 | 0.357 sec | 0.398 sec | 1.8 GB | 2 GB |\n| Medium | 100,000 | 200 | 130 | 0.383 sec | 0.446 sec | 3.7 GB | 4 GB |\n| Large | 250,000 | 500 | 130 | 0.378 sec | 0.434 sec | 7 GB | 8 GB |\n| XL | 500,000 | 1000 | 235 | 0.213 sec | 0.271 sec | 13.5 GB | 16 GB |\n| 2XL | 1,000,000 | 2000 | 380 | 0.133 sec | 0.236 sec | 30 GB | 32 GB |\n| 4XL | 1,000,000 | 2000 | 720 | 0.068 sec | 0.120 sec | 35 GB | 64 GB |\n| 8XL | 1,000,000 | 2000 | 1250 | 0.039 sec | 0.066 sec | 38 GB | 128 GB |\n| 12XL | 1,000,000 | 2000 | 1600 | 0.030 sec | 0.052 sec | 41 GB | 192 GB |\n| 16XL | 1,000,000 | 2000 | 1790 | 0.029 sec | 0.051 sec | 45 GB | 256 GB |\n\n",
      "overlap_text": {
        "previous_chunk_id": "42afe8dc-091a-444d-905c-800f813c70b5",
        "text": "Content of the previous chunk for context: h1: Choosing your Compute Add-on h2: IVFFlat [\\#](\\#ivfflat)\n\n-openai-1M) dataset, which contains 1,000,000 embeddings of text. Each embedding is 1536 dimensions created with the [OpenAI Embeddings API](https://platform.openai.com/docs/guides/embeddings).\n"
      }
    }
  },
  {
    "chunk_id": "c258a1b3-dd57-4867-9d28-b548cafd638a",
    "metadata": {
      "token_count": 142,
      "source_url": "https://supabase.com/docs/guides/ai/choosing-compute-addon",
      "page_title": "Choosing your Compute Add-on | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Choosing your Compute Add-on",
        "h2": "IVFFlat [\\#](\\#ivfflat)"
      },
      "text": "For 1,000,000 vectors 10 probes results to accuracy of 0.91. And for 500,000 vectors and below 10 probes results to accuracy in the range of 0.95 - 0.99. To increase accuracy, you need to increase the number of probes.\n\nIt is possible to upload more vectors to a single table if Memory allows it (for example, 4XL plan and higher for OpenAI embeddings). But it will affect the performance of the queries: QPS will be lower, and latency will be higher. Scaling should be almost linear, but it is recommended to benchmark your workload to find the optimal number of vectors per table and per database instance.\n",
      "overlap_text": {
        "previous_chunk_id": "54831934-cbdd-40ce-b4f4-3f83e85e7a5b",
        "text": "Content of the previous chunk for context: h1: Choosing your Compute Add-on h2: IVFFlat [\\#](\\#ivfflat)\n\n sec | 41 GB | 192 GB |\n| 16XL | 1,000,000 | 2000 | 1790 | 0.029 sec | 0.051 sec | 45 GB | 256 GB |\n\n"
      }
    }
  },
  {
    "chunk_id": "ab286e0c-aed8-4683-801c-1467e6c7087d",
    "metadata": {
      "token_count": 136,
      "source_url": "https://supabase.com/docs/guides/ai/choosing-compute-addon",
      "page_title": "Choosing your Compute Add-on | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Choosing your Compute Add-on",
        "h2": "Performance tips [\\#](\\#performance-tips)"
      },
      "text": "There are various ways to improve your pgvector performance. Here are some tips:\n\n### Pre-warming your database [\\#](\\#pre-warming-your-database)\n\nIt's useful to execute a few thousand \u201cwarm-up\u201d queries before going into production. This helps help with RAM utilization. This can also help to determine that you've selected the right compute size for your workload.\n\n### Finetune index parameters [\\#](\\#finetune-index-parameters)\n\nYou can increase the Requests per Second by increasing `m` and `ef_construction` or `lists`. This also has an important caveat: building the index takes longer with higher values for these parameters.\n",
      "overlap_text": {
        "previous_chunk_id": "c258a1b3-dd57-4867-9d28-b548cafd638a",
        "text": "Content of the previous chunk for context: h1: Choosing your Compute Add-on h2: IVFFlat [\\#](\\#ivfflat)\n\n But it will affect the performance of the queries: QPS will be lower, and latency will be higher. Scaling should be almost linear, but it is recommended to benchmark your workload to find the optimal number of vectors per table and per database instance.\n"
      }
    }
  },
  {
    "chunk_id": "15bec533-43bb-4fbe-9603-5d250fb081d8",
    "metadata": {
      "token_count": 33,
      "source_url": "https://supabase.com/docs/guides/ai/choosing-compute-addon",
      "page_title": "Choosing your Compute Add-on | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Choosing your Compute Add-on",
        "h2": "Performance tips [\\#](\\#performance-tips)"
      },
      "text": "\nHNSWIVFFlat\n\nCheck out more tips and the complete step-by-step guide in [Going to Production for AI applications](going-to-prod).\n",
      "overlap_text": {
        "previous_chunk_id": "ab286e0c-aed8-4683-801c-1467e6c7087d",
        "text": "Content of the previous chunk for context: h1: Choosing your Compute Add-on h2: Performance tips [\\#](\\#performance-tips)\n\n\\#finetune-index-parameters)\n\nYou can increase the Requests per Second by increasing `m` and `ef_construction` or `lists`. This also has an important caveat: building the index takes longer with higher values for these parameters.\n"
      }
    }
  },
  {
    "chunk_id": "5c16cb2e-5452-4e25-8a27-ee76e5e265ff",
    "metadata": {
      "token_count": 117,
      "source_url": "https://supabase.com/docs/guides/ai/choosing-compute-addon",
      "page_title": "Choosing your Compute Add-on | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Choosing your Compute Add-on",
        "h2": "Benchmark methodology [\\#](\\#benchmark-methodology)"
      },
      "text": "We follow techniques outlined in the [ANN Benchmarks](https://github.com/erikbern/ann-benchmarks) methodology. A Python test runner is responsible for uploading the data, creating the index, and running the queries. The pgvector engine is implemented using [vecs](https://github.com/supabase/vecs), a Python client for pgvector.\n\nEach test is run for a minimum of 30-40 minutes. They include a series of experiments executed at different concurrency levels to measure the engine's performance under different load types. The results are then averaged.\n",
      "overlap_text": {
        "previous_chunk_id": "15bec533-43bb-4fbe-9603-5d250fb081d8",
        "text": "Content of the previous chunk for context: h1: Choosing your Compute Add-on h2: Performance tips [\\#](\\#performance-tips)\n\n\nHNSWIVFFlat\n\nCheck out more tips and the complete step-by-step guide in [Going to Production for AI applications](going-to-prod).\n"
      }
    }
  },
  {
    "chunk_id": "cf2b894d-590a-41a9-bec2-c29f44f21516",
    "metadata": {
      "token_count": 32,
      "source_url": "https://supabase.com/docs/guides/ai/choosing-compute-addon",
      "page_title": "Choosing your Compute Add-on | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Choosing your Compute Add-on",
        "h2": "Benchmark methodology [\\#](\\#benchmark-methodology)"
      },
      "text": "\nAs a general recommendation, we suggest using a concurrency level of 5 or more for most workloads and 30 or more for high-load workloads.\n",
      "overlap_text": {
        "previous_chunk_id": "5c16cb2e-5452-4e25-8a27-ee76e5e265ff",
        "text": "Content of the previous chunk for context: h1: Choosing your Compute Add-on h2: Benchmark methodology [\\#](\\#benchmark-methodology)\n\n), a Python client for pgvector.\n\nEach test is run for a minimum of 30-40 minutes. They include a series of experiments executed at different concurrency levels to measure the engine's performance under different load types. The results are then averaged.\n"
      }
    }
  },
  {
    "chunk_id": "ec2ddddb-fdef-454e-8b31-f4482d2bbbc1",
    "metadata": {
      "token_count": 65,
      "source_url": "https://supabase.com/docs/guides/ai/vecs-python-client",
      "page_title": "Python client | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Python client",
        "h2": "Manage unstructured vector stores in PostgreSQL."
      },
      "text": "* * *\n\nSupabase provides a Python client called [`vecs`](https://github.com/supabase/vecs) for managing unstructured vector stores. This client provides a set of useful tools for creating and querying collections in PostgreSQL using the [pgvector](/docs/guides/database/extensions/pgvector) extension.\n"
    }
  },
  {
    "chunk_id": "44bee122-2d06-4da4-8df6-d23b68ffdbe6",
    "metadata": {
      "token_count": 114,
      "source_url": "https://supabase.com/docs/guides/ai/vecs-python-client",
      "page_title": "Python client | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Python client",
        "h2": "Quick start [\\#](\\#quick-start)"
      },
      "text": "Let's see how Vecs works using a local database. Make sure you have the Supabase CLI [installed](/docs/guides/cli#installation) on your machine.\n\n### Initialize your project [\\#](\\#initialize-your-project)\n\nStart a local Postgres instance in any folder using the `init` and `start` commands. Make sure you have Docker running!\n\n`\n_10\n# Initialize your project\n_10\nsupabase init\n_10\n_10\n# Start Postgres\n_10\nsupabase start\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "ec2ddddb-fdef-454e-8b31-f4482d2bbbc1",
        "text": "Content of the previous chunk for context: h1: Python client h2: Manage unstructured vector stores in PostgreSQL.\n\n://github.com/supabase/vecs) for managing unstructured vector stores. This client provides a set of useful tools for creating and querying collections in PostgreSQL using the [pgvector](/docs/guides/database/extensions/pgvector) extension.\n"
      }
    }
  },
  {
    "chunk_id": "4d2eabc6-b660-434b-a7eb-7ebc6b10ebfd",
    "metadata": {
      "token_count": 115,
      "source_url": "https://supabase.com/docs/guides/ai/vecs-python-client",
      "page_title": "Python client | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Python client",
        "h2": "Quick start [\\#](\\#quick-start)"
      },
      "text": "### Create a collection [\\#](\\#create-a-collection)\n\nInside a Python shell, run the following commands to create a new collection called \"docs\", with 3 dimensions.\n\n`\n_10\nimport vecs\n_10\n_10\n# create vector store client\n_10\nvx = vecs.create_client(\"postgresql://postgres:postgres@localhost:54322/postgres\")\n_10\n_10\n# create a collection of vectors with 3 dimensions\n_10\ndocs = vx.get_or_create_collection(name=\"docs\", dimension=3)\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "44bee122-2d06-4da4-8df6-d23b68ffdbe6",
        "text": "Content of the previous chunk for context: h1: Python client h2: Quick start [\\#](\\#quick-start)\n\n and `start` commands. Make sure you have Docker running!\n\n`\n_10\n# Initialize your project\n_10\nsupabase init\n_10\n_10\n# Start Postgres\n_10\nsupabase start\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "51f56b87-d918-48ec-9972-a466205be152",
    "metadata": {
      "token_count": 182,
      "source_url": "https://supabase.com/docs/guides/ai/vecs-python-client",
      "page_title": "Python client | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Python client",
        "h2": "Quick start [\\#](\\#quick-start)"
      },
      "text": "### Add embeddings [\\#](\\#add-embeddings)\n\nNow we can insert some embeddings into our \"docs\" collection using the `upsert()` command:\n\n`\n_13\nimport vecs\n_13\n_13\n# create vector store client\n_13\ndocs = vecs.get_or_create_collection(name=\"docs\", dimension=3)\n_13\n_13\n# a collection of vectors with 3 dimensions\n_13\nvectors=[\\\n_13\\\n(\"vec0\", [0.1, 0.2, 0.3], {\"year\": 1973}),\\\n_13\\\n(\"vec1\", [0.7, 0.8, 0.9], {\"year\": 2012})\\\n_13\\\n]\n_13\n_13\n# insert our vectors\n_13\ndocs.upsert(vectors=vectors)\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "4d2eabc6-b660-434b-a7eb-7ebc6b10ebfd",
        "text": "Content of the previous chunk for context: h1: Python client h2: Quick start [\\#](\\#quick-start)\n\n(\"postgresql://postgres:postgres@localhost:54322/postgres\")\n_10\n_10\n# create a collection of vectors with 3 dimensions\n_10\ndocs = vx.get_or_create_collection(name=\"docs\", dimension=3)\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "f4382c43-c38d-46f5-af4c-d1df301d57e6",
    "metadata": {
      "token_count": 145,
      "source_url": "https://supabase.com/docs/guides/ai/vecs-python-client",
      "page_title": "Python client | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Python client",
        "h2": "Quick start [\\#](\\#quick-start)"
      },
      "text": "### Query the collection [\\#](\\#query-the-collection)\n\nYou can now query the collection to retrieve a relevant match:\n\n`\n_10\nimport vecs\n_10\n_10\ndocs = vecs.get_or_create_collection(name=\"docs\", dimension=3)\n_10\n_10\n# query the collection filtering metadata for \"year\" = 2012\n_10\ndocs.query(\n_10\n    data=[0.4,0.5,0.6],      # required\n_10\n    limit=1,                         # number of records to return\n_10\n    filters={\"year\": {\"$eq\": 2012}}, # metadata filters\n_10\n)\n`\n",
      "overlap_text": {
        "previous_chunk_id": "51f56b87-d918-48ec-9972-a466205be152",
        "text": "Content of the previous chunk for context: h1: Python client h2: Quick start [\\#](\\#quick-start)\n\n [0.7, 0.8, 0.9], {\"year\": 2012})\\\n_13\\\n]\n_13\n_13\n# insert our vectors\n_13\ndocs.upsert(vectors=vectors)\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "21037682-5240-47be-9376-8668636a152b",
    "metadata": {
      "token_count": 26,
      "source_url": "https://supabase.com/docs/guides/ai/vecs-python-client",
      "page_title": "Python client | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Python client",
        "h2": "Deep dive [\\#](\\#deep-dive)"
      },
      "text": "For a more in-depth guide on `vecs` collections, see [API](/docs/guides/ai/python/api).\n",
      "overlap_text": {
        "previous_chunk_id": "f4382c43-c38d-46f5-af4c-d1df301d57e6",
        "text": "Content of the previous chunk for context: h1: Python client h2: Quick start [\\#](\\#quick-start)\n\n,0.6],      # required\n_10\n    limit=1,                         # number of records to return\n_10\n    filters={\"year\": {\"$eq\": 2012}}, # metadata filters\n_10\n)\n`\n"
      }
    }
  },
  {
    "chunk_id": "0ef1aba1-7e40-4c13-89d8-5ce26839f383",
    "metadata": {
      "token_count": 56,
      "source_url": "https://supabase.com/docs/guides/ai/vecs-python-client",
      "page_title": "Python client | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Python client",
        "h2": "Resources [\\#](\\#resources)"
      },
      "text": "- Official Vecs Documentation: [https://supabase.github.io/vecs/api](https://supabase.github.io/vecs/api)\n- Source Code: [https://github.com/supabase/vecs](https://github.com/supabase/vecs)\n",
      "overlap_text": {
        "previous_chunk_id": "21037682-5240-47be-9376-8668636a152b",
        "text": "Content of the previous chunk for context: h1: Python client h2: Deep dive [\\#](\\#deep-dive)\n\nFor a more in-depth guide on `vecs` collections, see [API](/docs/guides/ai/python/api).\n"
      }
    }
  },
  {
    "chunk_id": "c6427e16-d7f7-453c-ac7e-d41b2421bde1",
    "metadata": {
      "token_count": 137,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/face-similarity",
      "page_title": "Face similarity search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Face similarity search",
        "h2": "Identify the celebrities who look most similar to you using Supabase Vecs."
      },
      "text": "* * *\n\nThis guide will walk you through a [\"Face Similarity Search\"](https://github.com/supabase/supabase/blob/master/examples/ai/face_similarity.ipynb) example using Colab and Supabase Vecs. You will be able to identify the celebrities who look most similar to you (or any other person). You will:\n\n1. Launch a Postgres database that uses pgvector to store embeddings\n2. Launch a notebook that connects to your database\n3. Load the \" `ashraq/tmdb-people-image`\" celebrity dataset\n4. Use the `face_recognition` model to create an embedding for every celebrity photo.\n"
    }
  },
  {
    "chunk_id": "7dd43de6-9ce7-4ace-88a8-283be6522e77",
    "metadata": {
      "token_count": 10,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/face-similarity",
      "page_title": "Face similarity search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Face similarity search",
        "h2": "Identify the celebrities who look most similar to you using Supabase Vecs."
      },
      "text": "5. Search for similar faces inside the dataset.\n",
      "overlap_text": {
        "previous_chunk_id": "c6427e16-d7f7-453c-ac7e-d41b2421bde1",
        "text": "Content of the previous chunk for context: h1: Face similarity search h2: Identify the celebrities who look most similar to you using Supabase Vecs.\n\n embeddings\n2. Launch a notebook that connects to your database\n3. Load the \" `ashraq/tmdb-people-image`\" celebrity dataset\n4. Use the `face_recognition` model to create an embedding for every celebrity photo.\n"
      }
    }
  },
  {
    "chunk_id": "4f49abcb-ecec-4842-ad51-d397a80876ac",
    "metadata": {
      "token_count": 102,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/face-similarity",
      "page_title": "Face similarity search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Face similarity search",
        "h2": "Project setup [\\#](\\#project-setup)"
      },
      "text": "Let's create a new Postgres database. This is as simple as starting a new Project in Supabase:\n\n1. [Create a new project](https://database.new/) in the Supabase dashboard.\n2. Enter your project details. Remember to store your password somewhere safe.\n\nYour database will be available in less than a minute.\n\n**Finding your credentials:**\n\nYou can find your project credentials inside the project [settings](https://supabase.com/dashboard/project/_/settings/), including:\n",
      "overlap_text": {
        "previous_chunk_id": "7dd43de6-9ce7-4ace-88a8-283be6522e77",
        "text": "Content of the previous chunk for context: h1: Face similarity search h2: Identify the celebrities who look most similar to you using Supabase Vecs.\n\n5. Search for similar faces inside the dataset.\n"
      }
    }
  },
  {
    "chunk_id": "fe70d08d-7e20-4fad-a098-12237385dee8",
    "metadata": {
      "token_count": 61,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/face-similarity",
      "page_title": "Face similarity search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Face similarity search",
        "h2": "Project setup [\\#](\\#project-setup)"
      },
      "text": "\n- [Database credentials](https://supabase.com/dashboard/project/_/settings/database): connection strings and connection pooler details.\n- [API credentials](https://supabase.com/dashboard/project/_/settings/database): your serverless API URL and `anon` / `service_role` keys.\n",
      "overlap_text": {
        "previous_chunk_id": "4f49abcb-ecec-4842-ad51-d397a80876ac",
        "text": "Content of the previous chunk for context: h1: Face similarity search h2: Project setup [\\#](\\#project-setup)\n\n store your password somewhere safe.\n\nYour database will be available in less than a minute.\n\n**Finding your credentials:**\n\nYou can find your project credentials inside the project [settings](https://supabase.com/dashboard/project/_/settings/), including:\n"
      }
    }
  },
  {
    "chunk_id": "c4aafc84-57ae-42ce-8fe6-47cd7fb4ccb4",
    "metadata": {
      "token_count": 117,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/face-similarity",
      "page_title": "Face similarity search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Face similarity search",
        "h2": "Launching a notebook [\\#](\\#launching-a-notebook)"
      },
      "text": "Launch our [`semantic_text_deduplication`](https://github.com/supabase/supabase/blob/master/examples/ai/face_similarity.ipynb) notebook in Colab:\n\n[![](https://supabase.com/docs/img/ai/colab-badge.svg)](https://colab.research.google.com/github/supabase/supabase/blob/master/examples/ai/face_similarity.ipynb)\n\nAt the top of the notebook, you'll see a button `Copy to Drive`. Click this button to copy the notebook to your Google Drive.\n",
      "overlap_text": {
        "previous_chunk_id": "fe70d08d-7e20-4fad-a098-12237385dee8",
        "text": "Content of the previous chunk for context: h1: Face similarity search h2: Project setup [\\#](\\#project-setup)\n\n.com/dashboard/project/_/settings/database): connection strings and connection pooler details.\n- [API credentials](https://supabase.com/dashboard/project/_/settings/database): your serverless API URL and `anon` / `service_role` keys.\n"
      }
    }
  },
  {
    "chunk_id": "5e249848-3f97-4417-b4a1-f8e68437673f",
    "metadata": {
      "token_count": 131,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/face-similarity",
      "page_title": "Face similarity search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Face similarity search",
        "h2": "Connecting to your database [\\#](\\#connecting-to-your-database)"
      },
      "text": "Inside the Notebook, find the cell which specifies the `DB_CONNECTION`. It will contain some code like this:\n\n`\n_10\nimport vecs\n_10\n_10\nDB_CONNECTION = \"postgresql://<user>:<password>@<host>:<port>/<db_name>\"\n_10\n_10\n# create vector store client\n_10\nvx = vecs.create_client(DB_CONNECTION)\n`\n\nReplace the `DB_CONNECTION` with your own connection string for your database. You can find the Postgres connection string in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database) of your Supabase project.\n",
      "overlap_text": {
        "previous_chunk_id": "c4aafc84-57ae-42ce-8fe6-47cd7fb4ccb4",
        "text": "Content of the previous chunk for context: h1: Face similarity search h2: Launching a notebook [\\#](\\#launching-a-notebook)\n\n/github/supabase/supabase/blob/master/examples/ai/face_similarity.ipynb)\n\nAt the top of the notebook, you'll see a button `Copy to Drive`. Click this button to copy the notebook to your Google Drive.\n"
      }
    }
  },
  {
    "chunk_id": "3307be50-8fc0-476a-8f22-111070475158",
    "metadata": {
      "token_count": 70,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/face-similarity",
      "page_title": "Face similarity search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Face similarity search",
        "h2": "Connecting to your database [\\#](\\#connecting-to-your-database)"
      },
      "text": "\nSQLAlchemy requires the connection string to start with `postgresql://` (instead of `postgres://`). Don't forget to rename this after copying the string from the dashboard.\n\nYou must use the \"connection pooling\" string (domain ending in `*.pooler.supabase.com`) with Google Colab since Colab does not support IPv6.\n",
      "overlap_text": {
        "previous_chunk_id": "5e249848-3f97-4417-b4a1-f8e68437673f",
        "text": "Content of the previous chunk for context: h1: Face similarity search h2: Connecting to your database [\\#](\\#connecting-to-your-database)\n\n`\n\nReplace the `DB_CONNECTION` with your own connection string for your database. You can find the Postgres connection string in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database) of your Supabase project.\n"
      }
    }
  },
  {
    "chunk_id": "4d28dc3d-40e5-47ad-9004-3041cefc52b2",
    "metadata": {
      "token_count": 121,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/face-similarity",
      "page_title": "Face similarity search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Face similarity search",
        "h2": "Stepping through the notebook [\\#](\\#stepping-through-the-notebook)"
      },
      "text": "Now all that's left is to step through the notebook. You can do this by clicking the \"execute\" button ( `ctrl+enter`) at the top left of each code cell. The notebook guides you through the process of creating a collection, adding data to it, and querying it.\n\nYou can view the inserted items in the [Table Editor](https://supabase.com/dashboard/project/_/editor/), by selecting the `vecs` schema from the schema dropdown.\n\n![Colab documents](https://supabase.com/docs/img/ai/google-colab/colab-documents.png)\n",
      "overlap_text": {
        "previous_chunk_id": "3307be50-8fc0-476a-8f22-111070475158",
        "text": "Content of the previous chunk for context: h1: Face similarity search h2: Connecting to your database [\\#](\\#connecting-to-your-database)\n\n`). Don't forget to rename this after copying the string from the dashboard.\n\nYou must use the \"connection pooling\" string (domain ending in `*.pooler.supabase.com`) with Google Colab since Colab does not support IPv6.\n"
      }
    }
  },
  {
    "chunk_id": "ce79d8de-3697-4c4e-b46b-0f32ea461c0a",
    "metadata": {
      "token_count": 30,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/face-similarity",
      "page_title": "Face similarity search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Face similarity search",
        "h2": "Next steps [\\#](\\#next-steps)"
      },
      "text": "You can now start building your own applications with Vecs. Check our [examples](/docs/guides/ai#examples) for ideas.\n",
      "overlap_text": {
        "previous_chunk_id": "4d28dc3d-40e5-47ad-9004-3041cefc52b2",
        "text": "Content of the previous chunk for context: h1: Face similarity search h2: Stepping through the notebook [\\#](\\#stepping-through-the-notebook)\n\nhttps://supabase.com/dashboard/project/_/editor/), by selecting the `vecs` schema from the schema dropdown.\n\n![Colab documents](https://supabase.com/docs/img/ai/google-colab/colab-documents.png)\n"
      }
    }
  },
  {
    "chunk_id": "10e9fe26-4bfb-4521-9c3d-4b78050ccac6",
    "metadata": {
      "token_count": 140,
      "source_url": "https://supabase.com/docs/guides/ai/examples/image-search-openai-clip",
      "page_title": "Image Search with OpenAI CLIP | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Image Search with OpenAI CLIP",
        "h2": "Implement image search with the OpenAI CLIP Model and Supabase Vector."
      },
      "text": "* * *\n\nThe [OpenAI CLIP Model](https://github.com/openai/CLIP) was trained on a variety of (image, text)-pairs. You can use the CLIP model for:\n\n- Text-to-Image / Image-To-Text / Image-to-Image / Text-to-Text Search\n- You can fine-tune it on your own image and text data with the regular SentenceTransformers training code.\n\n[SentenceTransformers](https://www.sbert.net/examples/applications/image-search/README.html) provides models that allow you to embed images and text into the same vector space. You can use this to find similar images as well as to implement image search.\n"
    }
  },
  {
    "chunk_id": "ac2aa6b3-34a2-41ee-91d5-869c7b537f5f",
    "metadata": {
      "token_count": 45,
      "source_url": "https://supabase.com/docs/guides/ai/examples/image-search-openai-clip",
      "page_title": "Image Search with OpenAI CLIP | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Image Search with OpenAI CLIP",
        "h2": "Implement image search with the OpenAI CLIP Model and Supabase Vector."
      },
      "text": "\nYou can find the full application code as a Python Poetry project on [GitHub](https://github.com/supabase/supabase/tree/master/examples/ai/image_search#image-search-with-supabase-vector).\n",
      "overlap_text": {
        "previous_chunk_id": "10e9fe26-4bfb-4521-9c3d-4b78050ccac6",
        "text": "Content of the previous chunk for context: h1: Image Search with OpenAI CLIP h2: Implement image search with the OpenAI CLIP Model and Supabase Vector.\n\nTransformers](https://www.sbert.net/examples/applications/image-search/README.html) provides models that allow you to embed images and text into the same vector space. You can use this to find similar images as well as to implement image search.\n"
      }
    }
  },
  {
    "chunk_id": "fe52b31d-d6fb-4c3a-88e8-08dcce077162",
    "metadata": {
      "token_count": 56,
      "source_url": "https://supabase.com/docs/guides/ai/examples/image-search-openai-clip",
      "page_title": "Image Search with OpenAI CLIP | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Image Search with OpenAI CLIP",
        "h2": "Create a new Python project with Poetry [\\#](\\#create-a-new-python-project-with-poetry)"
      },
      "text": "[Poetry](https://python-poetry.org/) provides packaging and dependency management for Python. If you haven't already, install poetry via pip:\n\n`\n_10\npip install poetry\n`\n\nThen initialize a new project:\n\n`\n_10\npoetry new image-search\n`\n",
      "overlap_text": {
        "previous_chunk_id": "ac2aa6b3-34a2-41ee-91d5-869c7b537f5f",
        "text": "Content of the previous chunk for context: h1: Image Search with OpenAI CLIP h2: Implement image search with the OpenAI CLIP Model and Supabase Vector.\n\n\nYou can find the full application code as a Python Poetry project on [GitHub](https://github.com/supabase/supabase/tree/master/examples/ai/image_search#image-search-with-supabase-vector).\n"
      }
    }
  },
  {
    "chunk_id": "b02a7571-d13d-43b3-a14e-1d498a046331",
    "metadata": {
      "token_count": 101,
      "source_url": "https://supabase.com/docs/guides/ai/examples/image-search-openai-clip",
      "page_title": "Image Search with OpenAI CLIP | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Image Search with OpenAI CLIP",
        "h2": "Setup Supabase project [\\#](\\#setup-supabase-project)"
      },
      "text": "If you haven't already, [install the Supabase CLI](/docs/guides/cli), then initialize Supabase in the root of your newly created poetry project:\n\n`\n_10\nsupabase init\n`\n\nNext, start your local Supabase stack:\n\n`\n_10\nsupabase start\n`\n\nThis will start up the Supabase stack locally and print out a bunch of environment details, including your local `DB URL`. Make a note of that for later user.\n",
      "overlap_text": {
        "previous_chunk_id": "fe52b31d-d6fb-4c3a-88e8-08dcce077162",
        "text": "Content of the previous chunk for context: h1: Image Search with OpenAI CLIP h2: Create a new Python project with Poetry [\\#](\\#create-a-new-python-project-with-poetry)\n\npython-poetry.org/) provides packaging and dependency management for Python. If you haven't already, install poetry via pip:\n\n`\n_10\npip install poetry\n`\n\nThen initialize a new project:\n\n`\n_10\npoetry new image-search\n`\n"
      }
    }
  },
  {
    "chunk_id": "2990462d-0334-4457-9a4f-bba3de8f3e38",
    "metadata": {
      "token_count": 109,
      "source_url": "https://supabase.com/docs/guides/ai/examples/image-search-openai-clip",
      "page_title": "Image Search with OpenAI CLIP | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Image Search with OpenAI CLIP",
        "h2": "Install the dependencies [\\#](\\#install-the-dependencies)"
      },
      "text": "We will need to add the following dependencies to our project:\n\n- [`vecs`](https://github.com/supabase/vecs#vecs): Supabase Vector Python Client.\n- [`sentence-transformers`](https://huggingface.co/sentence-transformers/clip-ViT-B-32): a framework for sentence, text and image embeddings (used with OpenAI CLIP model)\n- [`matplotlib`](https://matplotlib.org/): for displaying our image result\n\n`\n_10\npoetry add vecs sentence-transformers matplotlib\n`\n",
      "overlap_text": {
        "previous_chunk_id": "b02a7571-d13d-43b3-a14e-1d498a046331",
        "text": "Content of the previous chunk for context: h1: Image Search with OpenAI CLIP h2: Setup Supabase project [\\#](\\#setup-supabase-project)\n\n Supabase stack:\n\n`\n_10\nsupabase start\n`\n\nThis will start up the Supabase stack locally and print out a bunch of environment details, including your local `DB URL`. Make a note of that for later user.\n"
      }
    }
  },
  {
    "chunk_id": "875fbc2c-421c-4823-823a-9ffbf22c27f4",
    "metadata": {
      "token_count": 97,
      "source_url": "https://supabase.com/docs/guides/ai/examples/image-search-openai-clip",
      "page_title": "Image Search with OpenAI CLIP | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Image Search with OpenAI CLIP",
        "h2": "Import the necessary dependencies [\\#](\\#import-the-necessary-dependencies)"
      },
      "text": "At the top of your main python script, import the dependencies and store your `DB URL` from above in a variable:\n\n`\n_10\nfrom PIL import Image\n_10\nfrom sentence_transformers import SentenceTransformer\n_10\nimport vecs\n_10\nfrom matplotlib import pyplot as plt\n_10\nfrom matplotlib import image as mpimg\n_10\n_10\nDB_CONNECTION = \"postgresql://postgres:postgres@localhost:54322/postgres\"\n`\n",
      "overlap_text": {
        "previous_chunk_id": "2990462d-0334-4457-9a4f-bba3de8f3e38",
        "text": "Content of the previous chunk for context: h1: Image Search with OpenAI CLIP h2: Install the dependencies [\\#](\\#install-the-dependencies)\n\n): a framework for sentence, text and image embeddings (used with OpenAI CLIP model)\n- [`matplotlib`](https://matplotlib.org/): for displaying our image result\n\n`\n_10\npoetry add vecs sentence-transformers matplotlib\n`\n"
      }
    }
  },
  {
    "chunk_id": "4e2d158a-9ace-449f-aba9-3be4eb827a49",
    "metadata": {
      "token_count": 107,
      "source_url": "https://supabase.com/docs/guides/ai/examples/image-search-openai-clip",
      "page_title": "Image Search with OpenAI CLIP | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Image Search with OpenAI CLIP",
        "h2": "Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)"
      },
      "text": "In the root of your project, create a new folder called `images` and add some images. You can use the images from the example project on [GitHub](https://github.com/supabase/supabase/tree/master/examples/ai/image_search/images) or you can find license free images on [unsplash](https://unsplash.com).\n\nNext, create a `seed` method, which will create a new Supabase Vector Collection, generate embeddings for your images, and upsert the embeddings into your database:\n",
      "overlap_text": {
        "previous_chunk_id": "875fbc2c-421c-4823-823a-9ffbf22c27f4",
        "text": "Content of the previous chunk for context: h1: Image Search with OpenAI CLIP h2: Import the necessary dependencies [\\#](\\#import-the-necessary-dependencies)\n\n\nimport vecs\n_10\nfrom matplotlib import pyplot as plt\n_10\nfrom matplotlib import image as mpimg\n_10\n_10\nDB_CONNECTION = \"postgresql://postgres:postgres@localhost:54322/postgres\"\n`\n"
      }
    }
  },
  {
    "chunk_id": "73d6b03f-3e25-43f1-a570-f4a7d1661b01",
    "metadata": {
      "token_count": 110,
      "source_url": "https://supabase.com/docs/guides/ai/examples/image-search-openai-clip",
      "page_title": "Image Search with OpenAI CLIP | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Image Search with OpenAI CLIP",
        "h2": "Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)"
      },
      "text": "\n`\n_43\ndef seed():\n_43\n    # create vector store client\n_43\n    vx = vecs.create_client(DB_CONNECTION)\n_43\n_43\n    # create a collection of vectors with 3 dimensions\n_43\n    images = vx.get_or_create_collection(name=\"image_vectors\", dimension=512)\n_43\n_43\n    # Load CLIP model\n_43\n    model = SentenceTransformer('clip-ViT-B-32')\n_43\n_43\n    # Encode an image:\n",
      "overlap_text": {
        "previous_chunk_id": "4e2d158a-9ace-449f-aba9-3be4eb827a49",
        "text": "Content of the previous chunk for context: h1: Image Search with OpenAI CLIP h2: Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)\n\n find license free images on [unsplash](https://unsplash.com).\n\nNext, create a `seed` method, which will create a new Supabase Vector Collection, generate embeddings for your images, and upsert the embeddings into your database:\n"
      }
    }
  },
  {
    "chunk_id": "deb9129d-cd0c-4a07-9c8d-4e0c8bf6cc2c",
    "metadata": {
      "token_count": 323,
      "source_url": "https://supabase.com/docs/guides/ai/examples/image-search-openai-clip",
      "page_title": "Image Search with OpenAI CLIP | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Image Search with OpenAI CLIP",
        "h2": "Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)"
      },
      "text": "_43\n    img_emb1 = model.encode(Image.open('./images/one.jpg'))\n_43\n    img_emb2 = model.encode(Image.open('./images/two.jpg'))\n_43\n    img_emb3 = model.encode(Image.open('./images/three.jpg'))\n_43\n    img_emb4 = model.encode(Image.open('./images/four.jpg'))\n_43\n_43\n    # add records to the *images* collection\n_43\n    images.upsert(\n_43\n        records=[\\\n_43\\\n            (\\\n_43\\\n                \"one.jpg\",        # the vector's identifier\\\n_43\\\n                img_emb1,          # the vector. list or np.array\\\n_43\\\n                {\"type\": \"jpg\"}   # associated  metadata\\\n_43\\\n            ), (\\\n_43\\\n                \"two.jpg\",\\\n_43\\\n                img_emb2,\\\n_43\\\n                {\"type\": \"jpg\"}\\\n_43\\\n            ), (\\\n_43\\\n                \"three.jpg\",\\\n_43\\\n                img_emb3,\\\n_43\\\n                {\"type\": \"jpg\"}\\\n_43\\\n            ), (\\\n_43\\\n                \"four.jpg\",\\\n_43\\\n                img_emb4,\\\n_43\\\n                {\"type\": \"jpg\"}\\\n_43\\\n            )\\\n_43\\\n        ]\n_43\n    )\n_43\n    print(\"Inserted images\")\n_43\n_43\n    # index the collection for fast search performance\n_43\n    images.create_index()\n_43\n    print(\"Created index\")\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "73d6b03f-3e25-43f1-a570-f4a7d1661b01",
        "text": "Content of the previous chunk for context: h1: Image Search with OpenAI CLIP h2: Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)\n\n(name=\"image_vectors\", dimension=512)\n_43\n_43\n    # Load CLIP model\n_43\n    model = SentenceTransformer('clip-ViT-B-32')\n_43\n_43\n    # Encode an image:\n"
      }
    }
  },
  {
    "chunk_id": "71d64150-34cb-404f-b4f3-bb4442a2eb30",
    "metadata": {
      "token_count": 130,
      "source_url": "https://supabase.com/docs/guides/ai/examples/image-search-openai-clip",
      "page_title": "Image Search with OpenAI CLIP | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Image Search with OpenAI CLIP",
        "h2": "Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)"
      },
      "text": "Add this method as a script in your `pyproject.toml` file:\n\n`\n_10\n[tool.poetry.scripts]\n_10\nseed = \"image_search.main:seed\"\n_10\nsearch = \"image_search.main:search\"\n`\n\nAfter activating the virtual environtment with `poetry shell` you can now run your seed script via `poetry run seed`. You can inspect the generated embeddings in your local database by visiting the local Supabase dashboard at [localhost:54323](http://localhost:54323/project/default/editor), selecting the `vecs` schema, and the `image_vectors` database.\n",
      "overlap_text": {
        "previous_chunk_id": "deb9129d-cd0c-4a07-9c8d-4e0c8bf6cc2c",
        "text": "Content of the previous chunk for context: h1: Image Search with OpenAI CLIP h2: Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)\n\n        ]\n_43\n    )\n_43\n    print(\"Inserted images\")\n_43\n_43\n    # index the collection for fast search performance\n_43\n    images.create_index()\n_43\n    print(\"Created index\")\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "c365f249-3d97-4a6e-9efa-6c253c386591",
    "metadata": {
      "token_count": 298,
      "source_url": "https://supabase.com/docs/guides/ai/examples/image-search-openai-clip",
      "page_title": "Image Search with OpenAI CLIP | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Image Search with OpenAI CLIP",
        "h2": "Perform an image search from a text query [\\#](\\#perform-an-image-search-from-a-text-query)"
      },
      "text": "With Supabase Vector we can easily query our embeddings. We can use either an image as search input or alternative we can generate an embedding from a string input and use that as the query input:\n\n`\n_23\ndef search():\n_23\n    # create vector store client\n_23\n    vx = vecs.create_client(DB_CONNECTION)\n_23\n    images = vx.get_or_create_collection(name=\"image_vectors\", dimension=512)\n_23\n_23\n    # Load CLIP model\n_23\n    model = SentenceTransformer('clip-ViT-B-32')\n_23\n    # Encode text query\n_23\n    query_string = \"a bike in front of a red brick wall\"\n_23\n    text_emb = model.encode(query_string)\n_23\n_23\n    # query the collection filtering metadata for \"type\" = \"jpg\"\n_23\n    results = images.query(\n_23\n        data=text_emb,                      # required\n_23\n        limit=1,                            # number of records to return\n_23\n        filters={\"type\": {\"$eq\": \"jpg\"}},   # metadata filters\n_23\n    )\n_23\n    result = results[0]\n_23\n    print(result)\n_23\n    plt.title(result)\n_23\n    image = mpimg.imread('./images/' + result)\n_23\n    plt.imshow(image)\n_23\n    plt.show()\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "71d64150-34cb-404f-b4f3-bb4442a2eb30",
        "text": "Content of the previous chunk for context: h1: Image Search with OpenAI CLIP h2: Create embeddings for your images [\\#](\\#create-embeddings-for-your-images)\n\n You can inspect the generated embeddings in your local database by visiting the local Supabase dashboard at [localhost:54323](http://localhost:54323/project/default/editor), selecting the `vecs` schema, and the `image_vectors` database.\n"
      }
    }
  },
  {
    "chunk_id": "edc7416b-69af-4056-a0fa-01a24abd9af9",
    "metadata": {
      "token_count": 72,
      "source_url": "https://supabase.com/docs/guides/ai/examples/image-search-openai-clip",
      "page_title": "Image Search with OpenAI CLIP | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Image Search with OpenAI CLIP",
        "h2": "Perform an image search from a text query [\\#](\\#perform-an-image-search-from-a-text-query)"
      },
      "text": "By limiting the query to one result, we can show the most relevant image to the user. Finally we use `matplotlib` to show the image result to the user.\n\nThat's it, go ahead and test it out by running `poetry run search` and you will be presented with an image of a \"bike in front of a red brick wall\".\n",
      "overlap_text": {
        "previous_chunk_id": "c365f249-3d97-4a6e-9efa-6c253c386591",
        "text": "Content of the previous chunk for context: h1: Image Search with OpenAI CLIP h2: Perform an image search from a text query [\\#](\\#perform-an-image-search-from-a-text-query)\n\n results[0]\n_23\n    print(result)\n_23\n    plt.title(result)\n_23\n    image = mpimg.imread('./images/' + result)\n_23\n    plt.imshow(image)\n_23\n    plt.show()\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "3b0ef201-2709-4240-81c8-a5eac5643c5e",
    "metadata": {
      "token_count": 34,
      "source_url": "https://supabase.com/docs/guides/ai/examples/image-search-openai-clip",
      "page_title": "Image Search with OpenAI CLIP | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Image Search with OpenAI CLIP",
        "h2": "Conclusion [\\#](\\#conclusion)"
      },
      "text": "With just a couple of lines of Python you are able to implement image search as well as reverse image search using OpenAI's CLIP model and Supabase Vector.\n",
      "overlap_text": {
        "previous_chunk_id": "edc7416b-69af-4056-a0fa-01a24abd9af9",
        "text": "Content of the previous chunk for context: h1: Image Search with OpenAI CLIP h2: Perform an image search from a text query [\\#](\\#perform-an-image-search-from-a-text-query)\n\n `matplotlib` to show the image result to the user.\n\nThat's it, go ahead and test it out by running `poetry run search` and you will be presented with an image of a \"bike in front of a red brick wall\".\n"
      }
    }
  },
  {
    "chunk_id": "60d9b0bf-0ba4-4c82-9a96-b31274a12f8e",
    "metadata": {
      "token_count": 100,
      "source_url": "https://supabase.com/docs/guides/ai/python/collections",
      "page_title": "Collections | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Collections"
      },
      "text": "* * *\n\n# Collections\n\nA collection is an group of vector records.\nRecords can be [added to or updated in](https://supabase.github.io/vecs/../api.md#upserting-vectors) a collection.\nCollections can be [queried](https://supabase.github.io/vecs/../api.md#query) at any time, but should be [indexed](https://supabase.github.io/vecs/../api.md#create-an-index) for scalable query performance.\n"
    }
  },
  {
    "chunk_id": "6c190ae1-25bb-499a-906f-2ad6bdc62a30",
    "metadata": {
      "token_count": 133,
      "source_url": "https://supabase.com/docs/guides/ai/python/collections",
      "page_title": "Collections | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Collections"
      },
      "text": "\nEach vector record has the form:\n\n`\n_10\nRecord (\n_10\n    id: String\n_10\n    vec: Numeric[]\n_10\n    metadata: JSON\n_10\n)\n`\n\nFor example:\n\n`\n_10\n(\"vec1\", [0.1, 0.2, 0.3], {\"year\": 1990})\n`\n\nUnderneath every `vecs` collection is a Postgres table\n\n`\n_10\ncreate table <collection_name> (\n_10\n    id string primary key,\n_10\n    vec vector(<dimension>),\n_10\n    metadata jsonb\n_10\n)\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "60d9b0bf-0ba4-4c82-9a96-b31274a12f8e",
        "text": "Content of the previous chunk for context: h1: Collections\n\n [queried](https://supabase.github.io/vecs/../api.md#query) at any time, but should be [indexed](https://supabase.github.io/vecs/../api.md#create-an-index) for scalable query performance.\n"
      }
    }
  },
  {
    "chunk_id": "64fe3fa3-3cf8-4962-bcc8-d1f578966158",
    "metadata": {
      "token_count": 37,
      "source_url": "https://supabase.com/docs/guides/ai/python/collections",
      "page_title": "Collections | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Collections"
      },
      "text": "where rows in the table map 1:1 with vecs vector records.\n\nIt is safe to select collection tables from outside the vecs client but issuing DDL is not recommended.\n",
      "overlap_text": {
        "previous_chunk_id": "6c190ae1-25bb-499a-906f-2ad6bdc62a30",
        "text": "Content of the previous chunk for context: h1: Collections\n\n collection is a Postgres table\n\n`\n_10\ncreate table <collection_name> (\n_10\n    id string primary key,\n_10\n    vec vector(<dimension>),\n_10\n    metadata jsonb\n_10\n)\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "6b554ec0-698d-4b7c-b9d9-fa6665b74bb5",
    "metadata": {
      "token_count": 47,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes",
      "page_title": "Vector indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector indexes"
      },
      "text": "* * *\n\nOnce your vector table starts to grow, you will likely want to add an index to speed up queries. Without indexes, you'll be performing a sequential scan which can be a resource-intensive operation when you have many records.\n"
    }
  },
  {
    "chunk_id": "9bb3f500-d982-49cd-ade0-f8b0f0ff9d4c",
    "metadata": {
      "token_count": 150,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes",
      "page_title": "Vector indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector indexes",
        "h2": "Choosing an index [\\#](\\#choosing-an-index)"
      },
      "text": "Today `pgvector` supports two types of indexes:\n\n- [HNSW](/docs/guides/ai/vector-indexes/hnsw-indexes)\n- [IVFFlat](/docs/guides/ai/vector-indexes/ivf-indexes)\n\nIn general we recommend using [HNSW](/docs/guides/ai/vector-indexes/hnsw-indexes) because of its [performance](https://supabase.com/blog/increase-performance-pgvector-hnsw#hnsw-performance-1536-dimensions) and [robustness against changing data](/docs/guides/ai/vector-indexes/hnsw-indexes#when-should-you-create-hnsw-indexes).\n",
      "overlap_text": {
        "previous_chunk_id": "6b554ec0-698d-4b7c-b9d9-fa6665b74bb5",
        "text": "Content of the previous chunk for context: h1: Vector indexes\n\n* * *\n\nOnce your vector table starts to grow, you will likely want to add an index to speed up queries. Without indexes, you'll be performing a sequential scan which can be a resource-intensive operation when you have many records.\n"
      }
    }
  },
  {
    "chunk_id": "48cd6ced-ffaf-47b8-8d2a-b67ee85d6900",
    "metadata": {
      "token_count": 105,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes",
      "page_title": "Vector indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector indexes",
        "h2": "Distance operators [\\#](\\#distance-operators)"
      },
      "text": "Indexes can be used to improve performance of nearest neighbor search using various distance measures. `pgvector` includes 3 distance operators:\n\n| Operator | Description | [**Operator class**](https://www.postgresql.org/docs/current/sql-createopclass.html) |\n| --- | --- | --- |\n| `<->` | Euclidean distance | `vector_l2_ops` |\n| `<#>` | negative inner product | `vector_ip_ops` |\n| `<=>` | cosine distance | `vector_cosine_ops` |\n\n",
      "overlap_text": {
        "previous_chunk_id": "9bb3f500-d982-49cd-ade0-f8b0f0ff9d4c",
        "text": "Content of the previous chunk for context: h1: Vector indexes h2: Choosing an index [\\#](\\#choosing-an-index)\n\n-hnsw#hnsw-performance-1536-dimensions) and [robustness against changing data](/docs/guides/ai/vector-indexes/hnsw-indexes#when-should-you-create-hnsw-indexes).\n"
      }
    }
  },
  {
    "chunk_id": "e42476e0-88e5-431d-9e97-1f2056babd7b",
    "metadata": {
      "token_count": 14,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes",
      "page_title": "Vector indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector indexes",
        "h2": "Distance operators [\\#](\\#distance-operators)"
      },
      "text": "Currently vectors with up to 2,000 dimensions can be indexed.\n",
      "overlap_text": {
        "previous_chunk_id": "48cd6ced-ffaf-47b8-8d2a-b67ee85d6900",
        "text": "Content of the previous chunk for context: h1: Vector indexes h2: Distance operators [\\#](\\#distance-operators)\n\n --- | --- |\n| `<->` | Euclidean distance | `vector_l2_ops` |\n| `<#>` | negative inner product | `vector_ip_ops` |\n| `<=>` | cosine distance | `vector_cosine_ops` |\n\n"
      }
    }
  },
  {
    "chunk_id": "0549f9e9-8511-4125-8d40-dc2f352234f9",
    "metadata": {
      "token_count": 26,
      "source_url": "https://supabase.com/docs/guides/ai/vector-indexes",
      "page_title": "Vector indexes | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector indexes",
        "h2": "Resources [\\#](\\#resources)"
      },
      "text": "Read more about indexing on `pgvector`'s [GitHub page](https://github.com/pgvector/pgvector#indexing).\n",
      "overlap_text": {
        "previous_chunk_id": "e42476e0-88e5-431d-9e97-1f2056babd7b",
        "text": "Content of the previous chunk for context: h1: Vector indexes h2: Distance operators [\\#](\\#distance-operators)\n\nCurrently vectors with up to 2,000 dimensions can be indexed.\n"
      }
    }
  },
  {
    "chunk_id": "a87295e6-69fb-4144-b1dc-e2d02d0b659e",
    "metadata": {
      "token_count": 129,
      "source_url": "https://supabase.com/docs/guides/ai/vector-columns",
      "page_title": "Vector columns | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector columns"
      },
      "text": "* * *\n\nSupabase offers a number of different ways to store and query vectors within Postgres. The SQL included in this guide is applicable for clients in all programming languages. If you are a Python user see your [Python client options](/docs/guides/ai/python-clients) after reading the `Learn` section.\n\nVectors in Supabase are enabled via [pgvector](https://github.com/pgvector/pgvector/), a PostgreSQL extension for storing and querying vectors in Postgres. It can be used to store [embeddings](/docs/guides/ai/concepts#what-are-embeddings).\n"
    }
  },
  {
    "chunk_id": "cc2350c9-631f-4719-beb3-d5c861d61745",
    "metadata": {
      "token_count": 128,
      "source_url": "https://supabase.com/docs/guides/ai/vector-columns",
      "page_title": "Vector columns | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector columns",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "### Enable the extension [\\#](\\#enable-the-extension)\n\nDashboardSQL\n\n1. Go to the [Database](https://supabase.com/dashboard/project/_/database/tables) page in the Dashboard.\n2. Click on **Extensions** in the sidebar.\n3. Search for \"vector\" and enable the extension.\n\n### Create a table to store vectors [\\#](\\#create-a-table-to-store-vectors)\n\nAfter enabling the `vector` extension, you will get access to a new data type called `vector`. The size of the vector (indicated in parenthesis) represents the number of dimensions stored in that vector.\n",
      "overlap_text": {
        "previous_chunk_id": "a87295e6-69fb-4144-b1dc-e2d02d0b659e",
        "text": "Content of the previous chunk for context: h1: Vector columns\n\n](https://github.com/pgvector/pgvector/), a PostgreSQL extension for storing and querying vectors in Postgres. It can be used to store [embeddings](/docs/guides/ai/concepts#what-are-embeddings).\n"
      }
    }
  },
  {
    "chunk_id": "7146027c-417b-4e4c-a886-f8aea8488700",
    "metadata": {
      "token_count": 184,
      "source_url": "https://supabase.com/docs/guides/ai/vector-columns",
      "page_title": "Vector columns | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector columns",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "\n`\n_10\ncreate table documents (\n_10\nid serial primary key,\n_10\ntitle text not null,\n_10\nbody text not null,\n_10\nembedding vector(384)\n_10\n);\n`\n\nIn the above SQL snippet, we create a `documents` table with a column called `embedding` (note this is just a regular Postgres column - you can name it whatever you like). We give the `embedding` column a `vector` data type with 384 dimensions. Change this to the number of dimensions produced by your embedding model. For example, if you are [generating embeddings](/docs/guides/ai/quickstarts/generate-text-embeddings) using the open source [`gte-small`](https://huggingface.co/Supabase/gte-small) model, you would set this number to 384 since that model produces 384 dimensions.\n",
      "overlap_text": {
        "previous_chunk_id": "cc2350c9-631f-4719-beb3-d5c861d61745",
        "text": "Content of the previous chunk for context: h1: Vector columns h2: Usage [\\#](\\#usage)\n\ncreate-a-table-to-store-vectors)\n\nAfter enabling the `vector` extension, you will get access to a new data type called `vector`. The size of the vector (indicated in parenthesis) represents the number of dimensions stored in that vector.\n"
      }
    }
  },
  {
    "chunk_id": "1941b086-70b5-4607-834c-86c1e3e71f94",
    "metadata": {
      "token_count": 275,
      "source_url": "https://supabase.com/docs/guides/ai/vector-columns",
      "page_title": "Vector columns | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector columns",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "\nIn general, embeddings with fewer dimensions perform best. See our [analysis on fewer dimensions in pgvector](https://supabase.com/blog/fewer-dimensions-are-better-pgvector).\n\n### Storing a vector / embedding [\\#](\\#storing-a-vector--embedding)\n\nIn this example we'll generate a vector using Transformers.js, then store it in the database using the Supabase JavaScript client.\n\n`\n_21\nimport { pipeline } from '@xenova/transformers'\n_21\nconst generateEmbedding = await pipeline('feature-extraction', 'Supabase/gte-small')\n_21\n_21\nconst title = 'First post!'\n_21\nconst body = 'Hello world!'\n_21\n_21\n// Generate a vector using Transformers.js\n_21\nconst output = await generateEmbedding(body, {\n_21\npooling: 'mean',\n_21\nnormalize: true,\n_21\n})\n_21\n_21\n// Extract the embedding output\n_21\nconst embedding = Array.from(output.data)\n_21\n_21\n// Store the vector in Postgres\n_21\nconst { data, error } = await supabase.from('documents').insert({\n_21\ntitle,\n_21\nbody,\n_21\nembedding,\n_21\n})\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "7146027c-417b-4e4c-a886-f8aea8488700",
        "text": "Content of the previous chunk for context: h1: Vector columns h2: Usage [\\#](\\#usage)\n\n/quickstarts/generate-text-embeddings) using the open source [`gte-small`](https://huggingface.co/Supabase/gte-small) model, you would set this number to 384 since that model produces 384 dimensions.\n"
      }
    }
  },
  {
    "chunk_id": "04736230-4b30-4335-b51f-26f76047a10e",
    "metadata": {
      "token_count": 111,
      "source_url": "https://supabase.com/docs/guides/ai/vector-columns",
      "page_title": "Vector columns | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector columns",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "This example uses the JavaScript Supabase client, but you can modify it to work with any [supported language library](/docs#client-libraries).\n\n### Querying a vector / embedding [\\#](\\#querying-a-vector--embedding)\n\nSimilarity search is the most common use case for vectors. `pgvector` support 3 new operators for computing distance:\n\n| Operator | Description |\n| --- | --- |\n| `<->` | Euclidean distance |\n| `<#>` | negative inner product |\n| `<=>` | cosine distance |\n\n",
      "overlap_text": {
        "previous_chunk_id": "1941b086-70b5-4607-834c-86c1e3e71f94",
        "text": "Content of the previous chunk for context: h1: Vector columns h2: Usage [\\#](\\#usage)\n\n21\n// Store the vector in Postgres\n_21\nconst { data, error } = await supabase.from('documents').insert({\n_21\ntitle,\n_21\nbody,\n_21\nembedding,\n_21\n})\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "bd335144-5253-4f70-b6a1-db390bf51cdd",
    "metadata": {
      "token_count": 140,
      "source_url": "https://supabase.com/docs/guides/ai/vector-columns",
      "page_title": "Vector columns | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector columns",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "Choosing the right operator depends on your needs. Dot product tends to be the fastest if your vectors are normalized. For more information on how embeddings work and how they relate to each other, see [What are Embeddings?](/docs/guides/ai/concepts#what-are-embeddings).\n\nSupabase client libraries like `supabase-js` connect to your Postgres instance via [PostgREST](/docs/guides/getting-started/architecture#postgrest-api). PostgREST does not currently support `pgvector` similarity operators, so we'll need to wrap our query in a Postgres function and call it via the `rpc()` method:\n",
      "overlap_text": {
        "previous_chunk_id": "04736230-4b30-4335-b51f-26f76047a10e",
        "text": "Content of the previous chunk for context: h1: Vector columns h2: Usage [\\#](\\#usage)\n\n. `pgvector` support 3 new operators for computing distance:\n\n| Operator | Description |\n| --- | --- |\n| `<->` | Euclidean distance |\n| `<#>` | negative inner product |\n| `<=>` | cosine distance |\n\n"
      }
    }
  },
  {
    "chunk_id": "1a08d44d-1531-4a14-b67f-4cb72ea07485",
    "metadata": {
      "token_count": 181,
      "source_url": "https://supabase.com/docs/guides/ai/vector-columns",
      "page_title": "Vector columns | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector columns",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "\n`\n_23\ncreate or replace function match_documents (\n_23\nquery_embedding vector(384),\n_23\nmatch_threshold float,\n_23\nmatch_count int\n_23\n)\n_23\nreturns table (\n_23\nid bigint,\n_23\ntitle text,\n_23\nbody text,\n_23\nsimilarity float\n_23\n)\n_23\nlanguage sql stable\n_23\nas $$\n_23\nselect\n_23\n    documents.id,\n_23\n    documents.title,\n_23\n    documents.body,\n_23\n    1 - (documents.embedding <=> query_embedding) as similarity\n_23\nfrom documents\n_23\nwhere 1 - (documents.embedding <=> query_embedding) > match_threshold\n_23\norder by (documents.embedding <=> query_embedding) asc\n_23\nlimit match_count;\n_23\n$$;\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "bd335144-5253-4f70-b6a1-db390bf51cdd",
        "text": "Content of the previous chunk for context: h1: Vector columns h2: Usage [\\#](\\#usage)\n\nes/getting-started/architecture#postgrest-api). PostgREST does not currently support `pgvector` similarity operators, so we'll need to wrap our query in a Postgres function and call it via the `rpc()` method:\n"
      }
    }
  },
  {
    "chunk_id": "fa191979-9598-4140-902e-f51c65bd54c0",
    "metadata": {
      "token_count": 142,
      "source_url": "https://supabase.com/docs/guides/ai/vector-columns",
      "page_title": "Vector columns | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector columns",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "This function takes a `query_embedding` argument and compares it to all other embeddings in the `documents` table. Each comparison returns a similarity score. If the similarity is greater than the `match_threshold` argument, it is returned. The number of rows returned is limited by the `match_count` argument.\n\nFeel free to modify this method to fit the needs of your application. The `match_threshold` ensures that only documents that have a minimum similarity to the `query_embedding` are returned. Without this, you may end up returning documents that subjectively don't match. This value will vary for each application - you will need to perform your own testing to determine the threshold that makes sense for your app.\n",
      "overlap_text": {
        "previous_chunk_id": "1a08d44d-1531-4a14-b67f-4cb72ea07485",
        "text": "Content of the previous chunk for context: h1: Vector columns h2: Usage [\\#](\\#usage)\n\n23\nfrom documents\n_23\nwhere 1 - (documents.embedding <=> query_embedding) > match_threshold\n_23\norder by (documents.embedding <=> query_embedding) asc\n_23\nlimit match_count;\n_23\n$$;\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "7d71a171-051c-4518-ad1f-8daf16c6d817",
    "metadata": {
      "token_count": 148,
      "source_url": "https://supabase.com/docs/guides/ai/vector-columns",
      "page_title": "Vector columns | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector columns",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "\nIf you index your vector column, ensure that the `order by` sorts by the distance function directly (rather than sorting by the calculated `similarity` column, which may lead to the index being ignored and poor performance).\n\nTo execute the function from your client library, call `rpc()` with the name of your Postgres function:\n\n`\n_10\nconst { data: documents } = await supabaseClient.rpc('match_documents', {\n_10\nquery_embedding: embedding, // Pass the embedding you want to compare\n_10\nmatch_threshold: 0.78, // Choose an appropriate threshold for your data\n_10\nmatch_count: 10, // Choose the number of matches\n_10\n})\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "fa191979-9598-4140-902e-f51c65bd54c0",
        "text": "Content of the previous chunk for context: h1: Vector columns h2: Usage [\\#](\\#usage)\n\n `query_embedding` are returned. Without this, you may end up returning documents that subjectively don't match. This value will vary for each application - you will need to perform your own testing to determine the threshold that makes sense for your app.\n"
      }
    }
  },
  {
    "chunk_id": "0a3302fe-e058-4202-8496-29e351796322",
    "metadata": {
      "token_count": 134,
      "source_url": "https://supabase.com/docs/guides/ai/vector-columns",
      "page_title": "Vector columns | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector columns",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "In this example `embedding` would be another embedding you wish to compare against your table of pre-generated embedding documents. For example if you were building a search engine, every time the user submits their query you would first generate an embedding on the search query itself, then pass it into the above `rpc()` function to match.\n\nBe sure to use embeddings produced from the same embedding model when calculating distance. Comparing embeddings from two different models will produce no meaningful result.\n\nVectors and embeddings can be used for much more than search. Learn more about embeddings at [What are Embeddings?](/docs/guides/ai/concepts#what-are-embeddings).\n",
      "overlap_text": {
        "previous_chunk_id": "7d71a171-051c-4518-ad1f-8daf16c6d817",
        "text": "Content of the previous chunk for context: h1: Vector columns h2: Usage [\\#](\\#usage)\n\n // Pass the embedding you want to compare\n_10\nmatch_threshold: 0.78, // Choose an appropriate threshold for your data\n_10\nmatch_count: 10, // Choose the number of matches\n_10\n})\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "a401e977-db43-48c8-be18-c8c792f34a06",
    "metadata": {
      "token_count": 60,
      "source_url": "https://supabase.com/docs/guides/ai/vector-columns",
      "page_title": "Vector columns | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Vector columns",
        "h2": "Usage [\\#](\\#usage)"
      },
      "text": "\n### Indexes [\\#](\\#indexes)\n\nOnce your vector table starts to grow, you will likely want to add an index to speed up queries. See [Vector indexes](/docs/guides/ai/vector-indexes) to learn how vector indexes work and how to create them.\n",
      "overlap_text": {
        "previous_chunk_id": "0a3302fe-e058-4202-8496-29e351796322",
        "text": "Content of the previous chunk for context: h1: Vector columns h2: Usage [\\#](\\#usage)\n\n two different models will produce no meaningful result.\n\nVectors and embeddings can be used for much more than search. Learn more about embeddings at [What are Embeddings?](/docs/guides/ai/concepts#what-are-embeddings).\n"
      }
    }
  },
  {
    "chunk_id": "20c32f6b-2d06-4834-9649-eed83cc38e83",
    "metadata": {
      "token_count": 143,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/text-deduplication",
      "page_title": "Semantic Text Deduplication | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Text Deduplication",
        "h2": "Finding duplicate movie reviews with Supabase Vecs."
      },
      "text": "* * *\n\nThis guide will walk you through a [\"Semantic Text Deduplication\"](https://github.com/supabase/supabase/blob/master/examples/ai/semantic_text_deduplication.ipynb) example using Colab and Supabase Vecs. You'll learn how to find similar movie reviews using embeddings, and remove any that seem like duplicates. You will:\n\n1. Launch a Postgres database that uses pgvector to store embeddings\n2. Launch a notebook that connects to your database\n3. Load the IMDB dataset\n4. Use the `sentence-transformers/all-MiniLM-L6-v2` model to create an embedding representing the semantic meaning of each review.\n"
    }
  },
  {
    "chunk_id": "26bb1986-6228-4c50-9f4d-b65b12e9d65f",
    "metadata": {
      "token_count": 7,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/text-deduplication",
      "page_title": "Semantic Text Deduplication | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Text Deduplication",
        "h2": "Finding duplicate movie reviews with Supabase Vecs."
      },
      "text": "5. Search for all duplicates.\n",
      "overlap_text": {
        "previous_chunk_id": "20c32f6b-2d06-4834-9649-eed83cc38e83",
        "text": "Content of the previous chunk for context: h1: Semantic Text Deduplication h2: Finding duplicate movie reviews with Supabase Vecs.\n\n\n2. Launch a notebook that connects to your database\n3. Load the IMDB dataset\n4. Use the `sentence-transformers/all-MiniLM-L6-v2` model to create an embedding representing the semantic meaning of each review.\n"
      }
    }
  },
  {
    "chunk_id": "a0e63ef8-b50c-40c0-8137-13cf281d1c00",
    "metadata": {
      "token_count": 102,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/text-deduplication",
      "page_title": "Semantic Text Deduplication | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Text Deduplication",
        "h2": "Project setup [\\#](\\#project-setup)"
      },
      "text": "Let's create a new Postgres database. This is as simple as starting a new Project in Supabase:\n\n1. [Create a new project](https://database.new/) in the Supabase dashboard.\n2. Enter your project details. Remember to store your password somewhere safe.\n\nYour database will be available in less than a minute.\n\n**Finding your credentials:**\n\nYou can find your project credentials inside the project [settings](https://supabase.com/dashboard/project/_/settings/), including:\n",
      "overlap_text": {
        "previous_chunk_id": "26bb1986-6228-4c50-9f4d-b65b12e9d65f",
        "text": "Content of the previous chunk for context: h1: Semantic Text Deduplication h2: Finding duplicate movie reviews with Supabase Vecs.\n\n5. Search for all duplicates.\n"
      }
    }
  },
  {
    "chunk_id": "5cc8c599-e43c-4d0d-b134-ab2cd18ce944",
    "metadata": {
      "token_count": 61,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/text-deduplication",
      "page_title": "Semantic Text Deduplication | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Text Deduplication",
        "h2": "Project setup [\\#](\\#project-setup)"
      },
      "text": "\n- [Database credentials](https://supabase.com/dashboard/project/_/settings/database): connection strings and connection pooler details.\n- [API credentials](https://supabase.com/dashboard/project/_/settings/database): your serverless API URL and `anon` / `service_role` keys.\n",
      "overlap_text": {
        "previous_chunk_id": "a0e63ef8-b50c-40c0-8137-13cf281d1c00",
        "text": "Content of the previous chunk for context: h1: Semantic Text Deduplication h2: Project setup [\\#](\\#project-setup)\n\n store your password somewhere safe.\n\nYour database will be available in less than a minute.\n\n**Finding your credentials:**\n\nYou can find your project credentials inside the project [settings](https://supabase.com/dashboard/project/_/settings/), including:\n"
      }
    }
  },
  {
    "chunk_id": "d69eee5c-caed-4cc7-a847-be2adbc90d09",
    "metadata": {
      "token_count": 125,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/text-deduplication",
      "page_title": "Semantic Text Deduplication | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Text Deduplication",
        "h2": "Launching a notebook [\\#](\\#launching-a-notebook)"
      },
      "text": "Launch our [`semantic_text_deduplication`](https://github.com/supabase/supabase/blob/master/examples/ai/semantic_text_deduplication.ipynb) notebook in Colab:\n\n[![](https://supabase.com/docs/img/ai/colab-badge.svg)](https://colab.research.google.com/github/supabase/supabase/blob/master/examples/ai/semantic_text_deduplication.ipynb)\n\nAt the top of the notebook, you'll see a button `Copy to Drive`. Click this button to copy the notebook to your Google Drive.\n",
      "overlap_text": {
        "previous_chunk_id": "5cc8c599-e43c-4d0d-b134-ab2cd18ce944",
        "text": "Content of the previous chunk for context: h1: Semantic Text Deduplication h2: Project setup [\\#](\\#project-setup)\n\n.com/dashboard/project/_/settings/database): connection strings and connection pooler details.\n- [API credentials](https://supabase.com/dashboard/project/_/settings/database): your serverless API URL and `anon` / `service_role` keys.\n"
      }
    }
  },
  {
    "chunk_id": "60f53cc1-fc84-4d95-925e-c4d704347356",
    "metadata": {
      "token_count": 131,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/text-deduplication",
      "page_title": "Semantic Text Deduplication | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Text Deduplication",
        "h2": "Connecting to your database [\\#](\\#connecting-to-your-database)"
      },
      "text": "Inside the Notebook, find the cell which specifies the `DB_CONNECTION`. It will contain some code like this:\n\n`\n_10\nimport vecs\n_10\n_10\nDB_CONNECTION = \"postgresql://<user>:<password>@<host>:<port>/<db_name>\"\n_10\n_10\n# create vector store client\n_10\nvx = vecs.create_client(DB_CONNECTION)\n`\n\nReplace the `DB_CONNECTION` with your own connection string for your database. You can find the Postgres connection string in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database) of your Supabase project.\n",
      "overlap_text": {
        "previous_chunk_id": "d69eee5c-caed-4cc7-a847-be2adbc90d09",
        "text": "Content of the previous chunk for context: h1: Semantic Text Deduplication h2: Launching a notebook [\\#](\\#launching-a-notebook)\n\nase/supabase/blob/master/examples/ai/semantic_text_deduplication.ipynb)\n\nAt the top of the notebook, you'll see a button `Copy to Drive`. Click this button to copy the notebook to your Google Drive.\n"
      }
    }
  },
  {
    "chunk_id": "35dbe91a-c329-4fe1-998d-b4e08f867468",
    "metadata": {
      "token_count": 70,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/text-deduplication",
      "page_title": "Semantic Text Deduplication | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Text Deduplication",
        "h2": "Connecting to your database [\\#](\\#connecting-to-your-database)"
      },
      "text": "\nSQLAlchemy requires the connection string to start with `postgresql://` (instead of `postgres://`). Don't forget to rename this after copying the string from the dashboard.\n\nYou must use the \"connection pooling\" string (domain ending in `*.pooler.supabase.com`) with Google Colab since Colab does not support IPv6.\n",
      "overlap_text": {
        "previous_chunk_id": "60f53cc1-fc84-4d95-925e-c4d704347356",
        "text": "Content of the previous chunk for context: h1: Semantic Text Deduplication h2: Connecting to your database [\\#](\\#connecting-to-your-database)\n\n`\n\nReplace the `DB_CONNECTION` with your own connection string for your database. You can find the Postgres connection string in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database) of your Supabase project.\n"
      }
    }
  },
  {
    "chunk_id": "426445eb-8a2e-4843-aa89-b8f26d0a1a4b",
    "metadata": {
      "token_count": 121,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/text-deduplication",
      "page_title": "Semantic Text Deduplication | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Text Deduplication",
        "h2": "Stepping through the notebook [\\#](\\#stepping-through-the-notebook)"
      },
      "text": "Now all that's left is to step through the notebook. You can do this by clicking the \"execute\" button ( `ctrl+enter`) at the top left of each code cell. The notebook guides you through the process of creating a collection, adding data to it, and querying it.\n\nYou can view the inserted items in the [Table Editor](https://supabase.com/dashboard/project/_/editor/), by selecting the `vecs` schema from the schema dropdown.\n\n![Colab documents](https://supabase.com/docs/img/ai/google-colab/colab-documents.png)\n",
      "overlap_text": {
        "previous_chunk_id": "35dbe91a-c329-4fe1-998d-b4e08f867468",
        "text": "Content of the previous chunk for context: h1: Semantic Text Deduplication h2: Connecting to your database [\\#](\\#connecting-to-your-database)\n\n`). Don't forget to rename this after copying the string from the dashboard.\n\nYou must use the \"connection pooling\" string (domain ending in `*.pooler.supabase.com`) with Google Colab since Colab does not support IPv6.\n"
      }
    }
  },
  {
    "chunk_id": "4f6f5fee-b4ed-40a0-9648-c6773ed895c2",
    "metadata": {
      "token_count": 70,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/text-deduplication",
      "page_title": "Semantic Text Deduplication | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Text Deduplication",
        "h2": "Deployment [\\#](\\#deployment)"
      },
      "text": "If you have your own infrastructure for deploying Python apps, you can continue to use `vecs` as described in this guide.\n\nAlternatively if you would like to quickly deploy using Supabase, check out our guide on using the [Hugging Face Inference API](/docs/guides/ai/hugging-face) in Edge Functions using TypeScript.\n",
      "overlap_text": {
        "previous_chunk_id": "426445eb-8a2e-4843-aa89-b8f26d0a1a4b",
        "text": "Content of the previous chunk for context: h1: Semantic Text Deduplication h2: Stepping through the notebook [\\#](\\#stepping-through-the-notebook)\n\nhttps://supabase.com/dashboard/project/_/editor/), by selecting the `vecs` schema from the schema dropdown.\n\n![Colab documents](https://supabase.com/docs/img/ai/google-colab/colab-documents.png)\n"
      }
    }
  },
  {
    "chunk_id": "747afbac-58c6-45f0-b6de-6d9ebe16cc11",
    "metadata": {
      "token_count": 30,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/text-deduplication",
      "page_title": "Semantic Text Deduplication | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Semantic Text Deduplication",
        "h2": "Next steps [\\#](\\#next-steps)"
      },
      "text": "You can now start building your own applications with Vecs. Check our [examples](/docs/guides/ai#examples) for ideas.\n",
      "overlap_text": {
        "previous_chunk_id": "4f6f5fee-b4ed-40a0-9648-c6773ed895c2",
        "text": "Content of the previous chunk for context: h1: Semantic Text Deduplication h2: Deployment [\\#](\\#deployment)\n\n described in this guide.\n\nAlternatively if you would like to quickly deploy using Supabase, check out our guide on using the [Hugging Face Inference API](/docs/guides/ai/hugging-face) in Edge Functions using TypeScript.\n"
      }
    }
  },
  {
    "chunk_id": "68fb0f9d-852c-4139-8a8f-5ab1fba034a5",
    "metadata": {
      "token_count": 43,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/generate-text-embeddings",
      "page_title": "Generate Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generate Embeddings",
        "h2": "Generate text embeddings using Edge Functions."
      },
      "text": "* * *\n\nThis guide will walk you through how to generate high quality text embeddings in [Edge Functions](/docs/guides/functions) using its built-in AI inference API, so no external API is required.\n"
    }
  },
  {
    "chunk_id": "abf796a8-3414-4aca-a1d2-dc099fa0e9a3",
    "metadata": {
      "token_count": 108,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/generate-text-embeddings",
      "page_title": "Generate Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generate Embeddings",
        "h2": "Build the Edge Function [\\#](\\#build-the-edge-function)"
      },
      "text": "Let's build an Edge Function that will accept an input string and generate an embedding for it. Edge Functions are server-side TypeScript HTTP endpoints that run on-demand closest to your users.\n\n1\n\n### Set up Supabase locally\n\nMake sure you have the latest version of the [Supabase CLI installed](/docs/guides/cli/getting-started).\n\nInitialize Supabase in the root directory of your app and start your local stack.\n\n`\n_10\nsupabase init\n_10\nsupabase start\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "68fb0f9d-852c-4139-8a8f-5ab1fba034a5",
        "text": "Content of the previous chunk for context: h1: Generate Embeddings h2: Generate text embeddings using Edge Functions.\n\n* * *\n\nThis guide will walk you through how to generate high quality text embeddings in [Edge Functions](/docs/guides/functions) using its built-in AI inference API, so no external API is required.\n"
      }
    }
  },
  {
    "chunk_id": "7d43ea24-2a67-4238-bbca-8acd74f842c0",
    "metadata": {
      "token_count": 102,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/generate-text-embeddings",
      "page_title": "Generate Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generate Embeddings",
        "h2": "Build the Edge Function [\\#](\\#build-the-edge-function)"
      },
      "text": "2\n\n### Create Edge Function\n\nCreate an Edge Function that we will use to generate embeddings. We'll call this `embed` (you can name this anything you like).\n\nThis will create a new TypeScript file called `index.ts` under `./supabase/functions/embed`.\n\n`\n_10\nsupabase functions new embed\n`\n\n3\n\n### Setup Inference Session\n\nLet's create a new inference session to be used in the lifetime of this function. Multiple requests can use the same inference session.\n",
      "overlap_text": {
        "previous_chunk_id": "abf796a8-3414-4aca-a1d2-dc099fa0e9a3",
        "text": "Content of the previous chunk for context: h1: Generate Embeddings h2: Build the Edge Function [\\#](\\#build-the-edge-function)\n\nase CLI installed](/docs/guides/cli/getting-started).\n\nInitialize Supabase in the root directory of your app and start your local stack.\n\n`\n_10\nsupabase init\n_10\nsupabase start\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "90bf3d67-51dd-4183-97ad-4c479028757d",
    "metadata": {
      "token_count": 104,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/generate-text-embeddings",
      "page_title": "Generate Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generate Embeddings",
        "h2": "Build the Edge Function [\\#](\\#build-the-edge-function)"
      },
      "text": "\nCurrently, only the `gte-small` ( [https://huggingface.co/Supabase/gte-small](https://huggingface.co/Supabase/gte-small)) text embedding model is supported in Supabase's Edge Runtime.\n\n./supabase/functions/embed/index.ts\n\n`\n_10\nconst session = new Supabase.ai.Session('gte-small');\n`\n\n4\n\n### Implement request handler\n\nModify our request handler to accept an `input` string from the POST request JSON body.\n",
      "overlap_text": {
        "previous_chunk_id": "7d43ea24-2a67-4238-bbca-8acd74f842c0",
        "text": "Content of the previous chunk for context: h1: Generate Embeddings h2: Build the Edge Function [\\#](\\#build-the-edge-function)\n\nase/functions/embed`.\n\n`\n_10\nsupabase functions new embed\n`\n\n3\n\n### Setup Inference Session\n\nLet's create a new inference session to be used in the lifetime of this function. Multiple requests can use the same inference session.\n"
      }
    }
  },
  {
    "chunk_id": "6565e49a-e3de-4b52-a2d2-29d99ca5888c",
    "metadata": {
      "token_count": 161,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/generate-text-embeddings",
      "page_title": "Generate Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generate Embeddings",
        "h2": "Build the Edge Function [\\#](\\#build-the-edge-function)"
      },
      "text": "\nThen generate the embedding by calling `session.run(input)`.\n\n./supabase/functions/embed/index.ts\n\n`\n_16\nDeno.serve(async (req) => {\n_16\n// Extract input string from JSON body\n_16\nconst { input } = await req.json();\n_16\n_16\n// Generate the embedding from the user input\n_16\nconst embedding = await session.run(input, {\n_16\n    mean_pool: true,\n_16\n    normalize: true,\n_16\n});\n_16\n_16\n// Return the embedding\n_16\nreturn new Response(\n_16\n    JSON.stringify({ embedding }),\n_16\n    { headers: { 'Content-Type': 'application/json' } }\n_16\n);\n_16\n});\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "90bf3d67-51dd-4183-97ad-4c479028757d",
        "text": "Content of the previous chunk for context: h1: Generate Embeddings h2: Build the Edge Function [\\#](\\#build-the-edge-function)\n\nabase/functions/embed/index.ts\n\n`\n_10\nconst session = new Supabase.ai.Session('gte-small');\n`\n\n4\n\n### Implement request handler\n\nModify our request handler to accept an `input` string from the POST request JSON body.\n"
      }
    }
  },
  {
    "chunk_id": "ee0fbccb-45bf-4608-9482-483ad268b836",
    "metadata": {
      "token_count": 143,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/generate-text-embeddings",
      "page_title": "Generate Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generate Embeddings",
        "h2": "Build the Edge Function [\\#](\\#build-the-edge-function)"
      },
      "text": "Note the two options we pass to `session.run()`:\n\n- `mean_pool`: The first option sets `pooling` to `mean`. Pooling referes to how token-level embedding representations are compressed into a single sentence embedding that reflects the meaning of the entire sentence. Average pooling is the most common type of pooling for sentence embeddings.\n- `normalize`: The second option tells to normalize the embedding vector so that it can be used with distance measures like dot product. A normalized vector means its length (magnitude) is 1 - also referred to as a unit vector. A vector is normalized by dividing each element by the vector's length (magnitude), which maintains its direction but changes its length to 1.\n",
      "overlap_text": {
        "previous_chunk_id": "6565e49a-e3de-4b52-a2d2-29d99ca5888c",
        "text": "Content of the previous chunk for context: h1: Generate Embeddings h2: Build the Edge Function [\\#](\\#build-the-edge-function)\n\n16\n// Return the embedding\n_16\nreturn new Response(\n_16\n    JSON.stringify({ embedding }),\n_16\n    { headers: { 'Content-Type': 'application/json' } }\n_16\n);\n_16\n});\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "f23a69aa-26fe-47b7-8d13-cd2800d5c2a4",
    "metadata": {
      "token_count": 122,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/generate-text-embeddings",
      "page_title": "Generate Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generate Embeddings",
        "h2": "Build the Edge Function [\\#](\\#build-the-edge-function)"
      },
      "text": "\n5\n\n### Test it!\n\nTo test the Edge Function, first start a local functions server.\n\n`\n_10\nsupabase functions serve\n`\n\nThen in a new shell, create an HTTP request using cURL and pass in your input in the JSON body.\n\n`\n_10\ncurl --request POST 'http://localhost:54321/functions/v1/embed' \\\n_10\n  --header 'Authorization: Bearer ANON_KEY' \\\n_10\n  --header 'Content-Type: application/json' \\\n_10\n  --data '{ \"input\": \"hello world\" }'\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "ee0fbccb-45bf-4608-9482-483ad268b836",
        "text": "Content of the previous chunk for context: h1: Generate Embeddings h2: Build the Edge Function [\\#](\\#build-the-edge-function)\n\n. A normalized vector means its length (magnitude) is 1 - also referred to as a unit vector. A vector is normalized by dividing each element by the vector's length (magnitude), which maintains its direction but changes its length to 1.\n"
      }
    }
  },
  {
    "chunk_id": "7b27fde0-7237-4775-9ccb-51ca1ad31768",
    "metadata": {
      "token_count": 29,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/generate-text-embeddings",
      "page_title": "Generate Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generate Embeddings",
        "h2": "Build the Edge Function [\\#](\\#build-the-edge-function)"
      },
      "text": "Be sure to replace `ANON_KEY` with your project's anonymous key. You can get this key by running `supabase status`.\n",
      "overlap_text": {
        "previous_chunk_id": "f23a69aa-26fe-47b7-8d13-cd2800d5c2a4",
        "text": "Content of the previous chunk for context: h1: Generate Embeddings h2: Build the Edge Function [\\#](\\#build-the-edge-function)\n\n/embed' \\\n_10\n  --header 'Authorization: Bearer ANON_KEY' \\\n_10\n  --header 'Content-Type: application/json' \\\n_10\n  --data '{ \"input\": \"hello world\" }'\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "ee8a2c39-6af8-4d1e-b103-20322ca81304",
    "metadata": {
      "token_count": 38,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/generate-text-embeddings",
      "page_title": "Generate Embeddings | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Generate Embeddings",
        "h2": "Next steps [\\#](\\#next-steps)"
      },
      "text": "- Learn more about [embedding concepts](/docs/guides/ai/concepts)\n- [Store your embeddings](/docs/guides/ai/vector-columns) in a database\n",
      "overlap_text": {
        "previous_chunk_id": "7b27fde0-7237-4775-9ccb-51ca1ad31768",
        "text": "Content of the previous chunk for context: h1: Generate Embeddings h2: Build the Edge Function [\\#](\\#build-the-edge-function)\n\nBe sure to replace `ANON_KEY` with your project's anonymous key. You can get this key by running `supabase status`.\n"
      }
    }
  },
  {
    "chunk_id": "12f3f591-3729-4e76-886c-64d3bfbd2779",
    "metadata": {
      "token_count": 33,
      "source_url": "https://supabase.com/docs/guides/ai/structured-unstructured",
      "page_title": "Structured and Unstructured | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Structured and Unstructured",
        "h2": "Supabase is flexible enough to associate structured and unstructured metadata with embeddings."
      },
      "text": "* * *\n\nMost vector stores treat metadata associated with embeddings like NoSQL, unstructured data. Supabase is flexible enough to store unstructured and structured metadata.\n"
    }
  },
  {
    "chunk_id": "c0fb5a5f-a749-4c11-a0df-8791164b92ed",
    "metadata": {
      "token_count": 118,
      "source_url": "https://supabase.com/docs/guides/ai/structured-unstructured",
      "page_title": "Structured and Unstructured | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Structured and Unstructured",
        "h2": "Structured [\\#](\\#structured)"
      },
      "text": "`\n_11\ncreate table docs (\n_11\nid uuid primary key,\n_11\nembedding vector(3),\n_11\ncontent text,\n_11\nurl string\n_11\n);\n_11\n_11\ninsert into docs\n_11\n(id, embedding, content, url)\n_11\nvalues\n_11\n('79409372-7556-4ccc-ab8f-5786a6cfa4f7', array[0.1, 0.2, 0.3], 'Hello world', '/hello-world');\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "12f3f591-3729-4e76-886c-64d3bfbd2779",
        "text": "Content of the previous chunk for context: h1: Structured and Unstructured h2: Supabase is flexible enough to associate structured and unstructured metadata with embeddings.\n\n* * *\n\nMost vector stores treat metadata associated with embeddings like NoSQL, unstructured data. Supabase is flexible enough to store unstructured and structured metadata.\n"
      }
    }
  },
  {
    "chunk_id": "d21e2ed6-3d5a-4afe-b568-55bd169211d7",
    "metadata": {
      "token_count": 81,
      "source_url": "https://supabase.com/docs/guides/ai/structured-unstructured",
      "page_title": "Structured and Unstructured | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Structured and Unstructured",
        "h2": "Structured [\\#](\\#structured)"
      },
      "text": "Notice that we've associated two pieces of metadata, `content` and `url`, with the embedding. Those fields can be filtered, constrained, indexed, and generally operated on using the full power of SQL. Structured metadata fits naturally with a traditional Supabase application, and can be managed via database [migrations](/docs/guides/getting-started/local-development#database-migrations).\n",
      "overlap_text": {
        "previous_chunk_id": "c0fb5a5f-a749-4c11-a0df-8791164b92ed",
        "text": "Content of the previous chunk for context: h1: Structured and Unstructured h2: Structured [\\#](\\#structured)\n\n\n('79409372-7556-4ccc-ab8f-5786a6cfa4f7', array[0.1, 0.2, 0.3], 'Hello world', '/hello-world');\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "070770cf-8704-4f3c-8f26-1fe56bd71b65",
    "metadata": {
      "token_count": 135,
      "source_url": "https://supabase.com/docs/guides/ai/structured-unstructured",
      "page_title": "Structured and Unstructured | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Structured and Unstructured",
        "h2": "Unstructured [\\#](\\#unstructured)"
      },
      "text": "`\n_14\ncreate table docs (\n_14\nid uuid primary key,\n_14\nembedding vector(3),\n_14\nmeta jsonb\n_14\n);\n_14\n_14\ninsert into docs\n_14\n(id, embedding, meta)\n_14\nvalues\n_14\n(\n_14\n    '79409372-7556-4ccc-ab8f-5786a6cfa4f7',\n_14\n    array[0.1, 0.2, 0.3],\n_14\n    '{\"content\": \"Hello world\", \"url\": \"/hello-world\"}'\n_14\n);\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "d21e2ed6-3d5a-4afe-b568-55bd169211d7",
        "text": "Content of the previous chunk for context: h1: Structured and Unstructured h2: Structured [\\#](\\#structured)\n\n and generally operated on using the full power of SQL. Structured metadata fits naturally with a traditional Supabase application, and can be managed via database [migrations](/docs/guides/getting-started/local-development#database-migrations).\n"
      }
    }
  },
  {
    "chunk_id": "423caf48-3835-4ff0-815d-d39667e4188a",
    "metadata": {
      "token_count": 108,
      "source_url": "https://supabase.com/docs/guides/ai/structured-unstructured",
      "page_title": "Structured and Unstructured | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Structured and Unstructured",
        "h2": "Unstructured [\\#](\\#unstructured)"
      },
      "text": "An unstructured approach does not specify the metadata fields that are expected. It stores all metadata in a flexible `json`/ `jsonb` column. The tradeoff is that the querying/filtering capabilities of a schemaless data type are less flexible than when each field has a dedicated column. It also pushes the burden of metadata data integrity onto application code, which is more error prone than enforcing constraints in the database.\n\nThe unstructured approach is recommended:\n\n- for ephemeral/interactive workloads e.g. data science or scientific research\n",
      "overlap_text": {
        "previous_chunk_id": "070770cf-8704-4f3c-8f26-1fe56bd71b65",
        "text": "Content of the previous chunk for context: h1: Structured and Unstructured h2: Unstructured [\\#](\\#unstructured)\n\ncfa4f7',\n_14\n    array[0.1, 0.2, 0.3],\n_14\n    '{\"content\": \"Hello world\", \"url\": \"/hello-world\"}'\n_14\n);\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "5a0c8adb-2946-424f-8986-6ef7c7fa6c82",
    "metadata": {
      "token_count": 147,
      "source_url": "https://supabase.com/docs/guides/ai/structured-unstructured",
      "page_title": "Structured and Unstructured | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Structured and Unstructured",
        "h2": "Unstructured [\\#](\\#unstructured)"
      },
      "text": "- when metadata fields are user-defined or unknown\n- during rapid prototyping\n\nClient libraries like python's [vecs](https://github.com/supabase/vecs) use this structure. For example, running:\n\n`\n_10\n#!/usr/bin/env python3\n_10\nimport vecs\n_10\n_10\ndocs = vx.get_or_create_collection(name=\"docs\", dimension=1536)\n_10\n_10\ndocs.upsert(vectors=[\\\n_10\\\n('79409372-7556-4ccc-ab8f-5786a6cfa4f7', [100, 200, 300], { url: '/hello-world' })\\\n_10\\\n])\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "423caf48-3835-4ff0-815d-d39667e4188a",
        "text": "Content of the previous chunk for context: h1: Structured and Unstructured h2: Unstructured [\\#](\\#unstructured)\n\n. It also pushes the burden of metadata data integrity onto application code, which is more error prone than enforcing constraints in the database.\n\nThe unstructured approach is recommended:\n\n- for ephemeral/interactive workloads e.g. data science or scientific research\n"
      }
    }
  },
  {
    "chunk_id": "09b97e21-6970-4f33-a76e-51d241ea52e7",
    "metadata": {
      "token_count": 62,
      "source_url": "https://supabase.com/docs/guides/ai/structured-unstructured",
      "page_title": "Structured and Unstructured | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Structured and Unstructured",
        "h2": "Unstructured [\\#](\\#unstructured)"
      },
      "text": "automatically creates the unstructured SQL table during the call to `get_or_create_collection`.\n\nNote that when working with client libraries that emit SQL DDL, like `create table ...`, you should add that SQL to your migrations when moving to production to maintain a single source of truth for your database's schema.\n",
      "overlap_text": {
        "previous_chunk_id": "5a0c8adb-2946-424f-8986-6ef7c7fa6c82",
        "text": "Content of the previous chunk for context: h1: Structured and Unstructured h2: Unstructured [\\#](\\#unstructured)\n\n_10\\\n('79409372-7556-4ccc-ab8f-5786a6cfa4f7', [100, 200, 300], { url: '/hello-world' })\\\n_10\\\n])\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "6f657d58-f362-46a6-b6cb-9af3b92d962f",
    "metadata": {
      "token_count": 228,
      "source_url": "https://supabase.com/docs/guides/ai/structured-unstructured",
      "page_title": "Structured and Unstructured | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Structured and Unstructured",
        "h2": "Hybrid [\\#](\\#hybrid)"
      },
      "text": "The structured metadata style is recommended when the fields being tracked are known in advance. If you have a combination of known and unknown metadata fields, you can accommodate the unknown fields by adding a `json`/ `jsonb` column to the table. In that situation, known fields should continue to use dedicated columns for best query performance and throughput.\n\n`\n_18\ncreate table docs (\n_18\nid uuid primary key,\n_18\nembedding vector(3),\n_18\ncontent text,\n_18\nurl string,\n_18\nmeta jsonb\n_18\n);\n_18\n_18\ninsert into docs\n_18\n(id, embedding, content, url, meta)\n_18\nvalues\n_18\n(\n_18\n    '79409372-7556-4ccc-ab8f-5786a6cfa4f7',\n_18\n    array[0.1, 0.2, 0.3],\n_18\n    'Hello world',\n_18\n    '/hello-world',\n_18\n    '{\"key\": \"value\"}'\n_18\n);\n`\n",
      "overlap_text": {
        "previous_chunk_id": "09b97e21-6970-4f33-a76e-51d241ea52e7",
        "text": "Content of the previous chunk for context: h1: Structured and Unstructured h2: Unstructured [\\#](\\#unstructured)\n\n `get_or_create_collection`.\n\nNote that when working with client libraries that emit SQL DDL, like `create table ...`, you should add that SQL to your migrations when moving to production to maintain a single source of truth for your database's schema.\n"
      }
    }
  },
  {
    "chunk_id": "d7a610d3-887d-4ca8-9033-7a0dee1732a8",
    "metadata": {
      "token_count": 99,
      "source_url": "https://supabase.com/docs/guides/ai/structured-unstructured",
      "page_title": "Structured and Unstructured | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Structured and Unstructured",
        "h2": "Choosing the right model [\\#](\\#choosing-the-right-model)"
      },
      "text": "Both approaches create a table where you can store your embeddings and some metadata. You should choose the best approach for your use-case. In summary:\n\n- Structured metadata is best when fields are known in advance or query patterns are predictable e.g. a production Supabase application\n- Unstructured metadata is best when fields are unknown/user-defined or when working with data interactively e.g. exploratory research\n\nBoth approaches are valid, and the one you should choose depends on your use-case.\n",
      "overlap_text": {
        "previous_chunk_id": "6f657d58-f362-46a6-b6cb-9af3b92d962f",
        "text": "Content of the previous chunk for context: h1: Structured and Unstructured h2: Hybrid [\\#](\\#hybrid)\n\n\n    array[0.1, 0.2, 0.3],\n_18\n    'Hello world',\n_18\n    '/hello-world',\n_18\n    '{\"key\": \"value\"}'\n_18\n);\n`\n"
      }
    }
  },
  {
    "chunk_id": "77a36ed0-2ca8-4207-bef0-525f392be220",
    "metadata": {
      "token_count": 103,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/hello-world",
      "page_title": "Creating and managing collections | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Creating and managing collections",
        "h2": "Connecting to your database with Colab."
      },
      "text": "* * *\n\nThis guide will walk you through a basic [\"Hello World\"](https://github.com/supabase/supabase/blob/master/examples/ai/vector_hello_world.ipynb) example using Colab and Supabase Vecs. You'll learn how to:\n\n1. Launch a Postgres database that uses pgvector to store embeddings\n2. Launch a notebook that connects to your database\n3. Create a vector collection\n4. Add data to the collection\n5. Query the collection\n"
    }
  },
  {
    "chunk_id": "59651db0-cae7-4af8-b081-b8ae08b0875a",
    "metadata": {
      "token_count": 102,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/hello-world",
      "page_title": "Creating and managing collections | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Creating and managing collections",
        "h2": "Project setup [\\#](\\#project-setup)"
      },
      "text": "Let's create a new Postgres database. This is as simple as starting a new Project in Supabase:\n\n1. [Create a new project](https://database.new/) in the Supabase dashboard.\n2. Enter your project details. Remember to store your password somewhere safe.\n\nYour database will be available in less than a minute.\n\n**Finding your credentials:**\n\nYou can find your project credentials inside the project [settings](https://supabase.com/dashboard/project/_/settings/), including:\n",
      "overlap_text": {
        "previous_chunk_id": "77a36ed0-2ca8-4207-bef0-525f392be220",
        "text": "Content of the previous chunk for context: h1: Creating and managing collections h2: Connecting to your database with Colab.\n\n how to:\n\n1. Launch a Postgres database that uses pgvector to store embeddings\n2. Launch a notebook that connects to your database\n3. Create a vector collection\n4. Add data to the collection\n5. Query the collection\n"
      }
    }
  },
  {
    "chunk_id": "8c78d28d-e99d-4a4b-8166-aa3b1bf8ae5b",
    "metadata": {
      "token_count": 61,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/hello-world",
      "page_title": "Creating and managing collections | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Creating and managing collections",
        "h2": "Project setup [\\#](\\#project-setup)"
      },
      "text": "\n- [Database credentials](https://supabase.com/dashboard/project/_/settings/database): connection strings and connection pooler details.\n- [API credentials](https://supabase.com/dashboard/project/_/settings/database): your serverless API URL and `anon` / `service_role` keys.\n",
      "overlap_text": {
        "previous_chunk_id": "59651db0-cae7-4af8-b081-b8ae08b0875a",
        "text": "Content of the previous chunk for context: h1: Creating and managing collections h2: Project setup [\\#](\\#project-setup)\n\n store your password somewhere safe.\n\nYour database will be available in less than a minute.\n\n**Finding your credentials:**\n\nYou can find your project credentials inside the project [settings](https://supabase.com/dashboard/project/_/settings/), including:\n"
      }
    }
  },
  {
    "chunk_id": "cf634949-9dfa-4078-819b-9974c6ec5927",
    "metadata": {
      "token_count": 114,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/hello-world",
      "page_title": "Creating and managing collections | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Creating and managing collections",
        "h2": "Launching a notebook [\\#](\\#launching-a-notebook)"
      },
      "text": "Launch our [`vector_hello_world`](https://github.com/supabase/supabase/blob/master/examples/ai/vector_hello_world.ipynb) notebook in Colab:\n\n[![](https://supabase.com/docs/img/ai/colab-badge.svg)](https://colab.research.google.com/github/supabase/supabase/blob/master/examples/ai/vector_hello_world.ipynb)\n\nAt the top of the notebook, you'll see a button `Copy to Drive`. Click this button to copy the notebook to your Google Drive.\n",
      "overlap_text": {
        "previous_chunk_id": "8c78d28d-e99d-4a4b-8166-aa3b1bf8ae5b",
        "text": "Content of the previous chunk for context: h1: Creating and managing collections h2: Project setup [\\#](\\#project-setup)\n\n.com/dashboard/project/_/settings/database): connection strings and connection pooler details.\n- [API credentials](https://supabase.com/dashboard/project/_/settings/database): your serverless API URL and `anon` / `service_role` keys.\n"
      }
    }
  },
  {
    "chunk_id": "a5ad6e1b-bd0e-4b24-8a5a-35bc420716a7",
    "metadata": {
      "token_count": 131,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/hello-world",
      "page_title": "Creating and managing collections | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Creating and managing collections",
        "h2": "Connecting to your database [\\#](\\#connecting-to-your-database)"
      },
      "text": "Inside the Notebook, find the cell which specifies the `DB_CONNECTION`. It will contain some code like this:\n\n`\n_10\nimport vecs\n_10\n_10\nDB_CONNECTION = \"postgresql://<user>:<password>@<host>:<port>/<db_name>\"\n_10\n_10\n# create vector store client\n_10\nvx = vecs.create_client(DB_CONNECTION)\n`\n\nReplace the `DB_CONNECTION` with your own connection string for your database. You can find the Postgres connection string in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database) of your Supabase project.\n",
      "overlap_text": {
        "previous_chunk_id": "cf634949-9dfa-4078-819b-9974c6ec5927",
        "text": "Content of the previous chunk for context: h1: Creating and managing collections h2: Launching a notebook [\\#](\\#launching-a-notebook)\n\n/github/supabase/supabase/blob/master/examples/ai/vector_hello_world.ipynb)\n\nAt the top of the notebook, you'll see a button `Copy to Drive`. Click this button to copy the notebook to your Google Drive.\n"
      }
    }
  },
  {
    "chunk_id": "9f1ce64d-f2f7-4366-bdf3-206dc9157a2c",
    "metadata": {
      "token_count": 70,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/hello-world",
      "page_title": "Creating and managing collections | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Creating and managing collections",
        "h2": "Connecting to your database [\\#](\\#connecting-to-your-database)"
      },
      "text": "\nSQLAlchemy requires the connection string to start with `postgresql://` (instead of `postgres://`). Don't forget to rename this after copying the string from the dashboard.\n\nYou must use the \"connection pooling\" string (domain ending in `*.pooler.supabase.com`) with Google Colab since Colab does not support IPv6.\n",
      "overlap_text": {
        "previous_chunk_id": "a5ad6e1b-bd0e-4b24-8a5a-35bc420716a7",
        "text": "Content of the previous chunk for context: h1: Creating and managing collections h2: Connecting to your database [\\#](\\#connecting-to-your-database)\n\n`\n\nReplace the `DB_CONNECTION` with your own connection string for your database. You can find the Postgres connection string in the [Database Settings](https://supabase.com/dashboard/project/_/settings/database) of your Supabase project.\n"
      }
    }
  },
  {
    "chunk_id": "bcdb8f7c-5f6f-4026-a3ad-7912fe1c7d37",
    "metadata": {
      "token_count": 121,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/hello-world",
      "page_title": "Creating and managing collections | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Creating and managing collections",
        "h2": "Stepping through the notebook [\\#](\\#stepping-through-the-notebook)"
      },
      "text": "Now all that's left is to step through the notebook. You can do this by clicking the \"execute\" button ( `ctrl+enter`) at the top left of each code cell. The notebook guides you through the process of creating a collection, adding data to it, and querying it.\n\nYou can view the inserted items in the [Table Editor](https://supabase.com/dashboard/project/_/editor/), by selecting the `vecs` schema from the schema dropdown.\n\n![Colab documents](https://supabase.com/docs/img/ai/google-colab/colab-documents.png)\n",
      "overlap_text": {
        "previous_chunk_id": "9f1ce64d-f2f7-4366-bdf3-206dc9157a2c",
        "text": "Content of the previous chunk for context: h1: Creating and managing collections h2: Connecting to your database [\\#](\\#connecting-to-your-database)\n\n`). Don't forget to rename this after copying the string from the dashboard.\n\nYou must use the \"connection pooling\" string (domain ending in `*.pooler.supabase.com`) with Google Colab since Colab does not support IPv6.\n"
      }
    }
  },
  {
    "chunk_id": "d6c50eff-5e19-4581-af24-37739667cc32",
    "metadata": {
      "token_count": 30,
      "source_url": "https://supabase.com/docs/guides/ai/quickstarts/hello-world",
      "page_title": "Creating and managing collections | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Creating and managing collections",
        "h2": "Next steps [\\#](\\#next-steps)"
      },
      "text": "You can now start building your own applications with Vecs. Check our [examples](/docs/guides/ai#examples) for ideas.\n",
      "overlap_text": {
        "previous_chunk_id": "bcdb8f7c-5f6f-4026-a3ad-7912fe1c7d37",
        "text": "Content of the previous chunk for context: h1: Creating and managing collections h2: Stepping through the notebook [\\#](\\#stepping-through-the-notebook)\n\nhttps://supabase.com/dashboard/project/_/editor/), by selecting the `vecs` schema from the schema dropdown.\n\n![Colab documents](https://supabase.com/docs/img/ai/google-colab/colab-documents.png)\n"
      }
    }
  },
  {
    "chunk_id": "721c5162-9e03-47ed-b63c-8c6ffca27ceb",
    "metadata": {
      "token_count": 102,
      "source_url": "https://supabase.com/docs/guides/ai/keyword-search",
      "page_title": "Keyword search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Keyword search",
        "h2": "Learn how to search by words or phrases."
      },
      "text": "* * *\n\nKeyword search involves locating documents or records that contain specific words or phrases, primarily based on the exact match between the search terms and the text within the data. It differs from [semantic search](/docs/guides/ai/semantic-search), which interprets the meaning behind the query to provide results that are contextually related, even if the exact words aren't present in the text. Semantic search considers synonyms, intent, and natural language nuances to provide a more nuanced approach to information retrieval.\n"
    }
  },
  {
    "chunk_id": "d2efd08a-0e35-466d-ab40-76efaad6b6db",
    "metadata": {
      "token_count": 71,
      "source_url": "https://supabase.com/docs/guides/ai/keyword-search",
      "page_title": "Keyword search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Keyword search",
        "h2": "Learn how to search by words or phrases."
      },
      "text": "\nIn Postgres, keyword search is implemented using [full-text search](/docs/guides/database/full-text-search). It supports indexing and text analysis for data retrieval, focusing on records that match the search criteria. Postgres' full-text search extends beyond simple keyword matching to address linguistic nuances, making it effective for applications that require precise text queries.\n",
      "overlap_text": {
        "previous_chunk_id": "721c5162-9e03-47ed-b63c-8c6ffca27ceb",
        "text": "Content of the previous chunk for context: h1: Keyword search h2: Learn how to search by words or phrases.\n\n which interprets the meaning behind the query to provide results that are contextually related, even if the exact words aren't present in the text. Semantic search considers synonyms, intent, and natural language nuances to provide a more nuanced approach to information retrieval.\n"
      }
    }
  },
  {
    "chunk_id": "5f4e927d-0079-4ec6-b8e2-d981ddf80aa7",
    "metadata": {
      "token_count": 156,
      "source_url": "https://supabase.com/docs/guides/ai/keyword-search",
      "page_title": "Keyword search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Keyword search",
        "h2": "Why would I want to use keyword search? [\\#](\\#why-would-i-want-to-use-keyword-search)"
      },
      "text": "Keyword search is particularly useful in scenarios where precision and specificity matter. It's more effective than semantic search when users are looking for information using exact terminology or specific identifiers. It ensures that results directly contain those terms, reducing the chance of retrieving irrelevant information that might be semantically related but not what the user seeks.\n\nFor example in technical or academic research databases, researchers often search for specific studies, compounds, or concepts identified by certain terms or codes. Searching for a specific chemical compound using its exact molecular formula or a unique identifier will yield more focused and relevant results compared to a semantic search, which could return a wide range of documents discussing the compound in different contexts. Keyword search ensures documents that explicitly mention the exact term are found, allowing users to access the precise data they need efficiently.\n",
      "overlap_text": {
        "previous_chunk_id": "d2efd08a-0e35-466d-ab40-76efaad6b6db",
        "text": "Content of the previous chunk for context: h1: Keyword search h2: Learn how to search by words or phrases.\n\n/full-text-search). It supports indexing and text analysis for data retrieval, focusing on records that match the search criteria. Postgres' full-text search extends beyond simple keyword matching to address linguistic nuances, making it effective for applications that require precise text queries.\n"
      }
    }
  },
  {
    "chunk_id": "d9b609c7-1a56-45fc-bd01-002df8ba4cb3",
    "metadata": {
      "token_count": 41,
      "source_url": "https://supabase.com/docs/guides/ai/keyword-search",
      "page_title": "Keyword search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Keyword search",
        "h2": "Why would I want to use keyword search? [\\#](\\#why-would-i-want-to-use-keyword-search)"
      },
      "text": "\nIt's also possible to combine keyword search with semantic search to get the best of both worlds. See [Hybrid search](/docs/guides/ai/hybrid-search) for more details.\n",
      "overlap_text": {
        "previous_chunk_id": "5f4e927d-0079-4ec6-b8e2-d981ddf80aa7",
        "text": "Content of the previous chunk for context: h1: Keyword search h2: Why would I want to use keyword search? [\\#](\\#why-would-i-want-to-use-keyword-search)\n\n more focused and relevant results compared to a semantic search, which could return a wide range of documents discussing the compound in different contexts. Keyword search ensures documents that explicitly mention the exact term are found, allowing users to access the precise data they need efficiently.\n"
      }
    }
  },
  {
    "chunk_id": "f46b43d1-cbc0-4f45-80cc-2787ad8b2fbe",
    "metadata": {
      "token_count": 40,
      "source_url": "https://supabase.com/docs/guides/ai/keyword-search",
      "page_title": "Keyword search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Keyword search",
        "h2": "Using full-text search [\\#](\\#using-full-text-search)"
      },
      "text": "For an in-depth guide to Postgres' full-text search, including how to store, index, and query records, see [Full text search](/docs/guides/database/full-text-search).\n",
      "overlap_text": {
        "previous_chunk_id": "d9b609c7-1a56-45fc-bd01-002df8ba4cb3",
        "text": "Content of the previous chunk for context: h1: Keyword search h2: Why would I want to use keyword search? [\\#](\\#why-would-i-want-to-use-keyword-search)\n\n\nIt's also possible to combine keyword search with semantic search to get the best of both worlds. See [Hybrid search](/docs/guides/ai/hybrid-search) for more details.\n"
      }
    }
  },
  {
    "chunk_id": "5a831415-7924-4b85-b64d-d95c2e82bf52",
    "metadata": {
      "token_count": 33,
      "source_url": "https://supabase.com/docs/guides/ai/keyword-search",
      "page_title": "Keyword search | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Keyword search",
        "h2": "See also [\\#](\\#see-also)"
      },
      "text": "- [Semantic search](/docs/guides/ai/semantic-search)\n- [Hybrid search](/docs/guides/ai/hybrid-search)\n",
      "overlap_text": {
        "previous_chunk_id": "f46b43d1-cbc0-4f45-80cc-2787ad8b2fbe",
        "text": "Content of the previous chunk for context: h1: Keyword search h2: Using full-text search [\\#](\\#using-full-text-search)\n\nFor an in-depth guide to Postgres' full-text search, including how to store, index, and query records, see [Full text search](/docs/guides/database/full-text-search).\n"
      }
    }
  },
  {
    "chunk_id": "f126e35d-661c-4d6f-8e6b-8537bf62236a",
    "metadata": {
      "token_count": 41,
      "source_url": "https://supabase.com/docs/guides/ai/engineering-for-scale",
      "page_title": "Engineering for Scale | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Engineering for Scale",
        "h2": "Building an enterprise-grade vector architecture."
      },
      "text": "* * *\n\nContent sources for vectors can be extremely large. As you grow you should run your Vector workloads across several secondary databases (sometimes called \"pods\"), which allows each collection to scale independently.\n"
    }
  },
  {
    "chunk_id": "ca35950a-a685-43a3-8cfd-bf8cfc31e5f6",
    "metadata": {
      "token_count": 102,
      "source_url": "https://supabase.com/docs/guides/ai/engineering-for-scale",
      "page_title": "Engineering for Scale | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Engineering for Scale",
        "h2": "Simple workloads [\\#](\\#simple-workloads)"
      },
      "text": "For small workloads, it's typical to store your data in a single database.\n\nIf you've used [Vecs](/docs/guides/ai/vecs-python-client) to create 3 different collections, you can expose collections to your web or mobile application using [views](/docs/guides/database/tables#views):\n\nFor example, with 3 collections, called `docs`, `posts`, and `images`, we could expose the \"docs\" inside the public schema like this:\n",
      "overlap_text": {
        "previous_chunk_id": "f126e35d-661c-4d6f-8e6b-8537bf62236a",
        "text": "Content of the previous chunk for context: h1: Engineering for Scale h2: Building an enterprise-grade vector architecture.\n\n* * *\n\nContent sources for vectors can be extremely large. As you grow you should run your Vector workloads across several secondary databases (sometimes called \"pods\"), which allows each collection to scale independently.\n"
      }
    }
  },
  {
    "chunk_id": "c391edb8-6f89-4479-b29e-a549bbe3c216",
    "metadata": {
      "token_count": 129,
      "source_url": "https://supabase.com/docs/guides/ai/engineering-for-scale",
      "page_title": "Engineering for Scale | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Engineering for Scale",
        "h2": "Simple workloads [\\#](\\#simple-workloads)"
      },
      "text": "\n`\n_10\ncreate view public.docs as\n_10\nselect\n_10\nid,\n_10\nembedding,\n_10\nmetadata, # Expose the metadata as JSON\n_10\n(metadata->>'url')::text as url # Extract the URL as a string\n_10\nfrom vector\n`\n\nYou can then use any of the client libraries to access your collections within your applications:\n\n`\n_10\nconst { data, error } = await supabase\n_10\n.from('docs')\n_10\n.select('id, embedding, metadata')\n_10\n.eq('url', '/hello-world')\n`\n",
      "overlap_text": {
        "previous_chunk_id": "ca35950a-a685-43a3-8cfd-bf8cfc31e5f6",
        "text": "Content of the previous chunk for context: h1: Engineering for Scale h2: Simple workloads [\\#](\\#simple-workloads)\n\n mobile application using [views](/docs/guides/database/tables#views):\n\nFor example, with 3 collections, called `docs`, `posts`, and `images`, we could expose the \"docs\" inside the public schema like this:\n"
      }
    }
  },
  {
    "chunk_id": "978484d0-5c25-49f1-a786-8fb1508af35b",
    "metadata": {
      "token_count": 101,
      "source_url": "https://supabase.com/docs/guides/ai/engineering-for-scale",
      "page_title": "Engineering for Scale | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Engineering for Scale",
        "h2": "Enterprise workloads [\\#](\\#enterprise-workloads)"
      },
      "text": "As you move into production, we recommend splitting your collections into separate projects. This is because it allows your vector stores to scale independently of your production data. Vectors typically grow faster than operational data, and they have different resource requirements. Running them on separate databases removes the single-point-of-failure.\n\nYou can use as many secondary databases as you need to manage your collections. With this architecture, you have 2 options for accessing collections within your application:\n\n1. Query the collections directly using Vecs.\n",
      "overlap_text": {
        "previous_chunk_id": "c391edb8-6f89-4479-b29e-a549bbe3c216",
        "text": "Content of the previous chunk for context: h1: Engineering for Scale h2: Simple workloads [\\#](\\#simple-workloads)\n\n within your applications:\n\n`\n_10\nconst { data, error } = await supabase\n_10\n.from('docs')\n_10\n.select('id, embedding, metadata')\n_10\n.eq('url', '/hello-world')\n`\n"
      }
    }
  },
  {
    "chunk_id": "f3f1f011-2bb5-475a-9e7b-3a3aa8d734e1",
    "metadata": {
      "token_count": 112,
      "source_url": "https://supabase.com/docs/guides/ai/engineering-for-scale",
      "page_title": "Engineering for Scale | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Engineering for Scale",
        "h2": "Enterprise workloads [\\#](\\#enterprise-workloads)"
      },
      "text": "2. Access the collections from your Primary database through a Wrapper.\n\nYou can use both of these in tandem to suit your use-case. We recommend option `1` wherever possible, as it offers the most scalability.\n\n### Query collections using Vecs [\\#](\\#query-collections-using-vecs)\n\nVecs provides methods for querying collections, either using a [cosine similarity function](https://supabase.github.io/vecs/api/#basic) or with [metadata filtering](https://supabase.github.io/vecs/api/#metadata-filtering).\n",
      "overlap_text": {
        "previous_chunk_id": "978484d0-5c25-49f1-a786-8fb1508af35b",
        "text": "Content of the previous chunk for context: h1: Engineering for Scale h2: Enterprise workloads [\\#](\\#enterprise-workloads)\n\n databases removes the single-point-of-failure.\n\nYou can use as many secondary databases as you need to manage your collections. With this architecture, you have 2 options for accessing collections within your application:\n\n1. Query the collections directly using Vecs.\n"
      }
    }
  },
  {
    "chunk_id": "ad850734-7e36-4e4a-a5ae-a07c5701f7d8",
    "metadata": {
      "token_count": 101,
      "source_url": "https://supabase.com/docs/guides/ai/engineering-for-scale",
      "page_title": "Engineering for Scale | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Engineering for Scale",
        "h2": "Enterprise workloads [\\#](\\#enterprise-workloads)"
      },
      "text": "\n`\n_10\n# cosine similarity\n_10\ndocs.query(query_vector=[0.4,0.5,0.6], limit=5)\n_10\n_10\n# metadata filtering\n_10\ndocs.query(\n_10\n    query_vector=[0.4,0.5,0.6],\n_10\n    limit=5,\n_10\n    filters={\"year\": {\"$eq\": 2012}}, # metadata filters\n_10\n)\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "f3f1f011-2bb5-475a-9e7b-3a3aa8d734e1",
        "text": "Content of the previous chunk for context: h1: Engineering for Scale h2: Enterprise workloads [\\#](\\#enterprise-workloads)\n\ns provides methods for querying collections, either using a [cosine similarity function](https://supabase.github.io/vecs/api/#basic) or with [metadata filtering](https://supabase.github.io/vecs/api/#metadata-filtering).\n"
      }
    }
  },
  {
    "chunk_id": "144333b5-0837-4dc0-b843-f8bc6c74dad9",
    "metadata": {
      "token_count": 103,
      "source_url": "https://supabase.com/docs/guides/ai/engineering-for-scale",
      "page_title": "Engineering for Scale | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Engineering for Scale",
        "h2": "Enterprise workloads [\\#](\\#enterprise-workloads)"
      },
      "text": "### Accessing external collections using Wrappers [\\#](\\#accessing-external-collections-using-wrappers)\n\nSupabase supports [Foreign Data Wrappers](/blog/postgres-foreign-data-wrappers-rust). Wrappers allow you to connect two databases together so that you can query them over the network.\n\nThis involves 2 steps: connecting to your remote database from the primary and creating a Foreign Table.\n\n#### Connecting your remote database [\\#](\\#connecting-your-remote-database)\n\n",
      "overlap_text": {
        "previous_chunk_id": "ad850734-7e36-4e4a-a5ae-a07c5701f7d8",
        "text": "Content of the previous chunk for context: h1: Engineering for Scale h2: Enterprise workloads [\\#](\\#enterprise-workloads)\n\n\n    query_vector=[0.4,0.5,0.6],\n_10\n    limit=5,\n_10\n    filters={\"year\": {\"$eq\": 2012}}, # metadata filters\n_10\n)\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "f65bb526-f938-4115-8639-82e2185d577d",
    "metadata": {
      "token_count": 104,
      "source_url": "https://supabase.com/docs/guides/ai/engineering-for-scale",
      "page_title": "Engineering for Scale | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Engineering for Scale",
        "h2": "Enterprise workloads [\\#](\\#enterprise-workloads)"
      },
      "text": "Inside your Primary database we need to provide the credentials to access the secondary database:\n\n`\n_10\ncreate extension postgres_fdw;\n_10\n_10\ncreate server docs_server\n_10\nforeign data wrapper postgres_fdw\n_10\noptions (host 'db.xxx.supabase.co', port '5432', dbname 'postgres');\n_10\n_10\ncreate user mapping for docs_user\n_10\nserver docs_server\n_10\noptions (user 'postgres', password 'password');\n`\n\n",
      "overlap_text": {
        "previous_chunk_id": "144333b5-0837-4dc0-b843-f8bc6c74dad9",
        "text": "Content of the previous chunk for context: h1: Engineering for Scale h2: Enterprise workloads [\\#](\\#enterprise-workloads)\n\n two databases together so that you can query them over the network.\n\nThis involves 2 steps: connecting to your remote database from the primary and creating a Foreign Table.\n\n#### Connecting your remote database [\\#](\\#connecting-your-remote-database)\n\n"
      }
    }
  },
  {
    "chunk_id": "abb64140-2d76-4789-bd5c-8123d2f1a896",
    "metadata": {
      "token_count": 125,
      "source_url": "https://supabase.com/docs/guides/ai/engineering-for-scale",
      "page_title": "Engineering for Scale | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Engineering for Scale",
        "h2": "Enterprise workloads [\\#](\\#enterprise-workloads)"
      },
      "text": "#### Create a foreign table [\\#](\\#create-a-foreign-table)\n\nWe can now create a foreign table to access the data in our secondary project.\n\n`\n_10\ncreate foreign table docs (\n_10\nid text not null,\n_10\nembedding vector(384),\n_10\nmetadata jsonb,\n_10\nurl text\n_10\n)\n_10\nserver docs_server\n_10\noptions (schema_name 'public', table_name 'docs');\n`\n\nThis looks very similar to our View example above, and you can continue to use the client libraries to access your collections through the foreign table:\n",
      "overlap_text": {
        "previous_chunk_id": "f65bb526-f938-4115-8639-82e2185d577d",
        "text": "Content of the previous chunk for context: h1: Engineering for Scale h2: Enterprise workloads [\\#](\\#enterprise-workloads)\n\ndb.xxx.supabase.co', port '5432', dbname 'postgres');\n_10\n_10\ncreate user mapping for docs_user\n_10\nserver docs_server\n_10\noptions (user 'postgres', password 'password');\n`\n\n"
      }
    }
  },
  {
    "chunk_id": "6f84d77f-a117-4bbd-9ad2-eb79e41e4f0d",
    "metadata": {
      "token_count": 101,
      "source_url": "https://supabase.com/docs/guides/ai/engineering-for-scale",
      "page_title": "Engineering for Scale | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Engineering for Scale",
        "h2": "Enterprise workloads [\\#](\\#enterprise-workloads)"
      },
      "text": "\n`\n_10\nconst { data, error } = await supabase\n_10\n.from('docs')\n_10\n.select('id, embedding, metadata')\n_10\n.eq('url', '/hello-world')\n`\n\n### Enterprise architecture [\\#](\\#enterprise-architecture)\n\nThis diagram provides an example architecture that allows you to access the collections either with our client libraries or using Vecs. You can add as many secondary databases as you need (in this example we only show one):\n",
      "overlap_text": {
        "previous_chunk_id": "abb64140-2d76-4789-bd5c-8123d2f1a896",
        "text": "Content of the previous chunk for context: h1: Engineering for Scale h2: Enterprise workloads [\\#](\\#enterprise-workloads)\n\n10\nserver docs_server\n_10\noptions (schema_name 'public', table_name 'docs');\n`\n\nThis looks very similar to our View example above, and you can continue to use the client libraries to access your collections through the foreign table:\n"
      }
    }
  },
  {
    "chunk_id": "11ad14f4-557c-4418-afe6-ccf6072b69de",
    "metadata": {
      "token_count": 55,
      "source_url": "https://supabase.com/docs/guides/ai/concepts",
      "page_title": "Concepts | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Concepts"
      },
      "text": "* * *\n\nEmbeddings are core to many AI and vector applications. This guide covers these concepts. If you prefer to get started right away, see our guide on [Generating Embeddings](/docs/guides/ai/quickstarts/generate-text-embeddings).\n"
    }
  },
  {
    "chunk_id": "cc12967a-375b-4d8c-acc6-aab0c2340d5d",
    "metadata": {
      "token_count": 124,
      "source_url": "https://supabase.com/docs/guides/ai/concepts",
      "page_title": "Concepts | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Concepts",
        "h2": "What are embeddings? [\\#](\\#what-are-embeddings)"
      },
      "text": "Embeddings capture the \"relatedness\" of text, images, video, or other types of information. This relatedness is most commonly used for:\n\n- **Search:** how similar is a search term to a body of text?\n- **Recommendations:** how similar are two products?\n- **Classifications:** how do we categorize a body of text?\n- **Clustering:** how do we identify trends?\n\nLet's explore an example of text embeddings. Say we have three phrases:\n\n1. \"The cat chases the mouse\"\n2. \"The kitten hunts rodents\"\n3. \"I like ham sandwiches\"\n\n",
      "overlap_text": {
        "previous_chunk_id": "11ad14f4-557c-4418-afe6-ccf6072b69de",
        "text": "Content of the previous chunk for context: h1: Concepts\n\n are core to many AI and vector applications. This guide covers these concepts. If you prefer to get started right away, see our guide on [Generating Embeddings](/docs/guides/ai/quickstarts/generate-text-embeddings).\n"
      }
    }
  },
  {
    "chunk_id": "00656661-d4f8-4fbd-ab6a-ed5e9706eef5",
    "metadata": {
      "token_count": 82,
      "source_url": "https://supabase.com/docs/guides/ai/concepts",
      "page_title": "Concepts | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Concepts",
        "h2": "What are embeddings? [\\#](\\#what-are-embeddings)"
      },
      "text": "Your job is to group phrases with similar meaning. If you are a human, this should be obvious. Phrases 1 and 2 are almost identical, while phrase 3 has a completely different meaning.\n\nAlthough phrases 1 and 2 are similar, they share no common vocabulary (besides \"the\"). Yet their meanings are nearly identical. How can we teach a computer that these are the same?\n",
      "overlap_text": {
        "previous_chunk_id": "cc12967a-375b-4d8c-acc6-aab0c2340d5d",
        "text": "Content of the previous chunk for context: h1: Concepts h2: What are embeddings? [\\#](\\#what-are-embeddings)\n\nClustering:** how do we identify trends?\n\nLet's explore an example of text embeddings. Say we have three phrases:\n\n1. \"The cat chases the mouse\"\n2. \"The kitten hunts rodents\"\n3. \"I like ham sandwiches\"\n\n"
      }
    }
  },
  {
    "chunk_id": "0d0db271-7827-4d1d-90bc-91b24ad85f72",
    "metadata": {
      "token_count": 112,
      "source_url": "https://supabase.com/docs/guides/ai/concepts",
      "page_title": "Concepts | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Concepts",
        "h2": "Human language [\\#](\\#human-language)"
      },
      "text": "Humans use words and symbols to communicate language. But words in isolation are mostly meaningless - we need to draw from shared knowledge & experience in order to make sense of them. The phrase \u201cYou should Google it\u201d only makes sense if you know that Google is a search engine and that people have been using it as a verb.\n\nIn the same way, we need to train a neural network model to understand human language. An effective model should be trained on millions of different examples to understand what each word, phrase, sentence, or paragraph could mean in different contexts.\n",
      "overlap_text": {
        "previous_chunk_id": "00656661-d4f8-4fbd-ab6a-ed5e9706eef5",
        "text": "Content of the previous chunk for context: h1: Concepts h2: What are embeddings? [\\#](\\#what-are-embeddings)\n\n while phrase 3 has a completely different meaning.\n\nAlthough phrases 1 and 2 are similar, they share no common vocabulary (besides \"the\"). Yet their meanings are nearly identical. How can we teach a computer that these are the same?\n"
      }
    }
  },
  {
    "chunk_id": "b82edf64-66cc-4ee2-a997-eee4ee0a14f8",
    "metadata": {
      "token_count": 9,
      "source_url": "https://supabase.com/docs/guides/ai/concepts",
      "page_title": "Concepts | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Concepts",
        "h2": "Human language [\\#](\\#human-language)"
      },
      "text": "\nSo how does this relate to embeddings?\n",
      "overlap_text": {
        "previous_chunk_id": "0d0db271-7827-4d1d-90bc-91b24ad85f72",
        "text": "Content of the previous chunk for context: h1: Concepts h2: Human language [\\#](\\#human-language)\n\n a verb.\n\nIn the same way, we need to train a neural network model to understand human language. An effective model should be trained on millions of different examples to understand what each word, phrase, sentence, or paragraph could mean in different contexts.\n"
      }
    }
  },
  {
    "chunk_id": "6abb621c-06b0-4bc2-bec4-0b004a2521d8",
    "metadata": {
      "token_count": 140,
      "source_url": "https://supabase.com/docs/guides/ai/concepts",
      "page_title": "Concepts | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Concepts",
        "h2": "How do embeddings work? [\\#](\\#how-do-embeddings-work)"
      },
      "text": "Embeddings compress discrete information (words & symbols) into distributed continuous-valued data (vectors). If we took our phrases from before and plot them on a chart, it might look something like this:\n\n![Vector similarity](https://supabase.com/docs/img/ai/vector-similarity.png)\n\nPhrases 1 and 2 would be plotted close to each other, since their meanings are similar. We would expect phrase 3 to live somewhere far away since it isn't related. If we had a fourth phrase, \u201cSally ate Swiss cheese\u201d, this might exist somewhere between phrase 3 (cheese can go on sandwiches) and phrase 1 (mice like Swiss cheese).\n",
      "overlap_text": {
        "previous_chunk_id": "b82edf64-66cc-4ee2-a997-eee4ee0a14f8",
        "text": "Content of the previous chunk for context: h1: Concepts h2: Human language [\\#](\\#human-language)\n\n\nSo how does this relate to embeddings?\n"
      }
    }
  },
  {
    "chunk_id": "496ec728-86ce-4fba-96a4-31656a9f4c43",
    "metadata": {
      "token_count": 35,
      "source_url": "https://supabase.com/docs/guides/ai/concepts",
      "page_title": "Concepts | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Concepts",
        "h2": "How do embeddings work? [\\#](\\#how-do-embeddings-work)"
      },
      "text": "\nIn this example we only have 2 dimensions: the X and Y axis. In reality, we would need many more dimensions to effectively capture the complexities of human language.\n",
      "overlap_text": {
        "previous_chunk_id": "6abb621c-06b0-4bc2-bec4-0b004a2521d8",
        "text": "Content of the previous chunk for context: h1: Concepts h2: How do embeddings work? [\\#](\\#how-do-embeddings-work)\n\n somewhere far away since it isn't related. If we had a fourth phrase, \u201cSally ate Swiss cheese\u201d, this might exist somewhere between phrase 3 (cheese can go on sandwiches) and phrase 1 (mice like Swiss cheese).\n"
      }
    }
  },
  {
    "chunk_id": "d3943495-704c-4bec-a443-88cccfd70ec5",
    "metadata": {
      "token_count": 158,
      "source_url": "https://supabase.com/docs/guides/ai/concepts",
      "page_title": "Concepts | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Concepts",
        "h2": "Using embeddings [\\#](\\#using-embeddings)"
      },
      "text": "Compared to our 2-dimensional example above, most embedding models will output many more dimensions. For example the open source [`gte-small`](https://huggingface.co/Supabase/gte-small) model outputs 384 dimensions.\n\nWhy is this useful? Once we have generated embeddings on multiple texts, it is trivial to calculate how similar they are using vector math operations like cosine distance. A common use case for this is search. Your process might look something like this:\n\n1. Pre-process your knowledge base and generate embeddings for each page\n2. Store your embeddings to be referenced later\n3. Build a search page that prompts your user for input\n4. Take user's input, generate a one-time embedding, then perform a similarity search against your pre-processed embeddings.\n",
      "overlap_text": {
        "previous_chunk_id": "496ec728-86ce-4fba-96a4-31656a9f4c43",
        "text": "Content of the previous chunk for context: h1: Concepts h2: How do embeddings work? [\\#](\\#how-do-embeddings-work)\n\n\nIn this example we only have 2 dimensions: the X and Y axis. In reality, we would need many more dimensions to effectively capture the complexities of human language.\n"
      }
    }
  },
  {
    "chunk_id": "554a7a09-23b3-4ab8-91bf-39a501152f57",
    "metadata": {
      "token_count": 11,
      "source_url": "https://supabase.com/docs/guides/ai/concepts",
      "page_title": "Concepts | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Concepts",
        "h2": "Using embeddings [\\#](\\#using-embeddings)"
      },
      "text": "5. Return the most similar pages to the user\n",
      "overlap_text": {
        "previous_chunk_id": "d3943495-704c-4bec-a443-88cccfd70ec5",
        "text": "Content of the previous chunk for context: h1: Concepts h2: Using embeddings [\\#](\\#using-embeddings)\n\n page\n2. Store your embeddings to be referenced later\n3. Build a search page that prompts your user for input\n4. Take user's input, generate a one-time embedding, then perform a similarity search against your pre-processed embeddings.\n"
      }
    }
  },
  {
    "chunk_id": "76a40610-87ea-49a8-8a41-f701dcf676ae",
    "metadata": {
      "token_count": 20,
      "source_url": "https://supabase.com/docs/guides/ai/concepts",
      "page_title": "Concepts | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Concepts",
        "h2": "See also [\\#](\\#see-also)"
      },
      "text": "- [Structured and Unstructured embeddings](/docs/guides/ai/structured-unstructured)\n",
      "overlap_text": {
        "previous_chunk_id": "554a7a09-23b3-4ab8-91bf-39a501152f57",
        "text": "Content of the previous chunk for context: h1: Concepts h2: Using embeddings [\\#](\\#using-embeddings)\n\n5. Return the most similar pages to the user\n"
      }
    }
  },
  {
    "chunk_id": "4d3f2043-4265-47b0-9f35-37623ef9a502",
    "metadata": {
      "token_count": 75,
      "source_url": "https://supabase.com/docs/guides/ai/going-to-prod",
      "page_title": "Going to Production | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Going to Production",
        "h2": "Going to production checklist for AI applications."
      },
      "text": "* * *\n\nThis guide will help you to prepare your application for production. We'll provide actionable steps to help you scale your application, ensure that it is reliable, can handle the load, and provide optimal accuracy for your use case.\n\nSee our [Engineering for Scale](/docs/guides/ai/engineering-for-scale) guide for more information about engineering at scale.\n"
    }
  },
  {
    "chunk_id": "8847d38c-e894-4db3-bff9-bad191d873f8",
    "metadata": {
      "token_count": 140,
      "source_url": "https://supabase.com/docs/guides/ai/going-to-prod",
      "page_title": "Going to Production | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Going to Production",
        "h2": "Do you need indexes? [\\#](\\#do-you-need-indexes)"
      },
      "text": "Sequential scans will result in significantly higher latencies and lower throughput, guaranteeing 100% accuracy and not being RAM bound.\n\nThere are a couple of cases where you might not need indexes:\n\n- You have a small dataset and don't need to scale it.\n- You are not expecting high amounts of vector search queries per second.\n- You need to guarantee 100% accuracy.\n\nYou don't have to create indexes in these cases and can use sequential scans instead. This type of workload will not be RAM bound and will not require any additional resources but will result in higher latencies and lower throughput. Extra CPU cores may help to improve queries per second, but it will not help to improve latency.\n",
      "overlap_text": {
        "previous_chunk_id": "4d3f2043-4265-47b0-9f35-37623ef9a502",
        "text": "Content of the previous chunk for context: h1: Going to Production h2: Going to production checklist for AI applications.\n\n application, ensure that it is reliable, can handle the load, and provide optimal accuracy for your use case.\n\nSee our [Engineering for Scale](/docs/guides/ai/engineering-for-scale) guide for more information about engineering at scale.\n"
      }
    }
  },
  {
    "chunk_id": "50cdad5e-8a14-4046-a7cf-b0e71b8d97be",
    "metadata": {
      "token_count": 85,
      "source_url": "https://supabase.com/docs/guides/ai/going-to-prod",
      "page_title": "Going to Production | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Going to Production",
        "h2": "Do you need indexes? [\\#](\\#do-you-need-indexes)"
      },
      "text": "\nOn the other hand, if you need to scale your application, you will need to [create indexes](/docs/guides/ai/vector-indexes). This will result in lower latencies and higher throughput, but will require additional RAM to make use of Postgres Caching. Also, using indexes will result in lower accuracy, since you are replacing exact (KNN) search with approximate (ANN) search.\n",
      "overlap_text": {
        "previous_chunk_id": "8847d38c-e894-4db3-bff9-bad191d873f8",
        "text": "Content of the previous chunk for context: h1: Going to Production h2: Do you need indexes? [\\#](\\#do-you-need-indexes)\n\n scans instead. This type of workload will not be RAM bound and will not require any additional resources but will result in higher latencies and lower throughput. Extra CPU cores may help to improve queries per second, but it will not help to improve latency.\n"
      }
    }
  },
  {
    "chunk_id": "c2e767cf-af6b-4928-9125-90b1a30b3b5d",
    "metadata": {
      "token_count": 111,
      "source_url": "https://supabase.com/docs/guides/ai/going-to-prod",
      "page_title": "Going to Production | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Going to Production",
        "h2": "HNSW vs IVFFlat indexes [\\#](\\#hnsw-vs-ivfflat-indexes)"
      },
      "text": "`pgvector` supports two types of indexes: HNSW and IVFFlat. We recommend using [HNSW](/docs/guides/ai/vector-indexes/hnsw-indexes) because of its [performance](https://supabase.com/blog/increase-performance-pgvector-hnsw#hnsw-performance-1536-dimensions) and [robustness against changing data](/docs/guides/ai/vector-indexes/hnsw-indexes#when-should-you-create-hnsw-indexes).\n",
      "overlap_text": {
        "previous_chunk_id": "50cdad5e-8a14-4046-a7cf-b0e71b8d97be",
        "text": "Content of the previous chunk for context: h1: Going to Production h2: Do you need indexes? [\\#](\\#do-you-need-indexes)\n\n result in lower latencies and higher throughput, but will require additional RAM to make use of Postgres Caching. Also, using indexes will result in lower accuracy, since you are replacing exact (KNN) search with approximate (ANN) search.\n"
      }
    }
  },
  {
    "chunk_id": "5fa90fcf-e09f-4b86-87a9-293868745ce3",
    "metadata": {
      "token_count": 206,
      "source_url": "https://supabase.com/docs/guides/ai/going-to-prod",
      "page_title": "Going to Production | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Going to Production",
        "h2": "HNSW, understanding `ef_construction`, `ef_search`, and `m` [\\#](\\#hnsw-understanding-efconstruction--efsearch--and-m)"
      },
      "text": "Index build parameters:\n\n- `m` is the number of bi-directional links created for every new element during construction. Higher `m` is suitable for datasets with high dimensionality and/or high accuracy requirements. Reasonable values for `m` are between 2 and 100. Range 12-48 is a good starting point for most use cases (16 is the default value).\n\n- `ef_construction` is the size of the dynamic list for the nearest neighbors (used during the construction algorithm). Higher `ef_construction` will result in better index quality and higher accuracy, but it will also increase the time required to build the index. `ef_construction` has to be at least 2 \\* `m` (64 is the default value). At some point, increasing `ef_construction` does not improve the quality of the index. You can measure accuracy when `ef_search` = `ef_construction`: if accuracy is lower than 0.9, then there is room for improvement.\n",
      "overlap_text": {
        "previous_chunk_id": "c2e767cf-af6b-4928-9125-90b1a30b3b5d",
        "text": "Content of the previous chunk for context: h1: Going to Production h2: HNSW vs IVFFlat indexes [\\#](\\#hnsw-vs-ivfflat-indexes)\n\n-hnsw#hnsw-performance-1536-dimensions) and [robustness against changing data](/docs/guides/ai/vector-indexes/hnsw-indexes#when-should-you-create-hnsw-indexes).\n"
      }
    }
  },
  {
    "chunk_id": "22fb3182-4710-491d-aec2-570b35ac9d3a",
    "metadata": {
      "token_count": 56,
      "source_url": "https://supabase.com/docs/guides/ai/going-to-prod",
      "page_title": "Going to Production | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Going to Production",
        "h2": "HNSW, understanding `ef_construction`, `ef_search`, and `m` [\\#](\\#hnsw-understanding-efconstruction--efsearch--and-m)"
      },
      "text": "\n\nSearch parameters:\n\n- `ef_search` is the size of the dynamic list for the nearest neighbors (used during the search). Increasing `ef_search` will result in better accuracy, but it will also increase the time required to execute a query (40 is the default value).\n",
      "overlap_text": {
        "previous_chunk_id": "5fa90fcf-e09f-4b86-87a9-293868745ce3",
        "text": "Content of the previous chunk for context: h1: Going to Production h2: HNSW, understanding `ef_construction`, `ef_search`, and `m` [\\#](\\#hnsw-understanding-efconstruction--efsearch--and-m)\n\n some point, increasing `ef_construction` does not improve the quality of the index. You can measure accuracy when `ef_search` = `ef_construction`: if accuracy is lower than 0.9, then there is room for improvement.\n"
      }
    }
  },
  {
    "chunk_id": "276de0f2-bec3-448a-a052-43e273a38153",
    "metadata": {
      "token_count": 109,
      "source_url": "https://supabase.com/docs/guides/ai/going-to-prod",
      "page_title": "Going to Production | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Going to Production",
        "h2": "IVFFlat, understanding `probes` and `lists` [\\#](\\#ivfflat-understanding-probes-and-lists)"
      },
      "text": "Indexes used for approximate vector similarity search in pgvector divides a dataset into partitions. The number of these partitions is defined by the `lists` constant. The `probes` controls how many lists are going to be searched during a query.\n\nThe values of lists and probes directly affect accuracy and queries per second (QPS).\n\n- Higher `lists` means an index will be built slower, but you can achieve better QPS and accuracy.\n- Higher `probes` means that select queries will be slower, but you can achieve better accuracy.\n",
      "overlap_text": {
        "previous_chunk_id": "22fb3182-4710-491d-aec2-570b35ac9d3a",
        "text": "Content of the previous chunk for context: h1: Going to Production h2: HNSW, understanding `ef_construction`, `ef_search`, and `m` [\\#](\\#hnsw-understanding-efconstruction--efsearch--and-m)\n\nef_search` is the size of the dynamic list for the nearest neighbors (used during the search). Increasing `ef_search` will result in better accuracy, but it will also increase the time required to execute a query (40 is the default value).\n"
      }
    }
  },
  {
    "chunk_id": "a99aa52c-b48d-45fa-b29a-dd92e6d0e488",
    "metadata": {
      "token_count": 82,
      "source_url": "https://supabase.com/docs/guides/ai/going-to-prod",
      "page_title": "Going to Production | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Going to Production",
        "h2": "IVFFlat, understanding `probes` and `lists` [\\#](\\#ivfflat-understanding-probes-and-lists)"
      },
      "text": "- `lists` and `probes` are not independent. Higher `lists` means that you will have to use higher `probes` to achieve the same accuracy.\n\nYou can find more examples of how `lists` and `probes` constants affect accuracy and QPS in [pgvector 0.4.0 performance](https://supabase.com/blog/pgvector-performance) blogpost.\n",
      "overlap_text": {
        "previous_chunk_id": "276de0f2-bec3-448a-a052-43e273a38153",
        "text": "Content of the previous chunk for context: h1: Going to Production h2: IVFFlat, understanding `probes` and `lists` [\\#](\\#ivfflat-understanding-probes-and-lists)\n\n per second (QPS).\n\n- Higher `lists` means an index will be built slower, but you can achieve better QPS and accuracy.\n- Higher `probes` means that select queries will be slower, but you can achieve better accuracy.\n"
      }
    }
  },
  {
    "chunk_id": "66680f21-e4d1-4821-b961-8dfa06d74ced",
    "metadata": {
      "token_count": 148,
      "source_url": "https://supabase.com/docs/guides/ai/going-to-prod",
      "page_title": "Going to Production | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Going to Production",
        "h2": "Performance tips when using indexes [\\#](\\#performance-tips-when-using-indexes)"
      },
      "text": "First, a few generic tips which you can pick and choose from:\n\n1. The Supabase managed platform will automatically optimize Postgres configs for you based on your compute addon. But if you self-host, consider **adjusting your Postgres config** based on RAM & CPU cores. See [example optimizations](https://gist.github.com/egor-romanov/323e2847851bbd758081511785573c08) for more details.\n2. Prefer `inner-product` to `L2` or `Cosine` distances if your vectors are normalized (like `text-embedding-ada-002`). If embeddings are not normalized, `Cosine` distance should give the best results with an index.\n",
      "overlap_text": {
        "previous_chunk_id": "a99aa52c-b48d-45fa-b29a-dd92e6d0e488",
        "text": "Content of the previous chunk for context: h1: Going to Production h2: IVFFlat, understanding `probes` and `lists` [\\#](\\#ivfflat-understanding-probes-and-lists)\n\n same accuracy.\n\nYou can find more examples of how `lists` and `probes` constants affect accuracy and QPS in [pgvector 0.4.0 performance](https://supabase.com/blog/pgvector-performance) blogpost.\n"
      }
    }
  },
  {
    "chunk_id": "dc4d2746-5a7b-4433-8667-93ee0db80ea7",
    "metadata": {
      "token_count": 107,
      "source_url": "https://supabase.com/docs/guides/ai/going-to-prod",
      "page_title": "Going to Production | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Going to Production",
        "h2": "Performance tips when using indexes [\\#](\\#performance-tips-when-using-indexes)"
      },
      "text": "3. **Pre-warm your database.** Implement the warm-up technique before transitioning to production or running benchmarks.\n   - Use [pg\\_prewarm](https://www.postgresql.org/docs/current/pgprewarm.html) to load the index into RAM `select pg_prewarm('vecs.docs_vec_idx');`. This will help to avoid cold cache issues.\n   - Execute 10,000 to 50,000 \"warm-up\" queries before each benchmark/prod. This will help to utilize cache and buffers more efficiently.\n",
      "overlap_text": {
        "previous_chunk_id": "66680f21-e4d1-4821-b961-8dfa06d74ced",
        "text": "Content of the previous chunk for context: h1: Going to Production h2: Performance tips when using indexes [\\#](\\#performance-tips-when-using-indexes)\n\ninner-product` to `L2` or `Cosine` distances if your vectors are normalized (like `text-embedding-ada-002`). If embeddings are not normalized, `Cosine` distance should give the best results with an index.\n"
      }
    }
  },
  {
    "chunk_id": "a6c26f17-fc5b-4616-ac24-bd4ceecb522d",
    "metadata": {
      "token_count": 135,
      "source_url": "https://supabase.com/docs/guides/ai/going-to-prod",
      "page_title": "Going to Production | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Going to Production",
        "h2": "Performance tips when using indexes [\\#](\\#performance-tips-when-using-indexes)"
      },
      "text": "4. **Establish your workload.** Finetune `m` and `ef_construction` or `lists` constants for the pgvector index to accelerate your queries (at the expense of a slower build times). For instance, for benchmarks with 1,000,000 OpenAI embeddings, we set `m` and `ef_construction` to 32 and 80, and it resulted in 35% higher QPS than 24 and 56 values respectively.\n5. **Benchmark your own specific workloads.** Doing this during cache warm-up helps gauge the best value for the index build parameters, balancing accuracy with queries per second (QPS).\n",
      "overlap_text": {
        "previous_chunk_id": "dc4d2746-5a7b-4433-8667-93ee0db80ea7",
        "text": "Content of the previous chunk for context: h1: Going to Production h2: Performance tips when using indexes [\\#](\\#performance-tips-when-using-indexes)\n\n('vecs.docs_vec_idx');`. This will help to avoid cold cache issues.\n   - Execute 10,000 to 50,000 \"warm-up\" queries before each benchmark/prod. This will help to utilize cache and buffers more efficiently.\n"
      }
    }
  },
  {
    "chunk_id": "4587ecaa-3915-4953-8ab5-79b8e8b20cd3",
    "metadata": {
      "token_count": 120,
      "source_url": "https://supabase.com/docs/guides/ai/going-to-prod",
      "page_title": "Going to Production | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Going to Production",
        "h2": "Going into production [\\#](\\#going-into-production)"
      },
      "text": "1. Decide if you are going to use indexes or not. You can skip the rest of this guide if you do not use indexes.\n2. Over-provision RAM during preparation. You can scale down in step `5`, but it's better to start with a larger size to get the best results for RAM requirements. (We'd recommend at least 8XL if you're using Supabase.)\n3. Upload your data to the database. If you use the [`vecs`](/docs/guides/ai/python/api) library, it will automatically generate an index with default parameters.\n",
      "overlap_text": {
        "previous_chunk_id": "a6c26f17-fc5b-4616-ac24-bd4ceecb522d",
        "text": "Content of the previous chunk for context: h1: Going to Production h2: Performance tips when using indexes [\\#](\\#performance-tips-when-using-indexes)\n\n higher QPS than 24 and 56 values respectively.\n5. **Benchmark your own specific workloads.** Doing this during cache warm-up helps gauge the best value for the index build parameters, balancing accuracy with queries per second (QPS).\n"
      }
    }
  },
  {
    "chunk_id": "faafdcbb-b592-4911-b9ae-37af4609f693",
    "metadata": {
      "token_count": 110,
      "source_url": "https://supabase.com/docs/guides/ai/going-to-prod",
      "page_title": "Going to Production | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Going to Production",
        "h2": "Going into production [\\#](\\#going-into-production)"
      },
      "text": "4. Run a benchmark using randomly generated queries and observe the results. Again, you can use the `vecs` library with the `ann-benchmarks` tool. Do it with default values for index build parameters, you can later adjust them to get the best results.\n5. Monitor the RAM usage, and save it as a note for yourself. You would likely want to use a compute add-on in the future that has the same amount of RAM that was used at the moment (both actual RAM usage and RAM used for cache and buffers).\n",
      "overlap_text": {
        "previous_chunk_id": "4587ecaa-3915-4953-8ab5-79b8e8b20cd3",
        "text": "Content of the previous chunk for context: h1: Going to Production h2: Going into production [\\#](\\#going-into-production)\n\n least 8XL if you're using Supabase.)\n3. Upload your data to the database. If you use the [`vecs`](/docs/guides/ai/python/api) library, it will automatically generate an index with default parameters.\n"
      }
    }
  },
  {
    "chunk_id": "7f239426-42dc-44bf-958a-5df71f0f671f",
    "metadata": {
      "token_count": 121,
      "source_url": "https://supabase.com/docs/guides/ai/going-to-prod",
      "page_title": "Going to Production | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Going to Production",
        "h2": "Going into production [\\#](\\#going-into-production)"
      },
      "text": "6. Scale down your compute add-on to the one that would have the same amount of RAM used at the moment.\n7. Repeat step 3 to load the data into RAM. You should see QPS increase on subsequent runs, and stop when it no longer increases.\n8. Run a benchmark using real queries and observe the results. You can use the `vecs` library for that as well with `ann-benchmarks` tool. Tweak `ef_search` for HNSW or `probes` for IVFFlat until you see that both accuracy and QPS match your requirements.\n",
      "overlap_text": {
        "previous_chunk_id": "faafdcbb-b592-4911-b9ae-37af4609f693",
        "text": "Content of the previous chunk for context: h1: Going to Production h2: Going into production [\\#](\\#going-into-production)\n\n usage, and save it as a note for yourself. You would likely want to use a compute add-on in the future that has the same amount of RAM that was used at the moment (both actual RAM usage and RAM used for cache and buffers).\n"
      }
    }
  },
  {
    "chunk_id": "061157bd-7dae-4c4a-9f93-8ad6e6d6c6a4",
    "metadata": {
      "token_count": 146,
      "source_url": "https://supabase.com/docs/guides/ai/going-to-prod",
      "page_title": "Going to Production | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Going to Production",
        "h2": "Going into production [\\#](\\#going-into-production)"
      },
      "text": "9. If you want higher QPS you can increase `m` and `ef_construction` for HNSW or `lists` for IVFFlat parameters (consider switching from IVF to HNSW). You have to rebuild the index with a higher `m` and `ef_construction` values and repeat steps 6-7 to find the best combination of `m`, `ef_construction` and `ef_search` constants to achieve the best QPS and accuracy values. Higher `m`, `ef_construction` mean that index will build slower, but you can achieve better QPS and accuracy. Higher `ef_search` mean that select queries will be slower, but you can achieve better accuracy.\n",
      "overlap_text": {
        "previous_chunk_id": "7f239426-42dc-44bf-958a-5df71f0f671f",
        "text": "Content of the previous chunk for context: h1: Going to Production h2: Going into production [\\#](\\#going-into-production)\n\n the `vecs` library for that as well with `ann-benchmarks` tool. Tweak `ef_search` for HNSW or `probes` for IVFFlat until you see that both accuracy and QPS match your requirements.\n"
      }
    }
  },
  {
    "chunk_id": "d94e8e10-1a69-4bae-b76e-97afa6868973",
    "metadata": {
      "token_count": 166,
      "source_url": "https://supabase.com/docs/guides/ai/going-to-prod",
      "page_title": "Going to Production | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "Going to Production",
        "h2": "Useful links [\\#](\\#useful-links)"
      },
      "text": "Don't forget to check out the general [Production Checklist](/docs/guides/platform/going-into-prod) to ensure your project is secure, performant, and will remain available for your users.\n\nYou can look at our [Choosing Compute Add-on](/docs/guides/ai/choosing-compute-addon) guide to get a basic understanding of how much compute you might need for your workload.\n\nOr take a look at our [pgvector 0.5.0 performance](https://supabase.com/blog/increase-performance-pgvector-hnsw) and [pgvector 0.4.0 performance](https://supabase.com/blog/pgvector-performance) blog posts to see what pgvector is capable of and how the above technique can be used to achieve the best results.\n",
      "overlap_text": {
        "previous_chunk_id": "061157bd-7dae-4c4a-9f93-8ad6e6d6c6a4",
        "text": "Content of the previous chunk for context: h1: Going to Production h2: Going into production [\\#](\\#going-into-production)\n\n and accuracy values. Higher `m`, `ef_construction` mean that index will build slower, but you can achieve better QPS and accuracy. Higher `ef_search` mean that select queries will be slower, but you can achieve better accuracy.\n"
      }
    }
  },
  {
    "chunk_id": "0ca78d23-412d-437d-83dd-e03e828ea14d",
    "metadata": {
      "token_count": 129,
      "source_url": "https://supabase.com/docs/guides/ai",
      "page_title": "AI & Vectors | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "AI & Vectors",
        "h2": "The best vector database is the database you already have."
      },
      "text": "* * *\n\nSupabase provides an open source toolkit for developing AI applications using Postgres and pgvector. Use the Supabase client libraries to store, index, and query your vector embeddings at scale.\n\nThe toolkit includes:\n\n- A [vector store](/docs/guides/ai/vector-columns) and embeddings support using Postgres and pgvector.\n- A [Python client](/docs/guides/ai/vecs-python-client) for managing unstructured embeddings.\n- An [embedding generation](/docs/guides/ai/quickstarts/generate-text-embeddings) process using open source models directly in Edge Functions.\n"
    }
  },
  {
    "chunk_id": "c1fd3d8e-cc63-4e93-b8af-bd68e5a8609f",
    "metadata": {
      "token_count": 106,
      "source_url": "https://supabase.com/docs/guides/ai",
      "page_title": "AI & Vectors | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "AI & Vectors",
        "h2": "The best vector database is the database you already have."
      },
      "text": "- [Database migrations](/docs/guides/ai/examples/headless-vector-search#prepare-your-database) for managing structured embeddings.\n- Integrations with all popular AI providers, such as [OpenAI](/docs/guides/ai/examples/openai), [Hugging Face](/docs/guides/ai/hugging-face), [LangChain](/docs/guides/ai/langchain), and more.\n\nYou can use Supabase to build different types of search features for your app, including:\n",
      "overlap_text": {
        "previous_chunk_id": "0ca78d23-412d-437d-83dd-e03e828ea14d",
        "text": "Content of the previous chunk for context: h1: AI & Vectors h2: The best vector database is the database you already have.\n\ndocs/guides/ai/vecs-python-client) for managing unstructured embeddings.\n- An [embedding generation](/docs/guides/ai/quickstarts/generate-text-embeddings) process using open source models directly in Edge Functions.\n"
      }
    }
  },
  {
    "chunk_id": "a8ac48c3-e1f9-4b46-aae5-eccfbb97e31d",
    "metadata": {
      "token_count": 71,
      "source_url": "https://supabase.com/docs/guides/ai",
      "page_title": "AI & Vectors | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "AI & Vectors",
        "h2": "The best vector database is the database you already have."
      },
      "text": "\n- [Semantic search](/docs/guides/ai/semantic-search): search by meaning rather than exact keywords\n- [Keyword search](/docs/guides/ai/keyword-search): search by words or phrases\n- [Hybrid search](/docs/guides/ai/hybrid-search): combine semantic search with keyword search\n",
      "overlap_text": {
        "previous_chunk_id": "c1fd3d8e-cc63-4e93-b8af-bd68e5a8609f",
        "text": "Content of the previous chunk for context: h1: AI & Vectors h2: The best vector database is the database you already have.\n\nugging Face](/docs/guides/ai/hugging-face), [LangChain](/docs/guides/ai/langchain), and more.\n\nYou can use Supabase to build different types of search features for your app, including:\n"
      }
    }
  },
  {
    "chunk_id": "96fbc08c-f9e1-418e-b653-a2ab4e2993a7",
    "metadata": {
      "token_count": 165,
      "source_url": "https://supabase.com/docs/guides/ai",
      "page_title": "AI & Vectors | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "AI & Vectors",
        "h2": "Examples [\\#](\\#examples)"
      },
      "text": "Check out all of the AI [templates and examples](https://github.com/supabase/supabase/tree/master/examples/ai) in our GitHub repository.\n\n[![Headless Vector Search](https://supabase.com/docs/img/icons/github-icon-light.svg)\\\\\n\\\\\nHeadless Vector Search\\\\\n\\\\\nA toolkit to perform vector similarity search on your knowledge base embeddings.](/docs/guides/ai/examples/headless-vector-search)\n\n[![Image Search with OpenAI CLIP](https://supabase.com/docs/img/icons/github-icon-light.svg)\\\\\n\\\\\nImage Search with OpenAI CLIP\\\\\n\\\\\nImplement image search with the OpenAI CLIP Model and Supabase Vector.](/docs/guides/ai/examples/image-search-openai-clip)\n\n",
      "overlap_text": {
        "previous_chunk_id": "a8ac48c3-e1f9-4b46-aae5-eccfbb97e31d",
        "text": "Content of the previous chunk for context: h1: AI & Vectors h2: The best vector database is the database you already have.\n\n than exact keywords\n- [Keyword search](/docs/guides/ai/keyword-search): search by words or phrases\n- [Hybrid search](/docs/guides/ai/hybrid-search): combine semantic search with keyword search\n"
      }
    }
  },
  {
    "chunk_id": "50fac706-8748-4aca-8e60-64a4ff1e772c",
    "metadata": {
      "token_count": 115,
      "source_url": "https://supabase.com/docs/guides/ai",
      "page_title": "AI & Vectors | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "AI & Vectors",
        "h2": "Examples [\\#](\\#examples)"
      },
      "text": "[![Hugging Face inference](https://supabase.com/docs/img/icons/github-icon-light.svg)\\\\\n\\\\\nHugging Face inference\\\\\n\\\\\nGenerate image captions using Hugging Face.](/docs/guides/ai/examples/huggingface-image-captioning)\n\n[![OpenAI completions](https://supabase.com/docs/img/icons/github-icon-light.svg)\\\\\n\\\\\nOpenAI completions\\\\\n\\\\\nGenerate GPT text completions using OpenAI in Edge Functions.](/docs/guides/ai/examples/openai)\n\n",
      "overlap_text": {
        "previous_chunk_id": "96fbc08c-f9e1-418e-b653-a2ab4e2993a7",
        "text": "Content of the previous chunk for context: h1: AI & Vectors h2: Examples [\\#](\\#examples)\n\n-light.svg)\\\\\n\\\\\nImage Search with OpenAI CLIP\\\\\n\\\\\nImplement image search with the OpenAI CLIP Model and Supabase Vector.](/docs/guides/ai/examples/image-search-openai-clip)\n\n"
      }
    }
  },
  {
    "chunk_id": "d3204de6-99f7-49b0-93d2-e77acb624ed9",
    "metadata": {
      "token_count": 147,
      "source_url": "https://supabase.com/docs/guides/ai",
      "page_title": "AI & Vectors | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "AI & Vectors",
        "h2": "Examples [\\#](\\#examples)"
      },
      "text": "[![Building ChatGPT Plugins](https://supabase.com/docs/img/icons/github-icon-light.svg)\\\\\n\\\\\nBuilding ChatGPT Plugins\\\\\n\\\\\nUse Supabase as a Retrieval Store for your ChatGPT plugin.](/docs/guides/ai/examples/building-chatgpt-plugins)\n\n[![Vector search with Next.js and OpenAI](https://supabase.com/docs/img/icons/github-icon-light.svg)\\\\\n\\\\\nVector search with Next.js and OpenAI\\\\\n\\\\\nLearn how to build a ChatGPT-style doc search powered by Next.js, OpenAI, and Supabase.](/docs/guides/ai/examples/nextjs-vector-search)\n",
      "overlap_text": {
        "previous_chunk_id": "50fac706-8748-4aca-8e60-64a4ff1e772c",
        "text": "Content of the previous chunk for context: h1: AI & Vectors h2: Examples [\\#](\\#examples)\n\n://supabase.com/docs/img/icons/github-icon-light.svg)\\\\\n\\\\\nOpenAI completions\\\\\n\\\\\nGenerate GPT text completions using OpenAI in Edge Functions.](/docs/guides/ai/examples/openai)\n\n"
      }
    }
  },
  {
    "chunk_id": "27608a8e-b17d-4f84-b72b-ec58aa581342",
    "metadata": {
      "token_count": 141,
      "source_url": "https://supabase.com/docs/guides/ai",
      "page_title": "AI & Vectors | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "AI & Vectors",
        "h2": "Integrations [\\#](\\#integrations)"
      },
      "text": "[OpenAI\\\\\n\\\\\nOpenAI is an AI research and deployment company. Supabase provides a simple way to use OpenAI in your applications.](/docs/guides/ai/examples/building-chatgpt-plugins)\n\n[Amazon Bedrock\\\\\n\\\\\nA fully managed service that offers a choice of high-performing foundation models from leading AI companies.](/docs/guides/ai/integrations/amazon-bedrock)\n\n[Hugging Face\\\\\n\\\\\nHugging Face is an open-source provider of NLP technologies. Supabase provides a simple way to use Hugging Face's models in your applications.](/docs/guides/ai/hugging-face)\n\n",
      "overlap_text": {
        "previous_chunk_id": "d3204de6-99f7-49b0-93d2-e77acb624ed9",
        "text": "Content of the previous chunk for context: h1: AI & Vectors h2: Examples [\\#](\\#examples)\n\n search with Next.js and OpenAI\\\\\n\\\\\nLearn how to build a ChatGPT-style doc search powered by Next.js, OpenAI, and Supabase.](/docs/guides/ai/examples/nextjs-vector-search)\n"
      }
    }
  },
  {
    "chunk_id": "63a0fe28-8d90-400b-8187-57f8327fdf2d",
    "metadata": {
      "token_count": 82,
      "source_url": "https://supabase.com/docs/guides/ai",
      "page_title": "AI & Vectors | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "AI & Vectors",
        "h2": "Integrations [\\#](\\#integrations)"
      },
      "text": "[LangChain\\\\\n\\\\\nLangChain is a language-agnostic, open-source, and self-hosted API for text translation, summarization, and sentiment analysis.](/docs/guides/ai/langchain)\n\n[LlamaIndex\\\\\n\\\\\nLlamaIndex is a data framework for your LLM applications.](/docs/guides/ai/integrations/llamaindex)\n",
      "overlap_text": {
        "previous_chunk_id": "27608a8e-b17d-4f84-b72b-ec58aa581342",
        "text": "Content of the previous chunk for context: h1: AI & Vectors h2: Integrations [\\#](\\#integrations)\n\n[Hugging Face\\\\\n\\\\\nHugging Face is an open-source provider of NLP technologies. Supabase provides a simple way to use Hugging Face's models in your applications.](/docs/guides/ai/hugging-face)\n\n"
      }
    }
  },
  {
    "chunk_id": "3fcd786b-0b35-4918-ba06-1c810deb67ed",
    "metadata": {
      "token_count": 121,
      "source_url": "https://supabase.com/docs/guides/ai",
      "page_title": "AI & Vectors | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "AI & Vectors",
        "h2": "Case studies [\\#](\\#case-studies)"
      },
      "text": "[Berri AI Boosts Productivity by Migrating from AWS RDS to Supabase with pgvector\\\\\n\\\\\nLearn how Berri AI overcame challenges with self-hosting their vector database on AWS RDS and successfully migrated to Supabase.](https://supabase.com/customers/berriai)\n\n[Mendable switches from Pinecone to Supabase for PostgreSQL vector embeddings\\\\\n\\\\\nHow Mendable boosts efficiency and accuracy of chat powered search for documentation using Supabase with pgvector](https://supabase.com/customers/mendableai)\n\n",
      "overlap_text": {
        "previous_chunk_id": "63a0fe28-8d90-400b-8187-57f8327fdf2d",
        "text": "Content of the previous chunk for context: h1: AI & Vectors h2: Integrations [\\#](\\#integrations)\n\n analysis.](/docs/guides/ai/langchain)\n\n[LlamaIndex\\\\\n\\\\\nLlamaIndex is a data framework for your LLM applications.](/docs/guides/ai/integrations/llamaindex)\n"
      }
    }
  },
  {
    "chunk_id": "21774b17-09bf-464e-811f-b2f83277e768",
    "metadata": {
      "token_count": 72,
      "source_url": "https://supabase.com/docs/guides/ai",
      "page_title": "AI & Vectors | Supabase Docs"
    },
    "data": {
      "headers": {
        "h1": "AI & Vectors",
        "h2": "Case studies [\\#](\\#case-studies)"
      },
      "text": "[Markprompt: GDPR-Compliant AI Chatbots for Docs and Websites\\\\\n\\\\\nAI-powered chatbot platform, Markprompt, empowers developers to deliver efficient and GDPR-compliant prompt experiences on top of their content, by leveraging Supabase's secure and privacy-focused database and authentication solutions](https://supabase.com/customers/markprompt)\n",
      "overlap_text": {
        "previous_chunk_id": "3fcd786b-0b35-4918-ba06-1c810deb67ed",
        "text": "Content of the previous chunk for context: h1: AI & Vectors h2: Case studies [\\#](\\#case-studies)\n\n switches from Pinecone to Supabase for PostgreSQL vector embeddings\\\\\n\\\\\nHow Mendable boosts efficiency and accuracy of chat powered search for documentation using Supabase with pgvector](https://supabase.com/customers/mendableai)\n\n"
      }
    }
  }
]