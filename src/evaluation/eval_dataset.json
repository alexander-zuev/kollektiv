{
  "test_data": [
    {
      "question": "What is the difference between generating financial reports with and without XML tags?",
      "contexts": [
        "[Anthropic home page![light logo](https://mintlify.s3-us-west-1.amazonaws.com/anthropic/logo/light.svg)![dark logo](https://mintlify.s3-us-west-1.amazonaws.com/anthropic/logo/dark.svg)](/)\n\nEnglish\n\nSearch...\n\nCtrl K\n\nSearch\n\nNavigation\n\nPrompt engineering\n\nUse XML tags to structure your prompts\n\n[Welcome](/en/home) [User Guides](/en/docs/welcome) [API Reference](/en/api/getting-started) [Prompt Library](/en/prompt-library/library) [Release Notes](/en/release-notes/overview) [Developer Newsletter](/en/developer-newsletter/overview)\n\nWhen your prompts involve multiple components like context, instructions, and examples, XML tags can be a game-changer. They help Claude parse your prompts more accurately, leading to higher-quality outputs.\n\n**XML tip**: Use tags like `<instructions>`, `<example>`, and `<formatting>` to clearly separate different parts of your prompt. This prevents Claude from mixing up instructions with examples or context.\n\n## [\u200b](\\#why-use-xml-tags)  Why use XML tags?\n\n- **Clarity:** Clearly separate different parts of your prompt and ensure your prompt is well structured.\n- **Accuracy:** Reduce errors caused by Claude misinterpreting parts of your prompt.\n- **Flexibility:** Easily find, add, remove, or modify parts of your prompt without rewriting everything.\n- **Parseability:** Having Claude use XML tags in its output makes it easier to extract specific parts of its response by post-processing.\n\nThere are no canonical \u201cbest\u201d XML tags that Claude has been trained with in particular, although we recommend that your tag names make sense with the information they surround.\n\n* * *\n\n## [\u200b](\\#tagging-best-practices)  Tagging best practices\n\n1. **Be consistent**: Use the same tag names throughout your prompts, and refer to those tag names when talking about the content (e.g, `Using the contract in <contract> tags...`).\n2. **Nest tags**: You should nest tags `<outer><inner></inner></outer>` for hierarchical content.\n\n**Power user tip**: Combine XML tags with other techniques like multishot prompting ( `<examples>`) or chain of thought ( `<thinking>`, `<answer>`). This creates super-structured, high-performance prompts.\n\n### [\u200b](\\#examples)  Examples\n\nExample: Generating financial reports\n\nWithout XML tags, Claude misunderstands the task and generates a report that doesn\u2019t match the required structure or tone. After substitution, there is also a chance that Claude misunderstands where one section (like the the Q1 report example) stops and another begins.\n\n| Role | No XML Tags | With XML Tags |\n| --- | --- | --- |\n| User | You\u2019re a financial analyst at AcmeCorp. Generate a Q2 financial report for our investors. Include sections on Revenue Growth, Profit Margins, and Cash Flow, like with this example from last year: {{Q1\\_REPORT}}. Use data points from this spreadsheet: {{SPREADSHEET\\_DATA}}. The report should be extremely concise, to the point, professional, and in list format. It should and highlight both strengths and areas for improvement. | You\u2019re a financial analyst at AcmeCorp. Generate a Q2 financial report for our investors.<br>AcmeCorp is a B2B SaaS company. Our investors value transparency and actionable insights.<br>Use this data for your report:<data>{{SPREADSHEET\\_DATA}}</data><br><instructions><br>1\\. Include sections: Revenue Growth, Profit Margins, Cash Flow.<br>2\\. Highlight strengths and areas for improvement.<br></instructions><br>Make your tone concise and professional. Follow this structure:<br><formatting\\_example>{{Q1\\_REPORT}}</formatting\\_example> |\n| Assistant | Q2 Financial Report for AcmeCorp Investors<br>Dear Valued Investors,<br>I am pleased to present our Q2 financial report, showcasing AcmeCorp\u2019s continued growth and resilience in the B2B SaaS market.<br>1\\. Revenue Growth:<br>Our Q2 revenue"
      ],
      "ground_truth": "Without XML tags, Claude misunderstands the task and generates a report that doesn\u2019t match the required structure or tone. After substitution, there is also a chance that Claude misunderstands where one section stops and another begins. With XML tags, the prompt is structured more clearly, reducing errors and ensuring the report matches the required structure and tone.",
      "evolution_type": "simple",
      "metadata": [
        {
          "source": "/Users/az/PycharmProjects/omni-claude/src/data/raw/docs_anthropic_com_en_20240928_135426.json",
          "seq_num": 37,
          "title": "Use XML tags to structure your prompts - Anthropic",
          "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags",
          "description": ""
        }
      ]
    },
    {
      "question": "Why might Claude struggle with reading an analog clock?",
      "contexts": [
        "            \"data\": image1_data,\\\n                    },\\\n                },\\\n                {\\\n                    \"type\": \"text\",\\\n                    \"text\": \"Image 2:\"\\\n                },\\\n                {\\\n                    \"type\": \"image\",\\\n                    \"source\": {\\\n                        \"type\": \"base64\",\\\n                        \"media_type\": image2_media_type,\\\n                        \"data\": image2_data,\\\n                    },\\\n                },\\\n                {\\\n                    \"type\": \"text\",\\\n                    \"text\": \"How are these images different?\"\\\n                }\\\n            ],\\\n        }\\\n    ],\n)\n\n```\n\nExample: Four images across two conversation turns\n\nClaude\u2019s vision capabilities shine in multimodal conversations that mix images and text. You can have extended back-and-forth exchanges with Claude, adding new images or follow-up questions at any point. This enables powerful workflows for iterative image analysis, comparison, or combining visuals with other knowledge.\n\nAsk Claude to contrast two images, then ask a follow-up question comparing the first images to two new images.\n\n| Role | Content |\n| --- | --- |\n| User | Image 1: \\[Image 1\\] Image 2: \\[Image 2\\] How are these images different? |\n| Assistant | \\[Claude\u2019s response\\] |\n| User | Image 1: \\[Image 3\\] Image 2: \\[Image 4\\] Are these images similar to the first two? |\n| Assistant | \\[Claude\u2019s response\\] |\n\nWhen using the API, simply insert new images into the array of Messages in the `user` role as part of any standard [multiturn conversation](/en/api/messages-examples#multiple-conversational-turns) structure.\n\n* * *\n\n## [\u200b](\\#limitations)  Limitations\n\nWhile Claude\u2019s image understanding capabilities are cutting-edge, there are some limitations to be aware of:\n\n- **People identification**: Claude [cannot be used](https://www.anthropic.com/legal/aup) to identify (i.e., name) people in images and will refuse to do so.\n- **Accuracy**: Claude may hallucinate or make mistakes when interpreting low-quality, rotated, or very small images under 200 pixels.\n- **Spatial reasoning**: Claude\u2019s spatial reasoning abilities are limited. It may struggle with tasks requiring precise localization or layouts, like reading an analog clock face or describing exact positions of chess pieces.\n- **Counting**: Claude can give approximate counts of objects in an image but may not always be precisely accurate, especially with large numbers of small objects.\n- **AI generated images**: Claude does not know if an image is AI-generated and may be incorrect if asked. Do not rely on it to detect fake or synthetic images.\n- **Inappropriate content**: Claude will not process inappropriate or explicit images that violate our [Acceptable Use Policy](https://www.anthropic.com/legal/aup).\n-"
      ],
      "ground_truth": "Claude's spatial reasoning abilities are limited, which may cause it to struggle with tasks requiring precise localization or layouts, such as reading an analog clock face.",
      "evolution_type": "reasoning",
      "metadata": [
        {
          "source": "/Users/az/PycharmProjects/omni-claude/src/data/raw/docs_anthropic_com_en_20240928_135426.json",
          "seq_num": 40,
          "title": "Vision - Anthropic",
          "url": "https://docs.anthropic.com/en/docs/build-with-claude/vision",
          "description": "The Claude 3 family of models comes with new vision capabilities that allow Claude to understand and analyze images, opening up exciting possibilities for multimodal interaction."
        }
      ]
    },
    {
      "question": "How do evals and grading aid prompt engineering?",
      "contexts": [
        "[Anthropic home page![light logo](https://mintlify.s3-us-west-1.amazonaws.com/anthropic/logo/light.svg)![dark logo](https://mintlify.s3-us-west-1.amazonaws.com/anthropic/logo/dark.svg)](/)\n\nEnglish\n\nSearch...\n\nCtrl K\n\nSearch\n\nNavigation\n\nBuild with Claude\n\nCreate strong empirical evaluations\n\n[Welcome](/en/home) [User Guides](/en/docs/welcome) [API Reference](/en/api/getting-started) [Prompt Library](/en/prompt-library/library) [Release Notes](/en/release-notes/overview) [Developer Newsletter](/en/developer-newsletter/overview)\n\nAfter defining your success criteria, the next step is designing evaluations to measure LLM performance against those criteria. This is a vital part of the prompt engineering cycle.\n\n![](https://mintlify.s3-us-west-1.amazonaws.com/anthropic/images/how-to-prompt-eng.png)\n\nThis guide focuses on how to develop your test cases.\n\n## [\u200b](\\#building-evals-and-test-cases)  Building evals and test cases\n\n### [\u200b](\\#eval-design-principles)  Eval design principles\n\n1. **Be task-specific**: Design evals that mirror your real-world task distribution. Don\u2019t forget to factor in edge cases!\n\n\n\n\n\n\n\n\nExample edge cases\n\n\n\n\n\n\n- Irrelevant or nonexistent input data\n- Overly long input data or user input\n- \\[Chat use cases\\] Poor, harmful, or irrelevant user input\n- Ambiguous test cases where even humans would find it hard to reach an assessment consensus\n\n2. **Automate when possible**: Structure questions to allow for automated grading (e.g., multiple-choice, string match, code-graded, LLM-graded).\n3. **Prioritize volume over quality**: More questions with slightly lower signal automated grading is better than fewer questions with high-quality human hand-graded evals.\n\n### [\u200b](\\#example-evals)  Example evals\n\nTask fidelity (sentiment analysis) - exact match evaluation\n\n**What it measures**: Exact match evals measure whether the model\u2019s output exactly matches a predefined correct answer. It\u2019s a simple, unambiguous metric that\u2019s perfect for tasks with clear-cut, categorical answers like sentiment analysis (positive, negative, neutral).\n\n**Example eval test cases**: 1000 tweets with human-labeled sentiments.\n\nCopy\n\n```python\nimport anthropic\n\ntweets = [\\\n    {\"text\": \"This movie was a total waste of time. \ud83d\udc4e\", \"sentiment\": \"negative\"},\\\n    {\"text\": \"The new album is \ud83d\udd25! Been on repeat all day.\", \"sentiment\": \"positive\"},\\\n    {\"text\": \"I just love it when my flight gets delayed for 5 hours. #bestdayever\", \"sentiment\": \"negative\"},  # Edge case: Sarcasm\\\n    {\"text\": \"The movie's plot was terrible, but the acting was phenomenal.\", \"sentiment\": \"mixed\"},  # Edge case: Mixed sentiment\\\n    # ... 996 more tweets\\\n]\n\nclient = anthropic.Anthropic()\n\ndef get_completion(prompt: str):\n    message = client.messages.create(\n        model=\"claude-3-5-sonnet-20240620\",\n        max_tokens=50,\n        messages=[\\\n        {\"role\": \"user\", \"content\": prompt}\\\n        ]\n    )\n    return message.content[0].text\n\ndef evaluate_exact_match(model_output, correct_answer):\n    return model_output.strip().lower() == correct_answer.lower()\n\noutputs = [get_completion(f\"Classify this as 'positive', 'negative', 'neutral', or 'mixed': {tweet['text']}\") for tweet in tweets]\naccuracy = sum(evaluate_exact_match(output, tweet['sentiment']) for output, tweet in zip(outputs"
      ],
      "ground_truth": "Evals and grading aid prompt engineering by measuring LLM performance against defined success criteria. This involves designing evaluations that mirror real-world tasks, automating grading when possible, and prioritizing volume over quality to ensure comprehensive assessment.",
      "evolution_type": "multi_context",
      "metadata": [
        {
          "source": "/Users/az/PycharmProjects/omni-claude/src/data/raw/docs_anthropic_com_en_20240928_135426.json",
          "seq_num": 18,
          "title": "Create strong empirical evaluations - Anthropic",
          "url": "https://docs.anthropic.com/en/docs/build-with-claude/develop-tests",
          "description": ""
        }
      ]
    },
    {
      "question": "How to ensure Claude's outputs are accurate and consistent with good examples and clear instructions?",
      "contexts": [
        "[Anthropic home page![light logo](https://mintlify.s3-us-west-1.amazonaws.com/anthropic/logo/light.svg)![dark logo](https://mintlify.s3-us-west-1.amazonaws.com/anthropic/logo/dark.svg)](/)\n\nEnglish\n\nSearch...\n\nCtrl K\n\nSearch\n\nNavigation\n\nPrompt engineering\n\nUse examples (multishot prompting) to guide Claude's behavior\n\n[Welcome](/en/home) [User Guides](/en/docs/welcome) [API Reference](/en/api/getting-started) [Prompt Library](/en/prompt-library/library) [Release Notes](/en/release-notes/overview) [Developer Newsletter](/en/developer-newsletter/overview)\n\nExamples are your secret weapon shortcut for getting Claude to generate exactly what you need. By providing a few well-crafted examples in your prompt, you can dramatically improve the accuracy, consistency, and quality of Claude\u2019s outputs.\nThis technique, known as few-shot or multishot prompting, is particularly effective for tasks that require structured outputs or adherence to specific formats.\n\n**Power up your prompts**: Include 3-5 diverse, relevant examples to show Claude exactly what you want. More examples = better performance, especially for complex tasks.\n\n## [\u200b](\\#why-use-examples)  Why use examples?\n\n- **Accuracy**: Examples reduce misinterpretation of instructions.\n- **Consistency**: Examples enforce uniform structure and style.\n- **Performance**: Well-chosen examples boost Claude\u2019s ability to handle complex tasks.\n\n## [\u200b](\\#crafting-effective-examples)  Crafting effective examples\n\nFor maximum effectiveness, make sure that your examples are:\n\n- **Relevant**: Your examples mirror your actual use case.\n- **Diverse**: Your examples cover edge cases and potential challenges, and vary enough that Claude doesn\u2019t inadvertently pick up on unintended patterns.\n- **Clear**: Your examples are wrapped in `<example>` tags (if multiple, nested within `<examples>` tags) for structure.\n\nAsk Claude to evaluate your examples for relevance, diversity, or clarity. Or have Claude generate more examples based on your initial set.\n\nExample: Analyzing customer feedback\n\nNotice that in the \u201cno examples\u201d version, Claude does not list multiple options for each category, despite its written analysis indicating that there are multiple categories for certain feedback. It also includes a long explanation when we may not want it to.\n\n| Role | No Examples | With Examples |\n| --- | --- | --- |\n| User | Analyze this customer feedback and categorize the issues. Use these categories: UI/UX, Performance, Feature Request, Integration, Pricing, and Other. Also rate the sentiment (Positive/Neutral/Negative) and priority (High/Medium/Low).<br>Here is the feedback: {{FEEDBACK}} | Our CS team is overwhelmed with unstructured feedback. Your task is to analyze feedback and categorize issues for our product and engineering teams. Use these categories: UI/UX, Performance, Feature Request, Integration, Pricing, and Other. Also rate the sentiment (Positive/Neutral/Negative) and priority (High/Medium/Low). Here is an example:<br><example><br>Input: The new dashboard is a mess! It takes forever to load, and I can\u2019t find the export button. Fix this ASAP!<br>Category: UI/UX, Performance<br>Sentiment: Negative<br>Priority: High</example><br>Now, analyze this feedback: {{FEEDBACK}} |\n| Assistant (Claude\u2019s response) | Here\u2019s the analysis of the customer feedback:<br>Issue: UI/UX<br>Sentiment: Negative<br>Priority: High<br>The customer is frustrated with the new dashboard design, which they find cluttered and slow to load. They specifically call out the missing \u201cexport\u201d button, which is likely a critical feature. This issue needs to be addressed as a high priority.<br>Issue: Integration<br>Sentiment: Positive<br>Priority: Medium<br>The customer is pleased with the existing Salesforce integration but would like to see support for Hubspot as well. This is a feature request that could be considered for a future product update.<br>Issue: Pricing<br>Sentiment: Negative<br>Priority: High<br>The customer finds the pricing to be unreasonable, especially for the basic",
        "[Anthropic home page![light logo](https://mintlify.s3-us-west-1.amazonaws.com/anthropic/logo/light.svg)![dark logo](https://mintlify.s3-us-west-1.amazonaws.com/anthropic/logo/dark.svg)](/)\n\nEnglish\n\nSearch...\n\nCtrl K\n\nSearch\n\nNavigation\n\nPrompt engineering\n\nBe clear, direct, and detailed\n\n[Welcome](/en/home) [User Guides](/en/docs/welcome) [API Reference](/en/api/getting-started) [Prompt Library](/en/prompt-library/library) [Release Notes](/en/release-notes/overview) [Developer Newsletter](/en/developer-newsletter/overview)\n\nWhen interacting with Claude, think of it as a brilliant but very new employee (with amnesia) who needs explicit instructions. Like any new employee, Claude does not have context on your norms, styles, guidelines, or preferred ways of working.\nThe more precisely you explain what you want, the better Claude\u2019s response will be.\n\n**The golden rule of clear prompting**\n\nShow your prompt to a colleague, ideally someone who has minimal context on the task, and ask them to follow the instructions. If they\u2019re confused, Claude will likely be too.\n\n## [\u200b](\\#how-to-be-clear-contextual-and-specific)  How to be clear, contextual, and specific\n\n- **Give Claude contextual information:** Just like you might be able to better perform on a task if you knew more context, Claude will perform better if it has more contextual information. Some examples of contextual information:\n\n  - What the task results will be used for\n  - What audience the output is meant for\n  - What workflow the task is a part of, and where this task belongs in that workflow\n  - The end goal of the task, or what a successful task completion looks like\n- **Be specific about what you want Claude to do:** For example, if you want Claude to output only code and nothing else, say so.\n- **Provide instructions as sequential steps:** Use numbered lists or bullet points to better ensure that Claude carries out the task the exact way you want it to.\n\n### [\u200b](\\#examples)  Examples\n\nExample: Anonymizing customer feedback\n\nNotice that Claude still makes mistakes in the unclear prompting example, such as leaving in a customer\u2019s name.\n\n| Role | Unclear Prompt | Clear Prompt |\n| --- | --- | --- |\n| User | Please remove all personally identifiable information from these customer feedback messages: {{FEEDBACK\\_DATA}} | Your task is to anonymize customer feedback for our quarterly review.<br>Instructions:<br>1\\. Replace all customer names with \u201cCUSTOMER\\_\\[ID\\]\u201d (e.g., \u201cJane Doe\u201d \u2192 \u201cCUSTOMER\\_001\u201d).<br>2\\. Replace email addresses with \u201cEMAIL\\_\\[ID\\]@example.com\u201d.<br>3\\. Redact phone numbers as \u201cPHONE\\_\\[ID\\]\u201c.<br>4\\. If a message mentions a specific product (e.g., \u201cAcmeCloud\u201d), leave it intact.<br>5\\. If no PII is found, copy the message verbatim.<br>6\\. Output only the processed messages, separated by \u201d---\u201c.<br>Data to process: {{FEEDBACK\\_DATA}} |\n| Assistant (Claude\u2019s response) | Here are the anonymized customer feedback messages:<br>1\\. I\u2019ve been using your software for years, and it\u2019s been great. But lately, AcmeCloud has been crashing a lot. Fix it!<br>2\\. XXX, your customer support rep, was incredibly helpful. He guided me through the whole process. My email is XXX if you want to send a survey.<br>3\\. I\u2019m John Smith, and I\u2019m not happy. I\u2019ve been on hold for 2 hours trying to reach someone at XXX. This is unacceptable! | CUSTOMER\\_001: I\u2019ve been using your software for years, and it\u2019s been great. But lately, AcmeCloud has been crashing a lot. Fix it!<br>\\-\\-\\-<br>CUSTOMER\\_002: CUSTOMER\\_SERVICE\\_001, your customer support rep, was incredibly helpful. He guided me through"
      ],
      "ground_truth": "To ensure Claude's outputs are accurate and consistent, provide 3-5 diverse, relevant examples to guide its behavior. Make sure the examples are clear, relevant, and diverse, covering edge cases and potential challenges. Additionally, give Claude contextual information, be specific about what you want, and provide instructions as sequential steps.",
      "evolution_type": "multi_context",
      "metadata": [
        {
          "source": "/Users/az/PycharmProjects/omni-claude/src/data/raw/docs_anthropic_com_en_20240928_135426.json",
          "seq_num": 47,
          "title": "Use examples (multishot prompting) to guide Claude's behavior - Anthropic",
          "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/multishot-prompting",
          "description": ""
        },
        {
          "source": "/Users/az/PycharmProjects/omni-claude/src/data/raw/docs_anthropic_com_en_20240928_135426.json",
          "seq_num": 31,
          "title": "Be clear, direct, and detailed - Anthropic",
          "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/be-clear-and-direct",
          "description": ""
        }
      ]
    },
    {
      "question": "How can you force Claude to use a specific tool to answer a user's question?",
      "contexts": [
        " It will not provide any other information about the stock or company.\",\n  \"input_schema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"ticker\": {\n        \"type\": \"string\",\n        \"description\": \"The stock ticker symbol, e.g. AAPL for Apple Inc.\"\n      }\n    },\n    \"required\": [\"ticker\"]\n  }\n}\n\n```\n\nExample poor tool description\n\nJSON\n\nCopy\n\n```JSON\n{\n  \"name\": \"get_stock_price\",\n  \"description\": \"Gets the stock price for a ticker.\",\n  \"input_schema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"ticker\": {\n        \"type\": \"string\"\n      }\n    },\n    \"required\": [\"ticker\"]\n  }\n}\n\n```\n\nThe good description clearly explains what the tool does, when to use it, what data it returns, and what the `ticker` parameter means. The poor description is too brief and leaves Claude with many open questions about the tool\u2019s behavior and usage.\n\n### [\u200b](\\#controlling-claudes-output)  Controlling Claude\u2019s output\n\n#### [\u200b](\\#forcing-tool-use)  Forcing tool use\n\nIn some cases, you may want Claude to use a specific tool to answer the user\u2019s question, even if Claude thinks it can provide an answer without using a tool. You can do this by specifying the tool in the `tool_choice` field like so:\n\nCopy\n\n```\ntool_choice = {\"type\": \"tool\", \"name\": \"get_weather\"}\n\n```\n\nWhen working with the tool\\_choice parameter, we have three possible options:\n\n- `auto` allows Claude to decide whether to call any provided tools or not. This is the default value.\n- `any` tells Claude that it must use one of the provided tools, but doesn\u2019t force a particular tool.\n- `tool` allows us to force Claude to always use a particular tool.\n\nThis diagram illustrates how each option works:\n\n![](https://mintlify.s3-us-west-1.amazonaws.com/anthropic/images/tool_choice.png)\n\nNote that when you have `tool_choice` as `any` or `tool`, we will prefill the assistant message to force a tool to be used. This means that the models will not emit a chain-of-thought `text` content block before `tool_use` content blocks, even if explicitly asked to do so.\n\nOur testing has shown that this should not reduce performance. If you would like to keep chain-of-thought (particularly with Opus) while still requesting that the model use a specific tool, you can use `{\"type\": \"auto\"}` for `tool_choice` (the default) and add explicit instructions in a `user` message. For example: `What's the weather like in London? Use the get_weather tool in your response.`\n\n#### [\u200b](\\#json-output)  JSON output\n\nTools do not necessarily need to be client-side functions \u2014 you can use tools anytime you want the model to return JSON output that follows a provided schema. For example, you might use a `record_summary` tool with a particular schema. See [tool use examples](/en/docs/build-with-claude/tool-use#json-mode) for a full working example.\n\n#### [\u200b](\\#chain-of-thought)  Chain of thought\n\nWhen using tools, Claude will often show its \u201cchain of thought\u201d, i.e. the step-by-step reasoning it uses to break down the problem and decide which tools to use. The Claude 3 Opus model will do this if `tool_choice` is set to `auto` (this is the default value, see [Forcing tool use](/en/docs/build-with-claude/tool-use#forcing-tool-use)), and Sonnet and Haiku can be prompted into doing it.\n\nFor example, given the prompt \u201cWhat\u2019s the weather like in San Francisco right now, and what time is it there?\u201d, Claude might respond with:\n\nJSON\n\nCopy\n\n```JSON\n"
      ],
      "ground_truth": "You can force Claude to use a specific tool to answer a user's question by specifying the tool in the `tool_choice` field like so: `tool_choice = {\"type\": \"tool\", \"name\": \"get_weather\"}`.",
      "evolution_type": "simple",
      "metadata": [
        {
          "source": "/Users/az/PycharmProjects/omni-claude/src/data/raw/docs_anthropic_com_en_20240928_135426.json",
          "seq_num": 17,
          "title": "Tool use (function calling) - Anthropic",
          "url": "https://docs.anthropic.com/en/docs/build-with-claude/tool-use",
          "description": ""
        }
      ]
    }
  ]
}